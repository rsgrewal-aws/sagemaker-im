{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: nvidia-pyindex in /opt/conda/lib/python3.7/site-packages (1.0.9)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: tritonclient[http] in /opt/conda/lib/python3.7/site-packages (2.28.0)\n",
      "Requirement already satisfied: python-rapidjson>=0.9.1 in /opt/conda/lib/python3.7/site-packages (from tritonclient[http]) (1.9)\n",
      "Requirement already satisfied: numpy>=1.19.1 in /opt/conda/lib/python3.7/site-packages (from tritonclient[http]) (1.21.6)\n",
      "Requirement already satisfied: geventhttpclient<=2.0.2,>=1.4.4 in /opt/conda/lib/python3.7/site-packages (from tritonclient[http]) (2.0.2)\n",
      "Requirement already satisfied: aiohttp>=3.8.1 in /opt/conda/lib/python3.7/site-packages (from tritonclient[http]) (3.8.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp>=3.8.1->tritonclient[http]) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp>=3.8.1->tritonclient[http]) (1.3.3)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp>=3.8.1->tritonclient[http]) (0.13.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from aiohttp>=3.8.1->tritonclient[http]) (4.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp>=3.8.1->tritonclient[http]) (22.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp>=3.8.1->tritonclient[http]) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp>=3.8.1->tritonclient[http]) (4.0.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp>=3.8.1->tritonclient[http]) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp>=3.8.1->tritonclient[http]) (6.0.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from geventhttpclient<=2.0.2,>=1.4.4->tritonclient[http]) (1.14.0)\n",
      "Requirement already satisfied: brotli in /opt/conda/lib/python3.7/site-packages (from geventhttpclient<=2.0.2,>=1.4.4->tritonclient[http]) (1.0.9)\n",
      "Requirement already satisfied: gevent>=0.13 in /opt/conda/lib/python3.7/site-packages (from geventhttpclient<=2.0.2,>=1.4.4->tritonclient[http]) (1.4.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from geventhttpclient<=2.0.2,>=1.4.4->tritonclient[http]) (2022.9.24)\n",
      "Requirement already satisfied: greenlet>=0.4.14 in /opt/conda/lib/python3.7/site-packages (from gevent>=0.13->geventhttpclient<=2.0.2,>=1.4.4->tritonclient[http]) (0.4.15)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.7/site-packages (from yarl<2.0,>=1.0->aiohttp>=3.8.1->tritonclient[http]) (2.8)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -qU pip awscli boto3 sagemaker\n",
    "!pip install nvidia-pyindex\n",
    "!pip install tritonclient[http]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To create the JIT Trace model you need\n",
    "\n",
    "Torch version 1.12.1 Torch Vision 0.13.1 and Cuda library 11.3\n",
    "\n",
    "Secondly you need a GPU instance to run the notebook - this has been tested on a ml.g4dn.xlarge which comes with 1 gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com, https://download.pytorch.org/whl/cu113\n",
      "Requirement already satisfied: torch==1.12.1+cu113 in /opt/conda/lib/python3.7/site-packages (1.12.1+cu113)\n",
      "Requirement already satisfied: torchvision==0.13.1+cu113 in /opt/conda/lib/python3.7/site-packages (0.13.1+cu113)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.12.1+cu113) (4.4.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision==0.13.1+cu113) (1.21.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision==0.13.1+cu113) (2.28.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision==0.13.1+cu113) (9.3.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.13.1+cu113) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.13.1+cu113) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.13.1+cu113) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.13.1+cu113) (2.8)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 --extra-index-url https://download.pytorch.org/whl/cu113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import tarfile\n",
    "import boto3, json, sagemaker, time\n",
    "from sagemaker import get_execution_role\n",
    "import concurrent.futures\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPTIONAL -- Create a JIT Traced model\n",
    "\n",
    "#### Few points to note: The traced models is provided in the zip file which can be used as is\n",
    "1. The Model after trace is now returing outputs like OUTPUT_0 , 1 etc\n",
    "2. To change them to named outputs can be done and we can try post this issue gets resolved\n",
    "3. To full create a jit traced model we will need to provide a sample inputs and hence for now we have created a scripted model\n",
    "4. The TORCH and the TORCHSCRIPT libraries would need to match the container and hence we use the specific ones mentioned above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1+cu113\n",
      "0.13.1+cu113\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "print(torch.__version__)\n",
    "import torchvision\n",
    "print(torchvision.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert the model into Serving mode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model_path = Path(\"od-load-test-model/1/model.pth\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = torch.load(original_model_path)\n",
    "model = model.to(device)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JitDummy(torch.nn.Module):\n",
    "    # Modify original model to take int8 inputs and return Tuple[Tensor] results\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        \n",
    "    @torch.jit.ignore\n",
    "    def debug_output(self, preds):\n",
    "        test_o = [pred[\"boxes\"] for pred in  preds]\n",
    "        print(f\"{type(test_o[0])}, {test_o[0]}, {type(test_o)},\", flush=True)\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        orig_type = inp.dtype\n",
    "         #return bboxes, labels, scores\n",
    "        return (torch.ones((5, 3), dtype=orig_type), )  #torch.float16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JitConcatWrapper(torch.nn.Module):\n",
    "    # Modify original model to take int8 inputs and return Tuple[Tensor] results\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, inp):\n",
    "        \n",
    "        inp = inp.div(255)\n",
    "        \n",
    "        # this will make the jit model work with arbitrary batch sizes by splitting the input tensor along the batch axis\n",
    "        _, preds = self.model([t.squeeze() for t in torch.split(inp,1)])\n",
    "        \n",
    "        bboxes = []\n",
    "        labels = []\n",
    "        scores = []\n",
    "        img_idxs = []\n",
    "\n",
    "        for idx, pred in enumerate(preds):\n",
    "            num_detections = pred[\"labels\"].shape[0]\n",
    "            \n",
    "            if num_detections == 0:\n",
    "                continue\n",
    "                \n",
    "            else:\n",
    "                bboxes.append(pred[\"boxes\"])\n",
    "                labels.append(pred[\"labels\"])\n",
    "                scores.append(pred[\"scores\"])\n",
    "                img_idxs.append(torch.full((num_detections,), idx, dtype=torch.int8))\n",
    "        \n",
    "        if len(labels) == 0: # return empty tensors if no detections in batch\n",
    "            bboxes_out = torch.empty((0,4), dtype=torch.float32)\n",
    "            labels_out = torch.empty((0,), dtype=torch.int64) \n",
    "            scores_out = torch.empty((0,), dtype=torch.float32)\n",
    "            img_idxs_out = torch.empty((0,), dtype=torch.int8)\n",
    "    \n",
    "        else:\n",
    "            bboxes_out = torch.cat(bboxes)\n",
    "            labels_out = torch.cat(labels)\n",
    "            scores_out = torch.cat(scores)\n",
    "            img_idxs_out = torch.cat(img_idxs)\n",
    "        \n",
    "        return bboxes_out, labels_out, scores_out, img_idxs_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JitPadWrapper(torch.nn.Module):\n",
    "    # Modify original model to take int8 inputs and return Tuple[Tensor] results\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.device = next(model.parameters()).device\n",
    "        self.box_pad = torch.tensor([-1, -1, -1, -1], dtype=torch.float32).to(device)\n",
    "        self.label_pad = torch.tensor([-1], dtype=torch.int64).to(device)\n",
    "        self.scores_pad = torch.tensor([-1], dtype=torch.float32).to(device)\n",
    "        \n",
    "\n",
    "    def forward(self, inp):\n",
    "        \n",
    "        inp = inp.div(255)\n",
    "        \n",
    "        # this will make the jit model work with arbitrary batch sizes by splitting the input tensor along the batch axis\n",
    "        _, preds = self.model([t.squeeze() for t in torch.split(inp,1)])\n",
    "        \n",
    "        \n",
    "        max_detections = max([pred[\"labels\"].shape[0] for pred in preds])\n",
    "        \n",
    "        for pred in preds:\n",
    "            num_detections = pred[\"labels\"].shape[0]\n",
    "            padding_amount = max_detections - num_detections\n",
    "            \n",
    "            if padding_amount == 0:\n",
    "                continue\n",
    "            else:\n",
    "                pred[\"boxes\"] = torch.cat([pred[\"boxes\"], self.box_pad.expand(padding_amount, 4)])\n",
    "                pred[\"labels\"] = torch.cat([pred[\"labels\"], self.label_pad.expand(padding_amount, )])\n",
    "                pred[\"scores\"] = torch.cat([pred[\"scores\"], self.scores_pad.expand(padding_amount, )])\n",
    "        \n",
    "        bboxes = torch.stack([pred[\"boxes\"] for pred in  preds])\n",
    "        labels = torch.stack([pred[\"labels\"] for pred in  preds])\n",
    "        scores = torch.stack([pred[\"scores\"] for pred in  preds])\n",
    "        \n",
    "        return bboxes, labels, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JitWrapper(torch.nn.Module):\n",
    "    # Modify original model to take int8 inputs and return Tuple[Tensor] results\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        \n",
    "    @torch.jit.ignore\n",
    "    def debug_output(self, preds):\n",
    "        test_o = [pred[\"boxes\"] for pred in  preds]\n",
    "        print(f\"{type(test_o[0])}, {test_o[0]}, {type(test_o)},\", flush=True)\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        orig_type = inp.dtype\n",
    "        inp = inp.div(255)\n",
    "        local_device = torch.device('cuda') #if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "        #with torch.autocast(device_type='cuda'):\n",
    "        \n",
    "            # preds_old = [{\n",
    "            #     'boxes':torch.ones((5,3), dtype=torch.float32),  # to match the config.pbtxt\n",
    "            #     'labels':torch.ones((5,3), dtype=torch.int64), \n",
    "            #     'scores':torch.ones((5,3), dtype=torch.float32)\n",
    "            # }] # - # -  type preds 'List[Dict[str, Tensor]]'.\n",
    "            # this will make the jit model work with arbitrary batch sizes by splitting the input tensor along the batch axis\n",
    "            _, preds = self.model([t.squeeze() for t in torch.split(inp,1)])\n",
    "\n",
    "             # -  type preds 'List[Dict[str, Tensor]]'.\n",
    "            #if not torch.jit.is_scripting(): \n",
    "\n",
    "            bboxes = torch.stack([pred[\"boxes\"] for pred in  preds])\n",
    "            labels = torch.stack([pred[\"labels\"] for pred in  preds])\n",
    "            scores = torch.stack([pred[\"scores\"] for pred in  preds])\n",
    "            \n",
    "            bboxes = torch.stack([torch.nn.utils.rnn.pad_sequence([pred[\"boxes\"] for pred in  preds])  ])\n",
    "            labels = torch.stack([torch.nn.utils.rnn.pad_sequence([pred[\"labels\"] for pred in  preds]) ])\n",
    "            scores = torch.stack([torch.nn.utils.rnn.pad_sequence([pred[\"scores\"] for pred in  preds]) ])\n",
    "            print(f\"bboxes.shape={bboxes.shape}:\")\n",
    "        \n",
    "        return bboxes, labels, scores\n",
    "        #return torch.ones((5, 3), dtype=torch.float) #torch.float16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracing fails because the output of the model in _preds is nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "torch.Size([12, 3, 480, 856]) torch.Size([3, 480, 856])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-e51330710c4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtraced_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraced_wrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage_array_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#image_array_tensors)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraced_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0m_force_outplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m             \u001b[0m_module_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m         )\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    972\u001b[0m                 \u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m                 \u001b[0m_force_outplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m                 \u001b[0margument_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m             )\n\u001b[1;32m    976\u001b[0m             \u001b[0mcheck_trace_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1116\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1118\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1119\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-68-a48683e86f12>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# this will make the jit model work with arbitrary batch sizes by splitting the input tensor along the batch axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mbboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "#traced_wrapper = JitWrapper(model) \n",
    "#traced_wrapper = JitDummy(model)\n",
    "traced_wrapper = JitConcatWrapper(model)\n",
    "#traced_wrapper = JitPadWrapper(model)\n",
    "\n",
    "\n",
    "local_device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(local_device)\n",
    "image_array_tensors = torch.tensor(image_batch_local,device=local_device,dtype=torch.float)#.cuda()\n",
    "#image_array_tensors = torch.tensor(image_batch,device=local_device,dtype=torch.float)#.cuda()\n",
    "print(image_array_tensors.shape, image_array_tensors[0].shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    traced_model = torch.jit.trace(traced_wrapper, (image_array_tensors))#image_array_tensors)\n",
    "    \n",
    "print(traced_model.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Script works since output is at run time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    inp: Tensor) -> Tuple[Tensor, Tensor, Tensor]:\n",
      "  _0 = __torch__.torch.nn.utils.rnn.pad_sequence\n",
      "  inp0 = torch.div(inp, 255)\n",
      "  _1 = __torch__.torch.autograd.grad_mode.no_grad.__new__(__torch__.torch.autograd.grad_mode.no_grad)\n",
      "  _2 = (_1).__init__()\n",
      "  with _1:\n",
      "    model = self.model\n",
      "    _3 = annotate(List[Tensor], [])\n",
      "    _4 = torch.split(inp0, 1)\n",
      "    for _5 in range(torch.len(_4)):\n",
      "      t = _4[_5]\n",
      "      _6 = torch.append(_3, torch.squeeze(t))\n",
      "    _7, preds, = (model).forward(_3, None, )\n",
      "    _8 = annotate(List[Tensor], [])\n",
      "    for _9 in range(torch.len(preds)):\n",
      "      pred = preds[_9]\n",
      "      _10 = torch.append(_8, pred[\"boxes\"])\n",
      "    bboxes = torch.stack([_0(_8, False, 0., )])\n",
      "    _11 = annotate(List[Tensor], [])\n",
      "    for _12 in range(torch.len(preds)):\n",
      "      pred0 = preds[_12]\n",
      "      _13 = torch.append(_11, pred0[\"labels\"])\n",
      "    labels = torch.stack([_0(_11, False, 0., )])\n",
      "    _14 = annotate(List[Tensor], [])\n",
      "    for _15 in range(torch.len(preds)):\n",
      "      pred1 = preds[_15]\n",
      "      _16 = torch.append(_14, pred1[\"scores\"])\n",
      "    scores = torch.stack([_0(_14, False, 0., )])\n",
      "    _17 = torch.format(\"bboxes.shape={}:\", torch.size(bboxes))\n",
      "    print(_17)\n",
      "  return (bboxes, labels, scores)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#traced_wrapper = JitWrapper(model) \n",
    "#traced_wrapper = JitDummy(model)\n",
    "#traced_wrapper = JitConcatWrapper(model) # similiar to JitWrapper\n",
    "traced_wrapper = JitPadWrapper(model)\n",
    "\n",
    "jit_model = torch.jit.script(wrapped_model)\n",
    "print(jit_model.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'jit-resnet-v3-model/1/model.pt': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p jit-resnet-v3-model\n",
    "!mkdir -p jit-resnet-v3-model/1\n",
    "!rm jit-resnet-v3-model/1/model.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jit_model.save(\"./jit-resnet-v3-model/1/model.pt\")\n",
    "#torch.jit.save(jit_model, \"./jit-resnet-v3-model/1/model.pt\") \n",
    "#traced_model.save(\"jit-resnet-v3-model/1/model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 133560\n",
      "drwxr-xr-x 3 root root      6144 Nov 25 05:16 ..\n",
      "drwxr-xr-x 2 root root      6144 Dec  1 20:20 .ipynb_checkpoints\n",
      "drwxr-xr-x 3 root root      6144 Dec  1 20:21 .\n",
      "-rw-r--r-- 1 root root 136753044 Dec  1 20:21 model.pt\n"
     ]
    }
   ],
   "source": [
    "!ls -alrt jit-resnet-v3-model/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 133556\n",
      "drwxr-xr-x 3 root root      6144 Nov 25 05:16 ..\n",
      "-rw-r--r-- 1 root root 136753044 Dec  1 20:21 model.pt\n",
      "drwxr-xr-x 2 root root      6144 Dec  1 20:21 .\n"
     ]
    }
   ],
   "source": [
    "!rm -r jit-resnet-v3-model/1/.ip*\n",
    "!ls -alrt jit-resnet-v3-model/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting jit-resnet-v3-model/config.pbtxt\n"
     ]
    }
   ],
   "source": [
    "%%writefile jit-resnet-v3-model/config.pbtxt\n",
    "name: \"jit-resnet-v3-model\"\n",
    "platform: \"pytorch_libtorch\"\n",
    "max_batch_size: 12\n",
    "input {\n",
    "  name: \"INPUT__0\"\n",
    "  data_type: TYPE_UINT8\n",
    "  dims: [3,480,856]\n",
    "}\n",
    "output {\n",
    "  name: \"OUTPUT__0\"\n",
    "  data_type: TYPE_FP32\n",
    "  dims: [-1]\n",
    "}\n",
    "output {\n",
    "  name: \"OUTPUT__1\"\n",
    "  data_type: TYPE_INT64\n",
    "  dims: [-1]\n",
    "}\n",
    "\n",
    "output {\n",
    "  name: \"OUTPUT__2\"\n",
    "  data_type: TYPE_FP32\n",
    "  dims: [-1]\n",
    "}\n",
    "\n",
    "instance_group {\n",
    "  count: 3\n",
    "  kind: KIND_GPU\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now create the tar ball and upload "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_path = \"jit-resnet-v3-model\"\n",
    "\n",
    "output_filename = f\"model.tar.gz\"\n",
    "with tarfile.open(output_filename, \"w:gz\") as tar:\n",
    "    tar.add(model_path, arcname=model_path)\n",
    "sm_client = boto3.client(service_name=\"sagemaker\")\n",
    "sagemaker_session = sagemaker.Session(boto_session=boto3.Session())\n",
    "role = get_execution_role()\n",
    "\n",
    "model_uri = sagemaker_session.upload_data(path=output_filename, key_prefix=f\"{model_path}\")\n",
    "print(model_uri)\n",
    "os.remove(output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-eu-west-1-225730023796/temp_model/jit-resnet-v17-model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "model_path = \"jit-resnet-v3-model\"\n",
    "\n",
    "output_filename = f\"jit-resnet-v17-model.tar.gz\"\n",
    "with tarfile.open(output_filename, \"w:gz\") as tar:\n",
    "    tar.add(model_path, arcname=model_path)\n",
    "sm_client = boto3.client(service_name=\"sagemaker\")\n",
    "sagemaker_session = sagemaker.Session(boto_session=boto3.Session())\n",
    "role = get_execution_role()\n",
    "\n",
    "model_uri = sagemaker_session.upload_data(path=output_filename, key_prefix=\"temp_model\")\n",
    "print(model_uri)\n",
    "os.remove(output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480\n",
      "(12, 3, 480, 856)\n"
     ]
    },
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (400) from primary with message \"{\"error\":\"[request id: <id_unknown>] failed to split the output tensor 'OUTPUT__0' in responses: expected batch size of atleast 12 in model output, got 1\"}\". See https://eu-west-1.console.aws.amazon.com/cloudwatch/home?region=eu-west-1#logEventViewer:group=/aws/sagemaker/Endpoints/resnet-fpn-v2-2022-11-25-19-22-56-057 in account 225730023796 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-6b3e520b8773>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mst_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minvoke_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'jit-resnet-v17-model.tar.gz'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#'model.tar.gz') # 'resnet_fpn_v2.tar.gz' # - 'jit-resnet-v5-model.tar.gz' ) # passing in a numpy aray already\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#result = invoke_endpoint(torch.tensor(image_batch_local[0]).unsqueeze(0).numpy(), m_name, 'jit-resnet-v11-model.tar.gz')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-9426d9b1cb2b>\u001b[0m in \u001b[0;36minvoke_endpoint\u001b[0;34m(images, endpoint_name, target_model)\u001b[0m\n\u001b[1;32m     32\u001b[0m         ),\n\u001b[1;32m     33\u001b[0m         \u001b[0mBody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_body\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mTargetModel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m                 )\n\u001b[1;32m    529\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    958\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    961\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (400) from primary with message \"{\"error\":\"[request id: <id_unknown>] failed to split the output tensor 'OUTPUT__0' in responses: expected batch size of atleast 12 in model output, got 1\"}\". See https://eu-west-1.console.aws.amazon.com/cloudwatch/home?region=eu-west-1#logEventViewer:group=/aws/sagemaker/Endpoints/resnet-fpn-v2-2022-11-25-19-22-56-057 in account 225730023796 for more information."
     ]
    }
   ],
   "source": [
    "print(len(buffer[0]))\n",
    "st_time = time.time()\n",
    "\n",
    "result = invoke_endpoint(image_batch, m_name, 'jit-resnet-v17-model.tar.gz') #'model.tar.gz') # 'resnet_fpn_v2.tar.gz' # - 'jit-resnet-v5-model.tar.gz' ) # passing in a numpy aray already \n",
    "#result = invoke_endpoint(torch.tensor(image_batch_local[0]).unsqueeze(0).numpy(), m_name, 'jit-resnet-v11-model.tar.gz')\n",
    "\n",
    "print(len(buffer),time.time() - st_time)\n",
    "print(f\"Test finished for 1 batch of {batch_size} images::result={result}::\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 480, 856)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'{\"model_name\":\"d85097bca17a6d3758be38f49b039fe3\",\"model_version\":\"1\",\"outputs\":[{\"name\":\"OUTPUT__0\",\"datatype\":\"FP32\",\"shape\":[1,0,1,4],\"parameters\":{\"binary_data_size\":0}},{\"name\":\"OUTPUT__1\",\"datatype\":\"INT64\",\"shape\":[1,0,1],\"parameters\":{\"binary_data_size\":0}},{\"name\":\"OUTPUT__2\",\"datatype\":\"FP32\",\"shape\":[1,0,1],\"parameters\":{\"binary_data_size\":0}}]}'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = []\n",
    "outputs = []\n",
    "#input_data = torch.tensor(image_batch_local[0]).unsqueeze(0).numpy()\n",
    "input_data = torch.tensor(image_batch[0]).unsqueeze(0).numpy()\n",
    "print(input_data.shape)\n",
    "    \n",
    "runtime_sm_client = boto3.client('sagemaker-runtime')\n",
    "#inputs.append(httpclient.InferInput(\"INPUT__0\", [ len(input_data),h, w,3], \"UINT8\"))\n",
    "    \n",
    "inputs = [httpclient.InferInput(\"INPUT__0\", input_data.shape, \"UINT8\")]\n",
    "inputs[0].set_data_from_numpy(input_data, binary_data=True)\n",
    "outputs_data = [httpclient.InferRequestedOutput(f\"OUTPUT__{n}\", binary_data=True) for n in range(3)]\n",
    "    \n",
    "request_body, header_length = httpclient.InferenceServerClient.generate_request_body(\n",
    "        inputs, outputs=outputs_data\n",
    ")\n",
    "\n",
    "\n",
    "response_invoke = runtime_sm_client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        ContentType=\"application/vnd.sagemaker-triton.binary+json;json-header-size={}\".format(\n",
    "            header_length\n",
    "        ),\n",
    "        Body=request_body,\n",
    "        TargetModel='jit-resnet-v17-model.tar.gz',\n",
    "        \n",
    ")\n",
    "header_length_prefix = \"application/vnd.sagemaker-triton.binary+json;json-header-size=\"\n",
    "header_length_str = response_invoke[\"ContentType\"][len(header_length_prefix) :]\n",
    "if not header_length_str:\n",
    "        header_length_str='0'\n",
    "#result = httpclient.InferenceServerClient.parse_response_body(response_invoke[\"Body\"].read())\n",
    "#result\n",
    "binary_response = response_invoke[\"Body\"].read()\n",
    "binary_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"model_name\":\"d85097bca17a6d3758be38f49b039fe3\",\"model_version\":\"1\",\"outputs\":[{\"name\":\"OUTPUT__0\",\"datatype\":\"FP32\",\"shape\":[1,0,1,4],\"parameters\":{\"binary_data_size\":0}},{\"name\":\"OUTPUT__1\",\"datatype\":\"INT64\",\"shape\":[1,0,1],\"parameters\":{\"binary_data_size\":0}},{\"name\":\"OUTPUT__2\",\"datatype\":\"FP32\",\"shape\":[1,0,1],\"parameters\":{\"binary_data_size\":0}}]}'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tritonclient.http.InferResult at 0x7f6fce97f890>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "httpclient.InferenceServerClient.parse_response_body(binary_response, verbose=True, content_encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_uri='s3://sagemaker-eu-west-1-225730023796/temp_model/model.tar.gz'\n",
    "mme_path='s3://sagemaker-eu-west-1-225730023796/temp_model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'resnet-fpn-v2-2022-11-25-19-22-56-057'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "#m_name =  name_from_base(f\"{model_uri.rsplit('/')[-2]}\")\n",
    "m_name =  name_from_base(f\"resnet-fpn-v2\")\n",
    "\n",
    "m_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet-fpn-v2-2022-11-25-19-22-56-057\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'temp_model'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(m_name)\n",
    "model_uri.rsplit('/')[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "802834080501.dkr.ecr.eu-west-1.amazonaws.com/sagemaker-tritonserver:22.08-py3\n",
      "{'ModelArn': 'arn:aws:sagemaker:eu-west-1:225730023796:model/resnet-fpn-v2-2022-11-25-19-22-56-057', 'ResponseMetadata': {'RequestId': '9292f038-8541-4bd4-9a7c-5b737a0da87e', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '9292f038-8541-4bd4-9a7c-5b737a0da87e', 'content-type': 'application/x-amz-json-1.1', 'content-length': '99', 'date': 'Fri, 25 Nov 2022 19:23:08 GMT'}, 'RetryAttempts': 0}}\n",
      "{'EndpointConfigArn': 'arn:aws:sagemaker:eu-west-1:225730023796:endpoint-config/resnet-fpn-v2-2022-11-25-19-22-56-057', 'ResponseMetadata': {'RequestId': 'e7735e1d-c6c4-482d-a2dc-cbfc213bfc0d', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'e7735e1d-c6c4-482d-a2dc-cbfc213bfc0d', 'content-type': 'application/x-amz-json-1.1', 'content-length': '118', 'date': 'Fri, 25 Nov 2022 19:23:08 GMT'}, 'RetryAttempts': 0}}\n",
      "{'EndpointArn': 'arn:aws:sagemaker:eu-west-1:225730023796:endpoint/resnet-fpn-v2-2022-11-25-19-22-56-057', 'ResponseMetadata': {'RequestId': 'f3ca662a-a0b4-4dc6-804a-03673c324d0e', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'f3ca662a-a0b4-4dc6-804a-03673c324d0e', 'content-type': 'application/x-amz-json-1.1', 'content-length': '105', 'date': 'Fri, 25 Nov 2022 19:23:08 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "#m_name = model_uri.rsplit(\"/\")[-2] \n",
    "\n",
    "region = boto3.Session().region_name\n",
    "image_account = '802834080501' # eu-west-1\n",
    "base = \"amazonaws.com\"\n",
    "\n",
    "#- {account_id}.dkr.ecr.{region}.{base}/sagemaker-tritonserver:22.07-py3\n",
    "mme_triton_image_uri = (\n",
    "    \"{account_id}.dkr.ecr.{region}.{base}/sagemaker-tritonserver:22.08-py3\".format(\n",
    "        account_id=image_account, region=region, base=base\n",
    "    )\n",
    ")\n",
    "triton_image_uri = mme_triton_image_uri\n",
    "\n",
    "print(triton_image_uri)\n",
    "\n",
    "\n",
    "container = {\n",
    "    \"Image\": triton_image_uri, # \"763104351884.dkr.ecr.eu-west-1.amazonaws.com/sagemaker-tritonserver:22.07-py3\", # \"785573368785.dkr.ecr.us-east-1.amazonaws.com/sagemaker-tritonserver:22.09-py3\",\n",
    "    \"ModelDataUrl\": mme_path, # model_uri,\n",
    "    \"Mode\": \"MultiModel\",\n",
    "    \"Environment\": {\n",
    "        #\"SAGEMAKER_TRITON_DEFAULT_MODEL_NAME\": \"resnet_fpn_v2\",\n",
    "        \"SAGEMAKER_TRITON_THREAD_COUNT\": \"10\", #\"200\",\n",
    "        \"SAGEMAKER_TRITON_BUFFER_MANAGER_THREAD_COUNT\": \"5\", #\"10\"\n",
    "        #\"SAGEMAKER_TRITON_SHM_DEFAULT_BYTE_SIZE\" : \"20000000\", #\"1677721600\", #\"16777216000\", \"16777216\"\n",
    "        #\"SAGEMAKER_TRITON_SHM_GROWTH_BYTE_SIZE\": \"1048576\"\n",
    "\n",
    "    },\n",
    "}\n",
    "sm_client = boto3.client(service_name=\"sagemaker\")\n",
    "try:\n",
    "    create_model_response = sm_client.create_model(\n",
    "        ModelName=m_name , \n",
    "        ExecutionRoleArn=get_execution_role(), \n",
    "        PrimaryContainer=container\n",
    "    )\n",
    "    print(create_model_response)\n",
    "    \n",
    "    create_endpoint_config_response = sm_client.create_endpoint_config(\n",
    "        EndpointConfigName=m_name,\n",
    "        ProductionVariants=[\n",
    "            {\n",
    "                \"InstanceType\": \"ml.g4dn.2xlarge\",\n",
    "                \"InitialVariantWeight\": 1,\n",
    "                \"InitialInstanceCount\": 1,\n",
    "                \"ModelName\": m_name ,\n",
    "                \"VariantName\": \"AllTraffic\",\n",
    "            }\n",
    "        ],\n",
    "        )\n",
    "    print(create_endpoint_config_response)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\\n Trying to create endpoint\")\n",
    "\n",
    "\n",
    "\n",
    "response = sm_client.create_endpoint(\n",
    "    EndpointName=m_name ,\n",
    "    EndpointConfigName=m_name)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EndpointArn': 'arn:aws:sagemaker:eu-west-1:225730023796:endpoint/resnet-fpn-v2-2022-11-25-19-22-56-057',\n",
       " 'ResponseMetadata': {'RequestId': 'f3ca662a-a0b4-4dc6-804a-03673c324d0e',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'f3ca662a-a0b4-4dc6-804a-03673c324d0e',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '105',\n",
       "   'date': 'Fri, 25 Nov 2022 19:23:08 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_m_name = m_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SINGLE:Model:endpoint:Triton:Status: Creating\n",
      "Single:model:triton:Status: Creating\n",
      "Single:model:triton:Status: Creating\n",
      "Single:model:triton:Status: Creating\n",
      "Single:model:triton:Status: Creating\n",
      "Single:model:triton:Status: Creating\n",
      "Single:model:triton:Status: Creating\n",
      "Single:model:triton:Status: Creating\n",
      "Single:model:triton:Status: InService\n",
      "Arn: arn:aws:sagemaker:eu-west-1:225730023796:endpoint/resnet-fpn-v2-2022-11-25-19-22-56-057\n",
      "Single:model:triton:Status: InService\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "resp = sm_client.describe_endpoint(EndpointName=m_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"SINGLE:Model:endpoint:Triton:Status: \" + status)\n",
    "\n",
    "while status == \"Creating\":\n",
    "    time.sleep(30)\n",
    "    resp = sm_client.describe_endpoint(EndpointName=m_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "    print(\"Single:model:triton:Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp[\"EndpointArn\"])\n",
    "print(\"Single:model:triton:Status: \" + status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Clean up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1==2:\n",
    "    try:\n",
    "        sm_client.delete_endpoint(EndpointName=old_m_name)\n",
    "    except:\n",
    "        pass\n",
    "    sm_client.delete_endpoint_config(EndpointConfigName=old_m_name)\n",
    "    sm_client.delete_model(ModelName=old_m_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import concurrent.futures\n",
    "import tritonclient.http as httpclient\n",
    "from botocore.config import Config\n",
    "import numpy as np\n",
    "import random\n",
    "import boto3\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "w,h = 856,480\n",
    "\n",
    "urls = [\n",
    "    \"https://m.media-amazon.com/images/M/MV5BNDcwZDc2NTEtMzU0Ni00YTQyLWIyYTQtNTI3YjM0MzhmMmI4XkEyXkFqcGdeQXVyNTgyNTA4MjM@._V1_.jpg\",\n",
    "    \"https://lh3.googleusercontent.com/05JfZ1ZdyzrRNvhJosUFdcjjJRFE7k2KhmeM2ujqeCbrcrCb1hkq7O_JdUBpQ3r9hi0YeSn4WgmKx3Ai8LHdM2SucxSzl9TRZ4fCAqETJ6WtHgE=s0\",\n",
    "    \"https://assets.nintendo.com/image/upload/f_auto/q_auto/dpr_2.625/c_scale,w_400/ncom/en_US/games/switch/n/new-pokemon-snap-switch/hero\",\n",
    "    \"https://images.nintendolife.com/d358c9f9118af/pokemon-go.900x.jpg\",\n",
    "    \"https://cdn.vox-cdn.com/thumbor/IKt535q8LMnJDddmLL74TBtzv88=/0x266:1024x949/1280x854/cdn.vox-cdn.com/uploads/chorus_image/image/48942277/N3DS_PokemonSuperMysteryDungeon_MainIllustration_png_jpgcopy.0.0.jpg\",\n",
    "    \"https://i.imgflip.com/3sn9mp.jpg\",\n",
    "    \"https://techcrunch.com/wp-content/uploads/2017/08/cbsn.png\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "endpoint_name = m_name\n",
    "def read_image(i=0):\n",
    "    url = random.choice(urls)\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "\n",
    "    img = img.resize((w, h), Image.ANTIALIAS)\n",
    "    return np.asarray(img, dtype='uint8')\n",
    "\n",
    "def read_local_image(i=0,img_path='./shiba_inu_dog.jpg'):\n",
    "    img=Image.open(img_path)\n",
    "\n",
    "    img = img.resize((w, h), Image.ANTIALIAS)\n",
    "    return np.asarray(img, dtype='uint8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:41: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "batch_size = 12\n",
    "samples = 1\n",
    "buffer = []\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    images_future = [executor.submit(read_image, i) for i in range(samples*batch_size)]\n",
    "\n",
    "    for i, future in enumerate(concurrent.futures.as_completed(images_future)):\n",
    "        buffer.append(future.result())\n",
    "\n",
    "print(len(buffer))\n",
    "\n",
    "batch_size = 12\n",
    "samples = 1\n",
    "buffer_local = []\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    images_future = [executor.submit(read_local_image, i, './shiba_inu_dog.jpg') for i in range(samples*batch_size)]\n",
    "\n",
    "    for i, future in enumerate(concurrent.futures.as_completed(images_future)):\n",
    "        buffer_local.append(future.result())\n",
    "\n",
    "print(len(buffer_local))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480\n",
      "(12, 3, 480, 856)\n",
      "480\n",
      "(12, 3, 480, 856)\n"
     ]
    }
   ],
   "source": [
    "image_batch = np.asarray(buffer, dtype='uint8').transpose(0,3,1,2)  # -- 12 x 3 x 480 x 856 \n",
    "print(len(buffer[0]))\n",
    "print(image_batch.shape)\n",
    "\n",
    "image_batch_local = np.asarray(buffer_local, dtype='uint8').transpose(0,3,1,2)  # -- 12 x 3 x 480 x 856 \n",
    "print(len(buffer_local[0]))\n",
    "print(image_batch_local.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch Tensor manipulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 480, 856)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "image_batch_local[0].shape # - (3, 480, 856)\n",
    "torch.tensor(image_batch_local[0]).unsqueeze(0).shape # - (1, 3, 480, 856)\n",
    "\n",
    "print(torch.tensor(image_batch_local[0]).unsqueeze(0).numpy().shape) # - (1, 3, 480, 856) -- but is of type numpy\n",
    "print(type(torch.tensor(image_batch_local[0]).unsqueeze(0).numpy()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_endpoint(images,endpoint_name, target_model='model.tar.gz'): # - resnet_fpn_v3.tar.gz\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    input_data = images # np.asarray(images, dtype='uint8')  # passing in a numpy aray already \n",
    "    print(input_data.shape)\n",
    "    \n",
    "    #inputs.append(httpclient.InferInput(\"INPUT__0\", [ len(input_data),h, w,3], \"UINT8\"))\n",
    "    \n",
    "    inputs = [httpclient.InferInput(\"INPUT__0\", images.shape, \"UINT8\")]\n",
    "    inputs[0].set_data_from_numpy(images, binary_data=True)\n",
    "    outputs = [httpclient.InferRequestedOutput(f\"OUTPUT__{n}\", binary_data=True) for n in range(3)]\n",
    "    \n",
    "    request_body, header_length = httpclient.InferenceServerClient.generate_request_body(\n",
    "        inputs, outputs=outputs\n",
    "    )\n",
    "\n",
    "\n",
    "    runtime_sm_client = boto3.client(\n",
    "        \"sagemaker-runtime\",\n",
    "        region_name=\"eu-west-1\", \n",
    "        config=Config(\n",
    "            connect_timeout=5,\n",
    "            read_timeout=60, #120,\n",
    "            retries={'max_attempts': 2,'mode': 'standard'} #20\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    response = runtime_sm_client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        ContentType=\"application/vnd.sagemaker-triton.binary+json;json-header-size={}\".format(\n",
    "            header_length\n",
    "        ),\n",
    "        Body=request_body,\n",
    "        TargetModel=target_model,\n",
    "        \n",
    "    )\n",
    "    header_length_prefix = \"application/vnd.sagemaker-triton.binary+json;json-header-size=\"\n",
    "    header_length_str = response[\"ContentType\"][len(header_length_prefix) :]\n",
    "    if not header_length_str:\n",
    "        header_length_str='0'\n",
    "    result = httpclient.InferenceServerClient.parse_response_body(response[\"Body\"].read())\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480\n",
      "(12, 3, 480, 856)\n",
      "12 9.515902280807495\n",
      "Test finished for 1 batch of 12 images::result=<tritonclient.http.InferResult object at 0x7f6fcdc1cd90>::\n"
     ]
    }
   ],
   "source": [
    "print(len(buffer[0]))\n",
    "st_time = time.time()\n",
    "#result = invoke_endpoint(buffer, m_name)\n",
    "result = invoke_endpoint(image_batch_local, m_name, 'jit-resnet-v2-model.tar.gz') #'model.tar.gz') # 'resnet_fpn_v2.tar.gz' # - 'jit-resnet-v5-model.tar.gz' ) # passing in a numpy aray already \n",
    "print(len(buffer),time.time() - st_time)\n",
    "print(f\"Test finished for 1 batch of {batch_size} images::result={result}::\")\n",
    "            \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each:output:{'name': 'OUTPUT__0', 'datatype': 'FP32', 'shape': [12, 0, 4], 'parameters': {'binary_data_size': 0}}\n",
      "Values:output:[] \n",
      "\n",
      "Each:output:{'name': 'OUTPUT__1', 'datatype': 'INT64', 'shape': [12, 0], 'parameters': {'binary_data_size': 0}}\n",
      "Values:output:[] \n",
      "\n",
      "Each:output:{'name': 'OUTPUT__2', 'datatype': 'FP32', 'shape': [12, 0], 'parameters': {'binary_data_size': 0}}\n",
      "Values:output:[] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_outputs = result.get_response()['outputs']\n",
    "for single_output in result_outputs:\n",
    "    print(f\"Each:output:{single_output}\")\n",
    "    print(f\"Values:output:{result.as_numpy(single_output['name'])} \\n\")\n",
    "    \n",
    "# - 'shape': [12, 0, 4], 'parameters': {'binary_data_size': 0}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting invocation for model:: please wait ...\n",
      "\n",
      "Predictions for model latency: \n",
      "\n",
      "\n",
      "P95: 1914.787781238556 ms\n",
      "\n",
      "P90: 1897.0021724700928 ms\n",
      "\n",
      "Average: 1874.2761421203613 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Starting invocation for model:: please wait ...\")\n",
    "results = []\n",
    "for i in range(0, 50):\n",
    "    start = time.time()\n",
    "    invoke_endpoint(buffer, m_name)\n",
    "    results.append((time.time() - start) * 1000)\n",
    "print(\"\\nPredictions for model latency: \\n\")\n",
    "print(\"\\nP95: \" + str(np.percentile(results, 95)) + \" ms\\n\")\n",
    "print(\"P90: \" + str(np.percentile(results, 90)) + \" ms\\n\")\n",
    "print(\"Average: \" + str(np.average(results)) + \" ms\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions for model latency: \n",
      "\n",
      "\n",
      "P95: 1914.787781238556 ms\n",
      "\n",
      "P90: 1897.0021724700928 ms\n",
      "\n",
      "Average: 1874.2761421203613 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPredictions for model latency: \\n\")\n",
    "print(\"\\nP95: \" + str(np.percentile(results, 95)) + \" ms\\n\")\n",
    "print(\"P90: \" + str(np.percentile(results, 90)) + \" ms\\n\")\n",
    "print(\"Average: \" + str(np.average(results)) + \" ms\\n\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " 4 -- > 8  -- 125 ms\n",
    "8 -- > 14   --  400 ms\n",
    "13 --- > 26  -- 400 ms \n",
    "        \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_path = \"jit-resnet-v2-model\"\n",
    "\n",
    "output_filename = f\"model.tar.gz\"\n",
    "with tarfile.open(output_filename, \"w:gz\") as tar:\n",
    "    tar.add(model_path, arcname=model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m_name='time-od-model-2022-11-22-22-56-24-328'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time-od-model-2022-11-23-06-58-07-449\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from multiprocessing import cpu_count\n",
    "print(m_name)\n",
    "cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import traceback\n",
    "def run_worker(proc_id):\n",
    "    #print(\"Starting invocation for model:: please wait ...\")\n",
    "    start_worker = time.time()\n",
    "    results = [0]\n",
    "    error_count = 0\n",
    "    total_count = 0\n",
    "    \n",
    "    while ( (time.time() - start_worker) < 180 ) : # -- 300 sec  -- 1 hour 3600    2 hour 7200 is 4 is 14400 \n",
    "        start = time.time()\n",
    "        try:\n",
    "            total_count = total_count + 1\n",
    "            invoke_endpoint(buffer, m_name)\n",
    "            results.append((time.time() - start) * 1000)\n",
    "        except:\n",
    "            #print(traceback.format_exc())\n",
    "            error_count = error_count + 1\n",
    "            time.sleep(0.05)\n",
    "            \n",
    "        \n",
    "        \n",
    "    print(f\"{np.percentile(results, 95)} ms:total_success_count={total_count}::error_count={error_count}::\")\n",
    "    return f\"{np.percentile(results, 95)} ms:total_success_count={total_count}::error_count={error_count}::\"\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max_A-Sync:processes=45\n"
     ]
    }
   ],
   "source": [
    "# create a process pool\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "max_workers_cpu = 45 #cpu_count() # -*2\n",
    "print(f\"Max_A-Sync:processes={max_workers_cpu}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use a Thread Pool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "37972.13671207428 ms:total_success_count=46::error_count=45::\n",
      "42923.21339845657 ms:total_success_count=48::error_count=47::\n",
      "0.0 ms:total_success_count=42::error_count=42::\n",
      "0.0 ms:total_success_count=41::error_count=41::\n",
      "47835.4568362236 ms:total_success_count=47::error_count=46::\n",
      "0.0 ms:total_success_count=44::error_count=44::\n",
      "57578.9089679718 ms:total_success_count=45::error_count=44::\n",
      "18160.48011779785 ms:total_success_count=46::error_count=45::\n",
      "13640.869450569153 ms:total_success_count=45::error_count=44::\n",
      "28061.84641122818 ms:total_success_count=46::error_count=45::\n",
      "27536.960530281067 ms:total_success_count=44::error_count=43::\n",
      "23365.378677845 ms:total_success_count=42::error_count=41::\n",
      "27590.657460689545 ms:total_success_count=45::error_count=44::\n",
      "22840.94465970993 ms:total_success_count=48::error_count=47::\n",
      "37384.10577774048 ms:total_success_count=41::error_count=40::\n",
      "33125.83919763565 ms:total_success_count=42::error_count=41::\n",
      "42899.2857336998 ms:total_success_count=46::error_count=45::\n",
      "37991.906559467316 ms:total_success_count=44::error_count=43::\n",
      "42493.57023239136 ms:total_success_count=44::error_count=43::\n",
      "52383.88842344284 ms:total_success_count=46::error_count=45::\n",
      "47872.37482070923 ms:total_success_count=46::error_count=45::\n",
      "47736.61530017853 ms:total_success_count=45::error_count=44::\n",
      "0.0 ms:total_success_count=45::error_count=45::\n",
      "57192.821526527405 ms:total_success_count=46::error_count=45::\n",
      "0.0 ms:total_success_count=46::error_count=46::\n",
      "2527.402114868164 ms:total_success_count=45::error_count=44::\n",
      "0.0 ms:total_success_count=44::error_count=44::\n",
      "57709.971606731415 ms:total_success_count=50::error_count=49::\n",
      "52568.76599788666 ms:total_success_count=47::error_count=46::\n",
      "8823.63430261612 ms:total_success_count=49::error_count=48::\n",
      "18492.845940589905 ms:total_success_count=46::error_count=45::\n",
      "13640.643179416656 ms:total_success_count=46::error_count=45::\n",
      "23234.603238105774 ms:total_success_count=47::error_count=46::\n",
      "18123.791575431824 ms:total_success_count=48::error_count=47::\n",
      "32397.013473510742 ms:total_success_count=48::error_count=47::\n",
      "33078.77502441406 ms:total_success_count=46::error_count=45::\n",
      "52116.3235783577 ms:total_success_count=46::error_count=45::\n",
      "0.0 ms:total_success_count=43::error_count=43::\n",
      "0.0 ms:total_success_count=43::error_count=43::\n",
      "0.0 ms:total_success_count=43::error_count=43::\n",
      "0.0 ms:total_success_count=46::error_count=46::\n",
      "8874.015986919403 ms:total_success_count=47::error_count=46::\n",
      "4337.007129192352 ms:total_success_count=45::error_count=44::\n",
      "8843.750011920929 ms:total_success_count=46::error_count=45::\n",
      "13669.582104682922 ms:total_success_count=53::error_count=52::\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result_pool_list = []\n",
    "print(max_workers_cpu)\n",
    "with ThreadPoolExecutor(max_workers=(max_workers_cpu+10)) as pool:\n",
    "# call a function \n",
    "    for worker in range(max_workers_cpu) :\n",
    "        result_p = pool.submit(run_worker, worker )\n",
    "        result_pool_list.append(result_p)\n",
    "    \n",
    "    for result_p in result_pool_list:\n",
    "        result_p.result() # blocks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use a Multi Process Pool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "0.0 ms:total_success_count=1::error_count=1::\n",
      "0.0 ms:total_success_count=1::error_count=1::\n",
      "0.0 ms:total_success_count=1::error_count=1::\n",
      "0.0 ms:total_success_count=1::error_count=1::\n",
      "0.0 ms:total_success_count=1::error_count=1::\n",
      "0.0 ms:total_success_count=1::error_count=1::\n",
      "0.0 ms:total_success_count=1::error_count=1::\n",
      "0.0 ms:total_success_count=1::error_count=1::\n",
      "0.0 ms:total_success_count=1::error_count=1::\n",
      "0.0 ms:total_success_count=1::error_count=1::\n",
      "0.0 ms:total_success_count=1::error_count=1::\n",
      "0.0 ms:total_success_count=1::error_count=1::\n",
      "5175.184786319733 ms:total_success_count=2::error_count=1::\n",
      "5132.3278069496155 ms:total_success_count=2::error_count=1::\n",
      "5136.127984523773 ms:total_success_count=2::error_count=1::\n",
      "10011.859548091888 ms:total_success_count=2::error_count=1::\n",
      "9993.257522583008 ms:total_success_count=2::error_count=1::\n",
      "9991.812241077423 ms:total_success_count=2::error_count=1::\n",
      "14862.797772884369 ms:total_success_count=2::error_count=1::\n",
      "14865.903055667877 ms:total_success_count=2::error_count=1::\n",
      "14859.282302856445 ms:total_success_count=2::error_count=1::\n",
      "19772.33682870865 ms:total_success_count=2::error_count=1::\n",
      "19767.80710220337 ms:total_success_count=2::error_count=1::\n",
      "19779.565727710724 ms:total_success_count=2::error_count=1::\n",
      "24694.316720962524 ms:total_success_count=2::error_count=1::\n",
      "24697.391200065613 ms:total_success_count=2::error_count=1::\n",
      "24697.967863082886 ms:total_success_count=2::error_count=1::\n",
      "29638.448309898376 ms:total_success_count=2::error_count=1::\n",
      "29630.255663394928 ms:total_success_count=2::error_count=1::\n",
      "29651.420962810516 ms:total_success_count=2::error_count=1::\n",
      "34540.96978902817 ms:total_success_count=2::error_count=1::\n",
      "34547.10764884949 ms:total_success_count=2::error_count=1::\n",
      "34550.88517665863 ms:total_success_count=2::error_count=1::\n",
      "39504.92671728134 ms:total_success_count=2::error_count=1::\n",
      "39495.238506793976 ms:total_success_count=2::error_count=1::\n",
      "39491.46890640259 ms:total_success_count=3::error_count=2::\n",
      "44460.71251630783 ms:total_success_count=2::error_count=1::\n",
      "44447.95254468918 ms:total_success_count=2::error_count=1::\n",
      "44450.71853399277 ms:total_success_count=2::error_count=1::\n",
      "49429.46575880051 ms:total_success_count=2::error_count=1::\n",
      "49441.632306575775 ms:total_success_count=2::error_count=1::\n",
      "49423.39879274368 ms:total_success_count=2::error_count=1::\n",
      "54423.32422733307 ms:total_success_count=2::error_count=1::\n",
      "54431.761944293976 ms:total_success_count=2::error_count=1::\n",
      "54421.00172042847 ms:total_success_count=2::error_count=1::\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#with ProcessPoolExecutor(max_workers=max_workers_cpu) as executor:\n",
    "result_pool_list = []\n",
    "print(max_workers_cpu)\n",
    "result_list = []\n",
    "def async_call_back(result):\n",
    "    result_list.append(result)  \n",
    "    \n",
    "with Pool(processes=max_workers_cpu) as pool:\n",
    "# call a function \n",
    "    for worker in range(max_workers_cpu) :\n",
    "        result_p = pool.apply_async(func=run_worker, args=(worker,) , callback = async_call_back)\n",
    "        result_pool_list.append(result_p)\n",
    "    \n",
    "    for result_p in result_pool_list:\n",
    "        result_p.wait()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.0 ms:total_success_count=1::error_count=1::',\n",
       " '0.0 ms:total_success_count=1::error_count=1::',\n",
       " '0.0 ms:total_success_count=1::error_count=1::',\n",
       " '0.0 ms:total_success_count=1::error_count=1::',\n",
       " '0.0 ms:total_success_count=1::error_count=1::',\n",
       " '0.0 ms:total_success_count=1::error_count=1::',\n",
       " '0.0 ms:total_success_count=1::error_count=1::',\n",
       " '0.0 ms:total_success_count=1::error_count=1::',\n",
       " '0.0 ms:total_success_count=1::error_count=1::',\n",
       " '0.0 ms:total_success_count=1::error_count=1::',\n",
       " '0.0 ms:total_success_count=1::error_count=1::',\n",
       " '0.0 ms:total_success_count=1::error_count=1::',\n",
       " '5175.184786319733 ms:total_success_count=2::error_count=1::',\n",
       " '5132.3278069496155 ms:total_success_count=2::error_count=1::',\n",
       " '5136.127984523773 ms:total_success_count=2::error_count=1::',\n",
       " '10011.859548091888 ms:total_success_count=2::error_count=1::',\n",
       " '9993.257522583008 ms:total_success_count=2::error_count=1::',\n",
       " '9991.812241077423 ms:total_success_count=2::error_count=1::',\n",
       " '14862.797772884369 ms:total_success_count=2::error_count=1::',\n",
       " '14865.903055667877 ms:total_success_count=2::error_count=1::',\n",
       " '14859.282302856445 ms:total_success_count=2::error_count=1::',\n",
       " '19772.33682870865 ms:total_success_count=2::error_count=1::',\n",
       " '19767.80710220337 ms:total_success_count=2::error_count=1::',\n",
       " '19779.565727710724 ms:total_success_count=2::error_count=1::',\n",
       " '24694.316720962524 ms:total_success_count=2::error_count=1::',\n",
       " '24697.391200065613 ms:total_success_count=2::error_count=1::',\n",
       " '24697.967863082886 ms:total_success_count=2::error_count=1::',\n",
       " '29638.448309898376 ms:total_success_count=2::error_count=1::',\n",
       " '29630.255663394928 ms:total_success_count=2::error_count=1::',\n",
       " '29651.420962810516 ms:total_success_count=2::error_count=1::',\n",
       " '34540.96978902817 ms:total_success_count=2::error_count=1::',\n",
       " '34547.10764884949 ms:total_success_count=2::error_count=1::',\n",
       " '34550.88517665863 ms:total_success_count=2::error_count=1::',\n",
       " '39504.92671728134 ms:total_success_count=2::error_count=1::',\n",
       " '39495.238506793976 ms:total_success_count=2::error_count=1::',\n",
       " '39491.46890640259 ms:total_success_count=3::error_count=2::',\n",
       " '44460.71251630783 ms:total_success_count=2::error_count=1::',\n",
       " '44447.95254468918 ms:total_success_count=2::error_count=1::',\n",
       " '44450.71853399277 ms:total_success_count=2::error_count=1::',\n",
       " '49429.46575880051 ms:total_success_count=2::error_count=1::',\n",
       " '49441.632306575775 ms:total_success_count=2::error_count=1::',\n",
       " '49423.39879274368 ms:total_success_count=2::error_count=1::',\n",
       " '54423.32422733307 ms:total_success_count=2::error_count=1::',\n",
       " '54431.761944293976 ms:total_success_count=2::error_count=1::',\n",
       " '54421.00172042847 ms:total_success_count=2::error_count=1::']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '6a237969-ddc1-4e5a-9639-05e765beb30e',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '6a237969-ddc1-4e5a-9639-05e765beb30e',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Thu, 24 Nov 2022 01:10:11 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_client = boto3.client(service_name=\"sagemaker\")\n",
    "try:\n",
    "    sm_client.delete_endpoint(EndpointName=old_m_name)\n",
    "except:\n",
    "    pass\n",
    "sm_client.delete_endpoint_config(EndpointConfigName=old_m_name)\n",
    "sm_client.delete_model(ModelName=old_m_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End timings test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Image reading #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "s3_client.download_file(\n",
    "    \"sagemaker-sample-files\",\n",
    "    \"datasets/image/pets/shiba_inu_dog.jpg\",\n",
    "    \"shiba_inu_dog.jpg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tritonclient.http as httpclient\n",
    "\n",
    "def get_sample_image():\n",
    "    image_path = \"./shiba_inu_dog.jpg\"\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    img = img.resize((224, 224))\n",
    "    img = (np.array(img).astype(np.float32) / 255) - np.array(\n",
    "        [0.485, 0.456, 0.406], dtype=np.float32\n",
    "    ).reshape(1, 1, 3)\n",
    "    img = img / np.array([0.229, 0.224, 0.225], dtype=np.float32).reshape(1, 1, 3)\n",
    "    img = np.transpose(img, (2, 0, 1))\n",
    "    return img.tolist()\n",
    "\n",
    "def _get_sample_image_binary(input_name, output_name):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    inputs.append(httpclient.InferInput(input_name, [1, 3, 224, 224], \"FP32\"))\n",
    "    input_data = np.array(get_sample_image(), dtype=np.float32)\n",
    "    input_data = np.expand_dims(input_data, axis=0)\n",
    "    inputs[0].set_data_from_numpy(input_data, binary_data=True)\n",
    "    outputs.append(httpclient.InferRequestedOutput(output_name, binary_data=True))\n",
    "    request_body, header_length = httpclient.InferenceServerClient.generate_request_body(\n",
    "        inputs, outputs=outputs\n",
    "    )\n",
    "    return request_body, header_length\n",
    "\n",
    "\n",
    "def get_sample_image_binary_pt():\n",
    "    return _get_sample_image_binary(\"INPUT__0\", \"OUTPUT__0\")\n",
    "\n",
    "\n",
    "def get_sample_image_binary_trt():\n",
    "    return _get_sample_image_binary(\"input\", \"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "(3, 224, 224)\n",
      "<class 'numpy.ndarray'>\n",
      "0.2281874\n",
      "1\n",
      "(1, 3, 224, 224)\n",
      "<class 'numpy.ndarray'>\n",
      "0.2281874\n",
      "Trying triton http now \n",
      "\n",
      "1\n",
      "[1, 3, 224, 224]\n",
      "<class 'tritonclient.http.InferInput'>\n"
     ]
    }
   ],
   "source": [
    "input_data = np.array(get_sample_image(), dtype=np.float32)\n",
    "print(len(input_data))\n",
    "print(input_data.shape)\n",
    "print(type(input_data))\n",
    "print(input_data[0][0][0]) # 3d array\n",
    "\n",
    "input_data = np.expand_dims(input_data, axis=0)\n",
    "print(len(input_data))\n",
    "print(input_data.shape)\n",
    "print(type(input_data))\n",
    "print(input_data[0][0][0][0]) # 4d array\n",
    "\n",
    "print(\"Trying triton http now \\n\")\n",
    "\n",
    "inputs = [httpclient.InferInput('INPUT_0', [1, 3, 224, 224], \"FP32\")]\n",
    "inputs[0].set_data_from_numpy(input_data, binary_data=True)\n",
    "print(len(inputs))\n",
    "print(inputs[0].shape())\n",
    "print(type(inputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'INPUT_0'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0].name()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "40 thread \n",
    "\n",
    "\n",
    "60494.8188662529 ms:error_couent=119::\n",
    "60501.49495601654 ms:error_couent=122::\n",
    "60504.80670928955 ms:error_couent=118::60500.69344043732 ms:error_couent=125::\n",
    "\n",
    "60501.19564533234 ms:error_couent=123::\n",
    "60601.40076875687 ms:error_couent=119::\n",
    "60500.27595758438 ms:error_couent=119::\n",
    "60500.24199485779 ms:error_couent=124::\n",
    "60499.51107501984 ms:error_couent=118::\n",
    "60402.58823633194 ms:error_couent=121::\n",
    "60500.8269071579 ms:error_couent=122::\n",
    "60499.69577789307 ms:error_couent=120::\n",
    "60498.582792282104 ms:error_couent=123::\n",
    "60499.849128723145 ms:error_couent=128::\n",
    "60501.443219184875 ms:error_couent=120::\n",
    "60437.96515464783 ms:error_couent=120::\n",
    "60500.91872215271 ms:error_couent=121::\n",
    "60500.19918680191 ms:error_couent=117::\n",
    "60410.552978515625 ms:error_couent=120::\n",
    "60401.99126005173 ms:error_couent=123::\n",
    "60499.58511590958 ms:error_couent=119::\n",
    "60433.92027616501 ms:error_couent=119::\n",
    "60436.97384595871 ms:error_couent=119::\n",
    "60497.71378040314 ms:error_couent=118::\n",
    "60418.481397628784 ms:error_couent=118::\n",
    "60485.846972465515 ms:error_couent=123::\n",
    "60500.067472457886 ms:error_couent=121::\n",
    "60500.14668703079 ms:error_couent=122::\n",
    "60500.003480911255 ms:error_couent=119::\n",
    "60484.963381290436 ms:error_couent=123::\n",
    "60540.757632255554 ms:error_couent=119::\n",
    "60499.60553646088 ms:error_couent=125::\n",
    "60500.55503845215 ms:error_couent=120::\n",
    "60670.3411579132 ms:error_couent=119::\n",
    "60499.88877773285 ms:error_couent=125::\n",
    "60500.92899799347 ms:error_couent=126::\n",
    "60500.97515583038 ms:error_couent=120::\n",
    "60474.3475317955 ms:error_couent=125::\n",
    "60498.09741973877 ms:error_couent=124::\n",
    "60500.036001205444 ms:error_couent=123::\n",
    "\n",
    "\n",
    "--- 64 mb ram\n",
    "3873.058319091797 ms:total_success_count=3142::error_count=3082::\n",
    "3995.848929882049 ms:total_success_count=3147::error_count=3084::\n",
    "3860.694599151611 ms:total_success_count=3167::error_count=3111::\n",
    "3971.38352394104 ms:total_success_count=3165::error_count=3107::\n",
    "3861.039972305298 ms:total_success_count=3161::error_count=3097::\n",
    "4042.149782180786 ms:total_success_count=3141::error_count=3071::\n",
    "3793.244242668152 ms:total_success_count=3155::error_count=3105::\n",
    "3901.5486240386963 ms:total_success_count=3146::error_count=3086::\n",
    "3858.2913875579834 ms:total_success_count=3150::error_count=3090::\n",
    "4076.584064960479 ms:total_success_count=3154::error_count=3095::\n",
    "3909.9523544311523 ms:total_success_count=3184::error_count=3132::\n",
    "3919.7354078292847 ms:total_success_count=3153::error_count=3091::\n",
    "3839.4670128822327 ms:total_success_count=3166::error_count=3115::\n",
    "3881.712830066681 ms:total_success_count=3159::error_count=3100::\n",
    "3897.6311683654785 ms:total_success_count=3143::error_count=3078::\n",
    "3981.3438415527344 ms:total_success_count=3158::error_count=3102::\n",
    "3841.4840579032902 ms:total_success_count=3145::error_count=3074::\n",
    "3881.956684589386 ms:total_success_count=3153::error_count=3090::\n",
    "3844.3567156791687 ms:total_success_count=3158::error_count=3099::\n",
    "3851.363253593445 ms:total_success_count=3166::error_count=3112::\n",
    "3862.6136898994446 ms:total_success_count=3174::error_count=3123::\n",
    "3946.8325376510616 ms:total_success_count=3167::error_count=3113::\n",
    "3875.19748210907 ms:total_success_count=3155::error_count=3093::\n",
    "3993.70025396347 ms:total_success_count=3117::error_count=3034::\n",
    "3826.9234657287598 ms:total_success_count=3160::error_count=3103::\n",
    "3847.1598625183105 ms:total_success_count=3152::error_count=3092::\n",
    "3898.604702949524 ms:total_success_count=3193::error_count=3139::\n",
    "3789.7624850273132 ms:total_success_count=3140::error_count=3073::\n",
    "3906.441307067871 ms:total_success_count=3142::error_count=3086::\n",
    "3815.5348300933833 ms:total_success_count=3152::error_count=3096::\n",
    "3899.8199582099915 ms:total_success_count=3135::error_count=3074::\n",
    "3909.6834659576416 ms:total_success_count=3165::error_count=3105::\n",
    "3843.332529067993 ms:total_success_count=3153::error_count=3098::\n",
    "3810.3576421737666 ms:total_success_count=3159::error_count=3110::\n",
    "3986.4603996276855 ms:total_success_count=3145::error_count=3081::\n",
    "4214.553785324097 ms:total_success_count=3166::error_count=3112::\n",
    "3846.240758895874 ms:total_success_count=3131::error_count=3055::\n",
    "3887.1116638183594 ms:total_success_count=3122::error_count=3047::\n",
    "3968.292546272278 ms:total_success_count=3153::error_count=3090::\n",
    "3848.508644104004 ms:total_success_count=3149::error_count=3087::\n",
    "3922.533369064331 ms:total_success_count=3163::error_count=3111::\n",
    "4564.949727058411 ms:total_success_count=3134::error_count=3067::\n",
    "3948.239576816559 ms:total_success_count=3165::error_count=3102::\n",
    "3858.3760738372803 ms:total_success_count=3148::error_count=3090::\n",
    "3958.6301088333125 ms:total_success_count=3147::error_count=3078::\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    images = read_image()\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    input_data = np.asarray(images, dtype='uint8')\n",
    "    inputs.append(httpclient.InferInput(\"INPUT__0\", [ len(input_data),h, w,3], \"UINT8\"))\n",
    "    inputs[0].set_data_from_numpy(input_data, binary_data=True)\n",
    "    outputs.append(httpclient.InferRequestedOutput(\"BBOX\", binary_data=True))\n",
    "    outputs.append(httpclient.InferRequestedOutput(\"LABELS\", binary_data=True))\n",
    "    outputs.append(httpclient.InferRequestedOutput(\"SCORES\", binary_data=True))\n",
    "    request_body, header_length = httpclient.InferenceServerClient.generate_request_body(\n",
    "        inputs, outputs=outputs\n",
    "    )\n",
    "\n",
    "\n",
    "    runtime_sm_client = boto3.client(\"sagemaker-runtime\",region_name=\"eu-west-1\", config=Config(connect_timeout=5,\n",
    "                                                                                 read_timeout=120,\n",
    "                                                                                 retries={\n",
    "                                                                                     'max_attempts': 20,\n",
    "                                                                                     'mode': 'standard'\n",
    "\n",
    "                                                                                 }))\n",
    "    response = runtime_sm_client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        ContentType=\"application/vnd.sagemaker-triton.binary+json;json-header-size={}\".format(\n",
    "            header_length\n",
    "        ),\n",
    "        Body=request_body,\n",
    "        \n",
    "    )\n",
    "    header_length_prefix = \"application/vnd.sagemaker-triton.binary+json;json-header-size=\"\n",
    "    header_length_str = response[\"ContentType\"][len(header_length_prefix) :]\n",
    "    result = httpclient.InferenceServerClient.parse_response_body(\n",
    "        response[\"Body\"].read(), \n",
    "        header_length=int(header_length_str)\n",
    "    )\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing preprocess.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocess.py\n",
    "\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import concurrent.futures\n",
    "import tritonclient.http as httpclient\n",
    "from botocore.config import Config\n",
    "import numpy as np\n",
    "import random\n",
    "import boto3\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "w,h = 856,480\n",
    "\n",
    "urls = [\n",
    "    \"https://m.media-amazon.com/images/M/MV5BNDcwZDc2NTEtMzU0Ni00YTQyLWIyYTQtNTI3YjM0MzhmMmI4XkEyXkFqcGdeQXVyNTgyNTA4MjM@._V1_.jpg\",\n",
    "    \"https://lh3.googleusercontent.com/05JfZ1ZdyzrRNvhJosUFdcjjJRFE7k2KhmeM2ujqeCbrcrCb1hkq7O_JdUBpQ3r9hi0YeSn4WgmKx3Ai8LHdM2SucxSzl9TRZ4fCAqETJ6WtHgE=s0\",\n",
    "    \"https://assets.nintendo.com/image/upload/f_auto/q_auto/dpr_2.625/c_scale,w_400/ncom/en_US/games/switch/n/new-pokemon-snap-switch/hero\",\n",
    "    \"https://images.nintendolife.com/d358c9f9118af/pokemon-go.900x.jpg\",\n",
    "    \"https://cdn.vox-cdn.com/thumbor/IKt535q8LMnJDddmLL74TBtzv88=/0x266:1024x949/1280x854/cdn.vox-cdn.com/uploads/chorus_image/image/48942277/N3DS_PokemonSuperMysteryDungeon_MainIllustration_png_jpgcopy.0.0.jpg\",\n",
    "    \"https://i.imgflip.com/3sn9mp.jpg\",\n",
    "    \"https://techcrunch.com/wp-content/uploads/2017/08/cbsn.png\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "endpoint_name = \"od-load-test-model\"\n",
    "def read_image(i):\n",
    "    url = random.choice(urls)\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "\n",
    "    img = img.resize((w, h), Image.ANTIALIAS)\n",
    "    return np.asarray(img, dtype='uint8')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def invoke_endpoint(images):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    input_data = np.asarray(images, dtype='uint8')\n",
    "    inputs.append(httpclient.InferInput(\"INPUT__0\", [ len(input_data),h, w,3], \"UINT8\"))\n",
    "    inputs[0].set_data_from_numpy(input_data, binary_data=True)\n",
    "    outputs.append(httpclient.InferRequestedOutput(\"BBOX\", binary_data=True))\n",
    "    outputs.append(httpclient.InferRequestedOutput(\"LABELS\", binary_data=True))\n",
    "    outputs.append(httpclient.InferRequestedOutput(\"SCORES\", binary_data=True))\n",
    "    request_body, header_length = httpclient.InferenceServerClient.generate_request_body(\n",
    "        inputs, outputs=outputs\n",
    "    )\n",
    "\n",
    "\n",
    "    runtime_sm_client = boto3.client(\"sagemaker-runtime\",region_name=\"eu-west-1\", config=Config(connect_timeout=5,\n",
    "                                                                                 read_timeout=120,\n",
    "                                                                                 retries={\n",
    "                                                                                     'max_attempts': 20,\n",
    "                                                                                     'mode': 'standard'\n",
    "\n",
    "                                                                                 }))\n",
    "    response = runtime_sm_client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        ContentType=\"application/vnd.sagemaker-triton.binary+json;json-header-size={}\".format(\n",
    "            header_length\n",
    "        ),\n",
    "        Body=request_body,\n",
    "        \n",
    "    )\n",
    "    header_length_prefix = \"application/vnd.sagemaker-triton.binary+json;json-header-size=\"\n",
    "    header_length_str = response[\"ContentType\"][len(header_length_prefix) :]\n",
    "    result = httpclient.InferenceServerClient.parse_response_body(\n",
    "        response[\"Body\"].read(), \n",
    "        header_length=int(header_length_str)\n",
    "    )\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 12\n",
    "samples= 20\n",
    "\n",
    "def run():\n",
    "    j = 0 \n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        while j < 1000:\n",
    "            images_future = [executor.submit(read_image, i) for i in range(samples*batch_size)]\n",
    "            buffer = []\n",
    "            for i, future in enumerate(concurrent.futures.as_completed(images_future)):\n",
    "                buffer.append(future.result())\n",
    "                if len(buffer) >= batch_size:\n",
    "                    st_time = time.time()\n",
    "                    invoke_endpoint(buffer)\n",
    "                    print(len(buffer),time.time() - st_time)\n",
    "                    buffer.clear()\n",
    "            j+=1\n",
    "            \n",
    "\n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    print(\"start\")\n",
    "    run()\n",
    "    print(\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "FROM python:3.10.8-buster\n",
    "\n",
    "RUN pip install pillow tritonclient[\"http\"] numpy requests futures tqdm boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sagemaker-studio-image-build\n",
      "  Downloading sagemaker_studio_image_build-0.6.0.tar.gz (13 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: boto3<2.0,>=1.10.44 in /opt/conda/lib/python3.7/site-packages (from sagemaker-studio-image-build) (1.24.62)\n",
      "Requirement already satisfied: sagemaker<3.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker-studio-image-build) (2.107.0)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.62 in /opt/conda/lib/python3.7/site-packages (from boto3<2.0,>=1.10.44->sagemaker-studio-image-build) (1.27.62)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from boto3<2.0,>=1.10.44->sagemaker-studio-image-build) (0.6.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3<2.0,>=1.10.44->sagemaker-studio-image-build) (1.0.1)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.7/site-packages (from sagemaker<3.0->sagemaker-studio-image-build) (0.2.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker<3.0->sagemaker-studio-image-build) (20.1)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /opt/conda/lib/python3.7/site-packages (from sagemaker<3.0->sagemaker-studio-image-build) (0.1.5)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.7/site-packages (from sagemaker<3.0->sagemaker-studio-image-build) (1.0.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from sagemaker<3.0->sagemaker-studio-image-build) (1.3.5)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.7/site-packages (from sagemaker<3.0->sagemaker-studio-image-build) (0.2.0)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /opt/conda/lib/python3.7/site-packages (from sagemaker<3.0->sagemaker-studio-image-build) (3.20.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker<3.0->sagemaker-studio-image-build) (1.21.6)\n",
      "Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker<3.0->sagemaker-studio-image-build) (4.12.0)\n",
      "Requirement already satisfied: attrs<22,>=20.3.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker<3.0->sagemaker-studio-image-build) (21.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.7/site-packages (from botocore<1.28.0,>=1.27.62->boto3<2.0,>=1.10.44->sagemaker-studio-image-build) (1.26.12)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.28.0,>=1.27.62->boto3<2.0,>=1.10.44->sagemaker-studio-image-build) (2.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker<3.0->sagemaker-studio-image-build) (3.8.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker<3.0->sagemaker-studio-image-build) (4.3.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->sagemaker<3.0->sagemaker-studio-image-build) (1.14.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->sagemaker<3.0->sagemaker-studio-image-build) (2.4.6)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->sagemaker<3.0->sagemaker-studio-image-build) (2019.3)\n",
      "Requirement already satisfied: pox>=0.3.1 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker<3.0->sagemaker-studio-image-build) (0.3.1)\n",
      "Requirement already satisfied: ppft>=1.7.6.5 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker<3.0->sagemaker-studio-image-build) (1.7.6.5)\n",
      "Requirement already satisfied: multiprocess>=0.70.13 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker<3.0->sagemaker-studio-image-build) (0.70.13)\n",
      "Requirement already satisfied: dill>=0.3.5.1 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker<3.0->sagemaker-studio-image-build) (0.3.5.1)\n",
      "Building wheels for collected packages: sagemaker-studio-image-build\n",
      "  Building wheel for sagemaker-studio-image-build (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sagemaker-studio-image-build: filename=sagemaker_studio_image_build-0.6.0-py3-none-any.whl size=13469 sha256=7a6070e8d3c911d366460556304285e370236be25ba58439465ad9c81846b74e\n",
      "  Stored in directory: /root/.cache/pip/wheels/c1/9c/e8/cbf0266d9d9b1b6161f7ba9ddf572d02aacd411e8a5b4d186b\n",
      "Successfully built sagemaker-studio-image-build\n",
      "Installing collected packages: sagemaker-studio-image-build\n",
      "Successfully installed sagemaker-studio-image-build-0.6.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sagemaker-studio-image-build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...[Container] 2022/11/20 15:22:03 Waiting for agent ping\n",
      "\n",
      "[Container] 2022/11/20 15:22:04 Waiting for DOWNLOAD_SOURCE\n",
      "[Container] 2022/11/20 15:22:08 Phase is DOWNLOAD_SOURCE\n",
      "[Container] 2022/11/20 15:22:08 CODEBUILD_SRC_DIR=/codebuild/output/src144861214/src\n",
      "[Container] 2022/11/20 15:22:08 YAML location is /codebuild/output/src144861214/src/buildspec.yml\n",
      "[Container] 2022/11/20 15:22:08 Setting HTTP client timeout to higher timeout for S3 source\n",
      "[Container] 2022/11/20 15:22:08 Processing environment variables\n",
      "[Container] 2022/11/20 15:22:08 No runtime version selected in buildspec.\n",
      "[Container] 2022/11/20 15:22:08 Moving to directory /codebuild/output/src144861214/src\n",
      "[Container] 2022/11/20 15:22:08 Configuring ssm agent with target id: codebuild:58d545b4-55dc-467a-b0c4-930fd06071c5\n",
      "[Container] 2022/11/20 15:22:08 Successfully updated ssm agent configuration\n",
      "[Container] 2022/11/20 15:22:08 Registering with agent\n",
      "[Container] 2022/11/20 15:22:08 Phases found in YAML: 3\n",
      "[Container] 2022/11/20 15:22:08  PRE_BUILD: 9 commands\n",
      "[Container] 2022/11/20 15:22:08  BUILD: 4 commands\n",
      "[Container] 2022/11/20 15:22:08  POST_BUILD: 3 commands\n",
      "[Container] 2022/11/20 15:22:08 Phase complete: DOWNLOAD_SOURCE State: SUCCEEDED\n",
      "[Container] 2022/11/20 15:22:08 Phase context status code:  Message:\n",
      "[Container] 2022/11/20 15:22:08 Entering phase INSTALL\n",
      "[Container] 2022/11/20 15:22:08 Phase complete: INSTALL State: SUCCEEDED\n",
      "[Container] 2022/11/20 15:22:08 Phase context status code:  Message:\n",
      "[Container] 2022/11/20 15:22:08 Entering phase PRE_BUILD\n",
      "[Container] 2022/11/20 15:22:08 Running command echo Logging in to Amazon ECR...\n",
      "Logging in to Amazon ECR...\n",
      "\n",
      "[Container] 2022/11/20 15:22:08 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2022/11/20 15:22:21 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 763104351884)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2022/11/20 15:22:21 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 217643126080)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2022/11/20 15:22:22 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 727897471807)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2022/11/20 15:22:22 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 626614931356)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2022/11/20 15:22:23 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 683313688378)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2022/11/20 15:22:23 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 520713654638)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2022/11/20 15:22:24 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 462105765813)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2022/11/20 15:22:24 Phase complete: PRE_BUILD State: SUCCEEDED\n",
      "[Container] 2022/11/20 15:22:24 Phase context status code:  Message:\n",
      "[Container] 2022/11/20 15:22:24 Entering phase BUILD\n",
      "[Container] 2022/11/20 15:22:24 Running command echo Build started on `date`\n",
      "Build started on Sun Nov 20 15:22:24 UTC 2022\n",
      "\n",
      "[Container] 2022/11/20 15:22:24 Running command echo Building the Docker image...\n",
      "Building the Docker image...\n",
      "\n",
      "[Container] 2022/11/20 15:22:24 Running command docker build -t $IMAGE_REPO_NAME:$IMAGE_TAG .\n",
      "Sending build context to Docker daemon  136.7MB\n",
      "Step 1/2 : FROM python:3.10.8-buster\n",
      "3.10.8-buster: Pulling from library/python\n",
      "2730d739afad: Pulling fs layer\n",
      "a122751b3533: Pulling fs layer\n",
      "0a277c3efe7c: Pulling fs layer\n",
      "25c35b81c503: Pulling fs layer\n",
      "cb8cde86ddb2: Pulling fs layer\n",
      "3921145f3c18: Pulling fs layer\n",
      "39eac48b4a80: Pulling fs layer\n",
      "3033cd798920: Pulling fs layer\n",
      "d2f02b0e1c8b: Pulling fs layer\n",
      "3921145f3c18: Waiting\n",
      "39eac48b4a80: Waiting\n",
      "3033cd798920: Waiting\n",
      "d2f02b0e1c8b: Waiting\n",
      "25c35b81c503: Waiting\n",
      "cb8cde86ddb2: Waiting\n",
      "a122751b3533: Verifying Checksum\n",
      "a122751b3533: Download complete\n",
      "0a277c3efe7c: Verifying Checksum\n",
      "0a277c3efe7c: Download complete\n",
      "2730d739afad: Verifying Checksum\n",
      "2730d739afad: Download complete\n",
      "25c35b81c503: Verifying Checksum\n",
      "25c35b81c503: Download complete\n",
      "3921145f3c18: Verifying Checksum\n",
      "3921145f3c18: Download complete\n",
      "39eac48b4a80: Verifying Checksum\n",
      "39eac48b4a80: Download complete\n",
      "3033cd798920: Verifying Checksum\n",
      "3033cd798920: Download complete\n",
      "d2f02b0e1c8b: Verifying Checksum\n",
      "d2f02b0e1c8b: Download complete\n",
      "cb8cde86ddb2: Verifying Checksum\n",
      "cb8cde86ddb2: Download complete\n",
      "2730d739afad: Pull complete\n",
      "a122751b3533: Pull complete\n",
      "0a277c3efe7c: Pull complete\n",
      "25c35b81c503: Pull complete\n",
      "cb8cde86ddb2: Pull complete\n",
      "3921145f3c18: Pull complete\n",
      "39eac48b4a80: Pull complete\n",
      "3033cd798920: Pull complete\n",
      "d2f02b0e1c8b: Pull complete\n",
      "Digest: sha256:80755aa4f2a5b3a2c7ddc57e2a93406133a36070ca5621cac4ae802904475ca7\n",
      "Status: Downloaded newer image for python:3.10.8-buster\n",
      " ---> e9d407238827\n",
      "Step 2/2 : RUN pip install pillow tritonclient[\"http\"] numpy requests futures tqdm boto3\n",
      " ---> Running in 03d783c5dd57\n",
      "Collecting pillow\n",
      "  Downloading Pillow-9.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.3 MB)\n",
      "      3.3/3.3 MB 94.9 MB/s eta 0:00:00\n",
      "Collecting tritonclient[http]\n",
      "  Downloading tritonclient-2.27.0-py3-none-manylinux1_x86_64.whl (11.7 MB)\n",
      "      11.7/11.7 MB 115.3 MB/s eta 0:00:00\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "      17.1/17.1 MB 103.6 MB/s eta 0:00:00\n",
      "Collecting requests\n",
      "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "      62.8/62.8 kB 22.7 MB/s eta 0:00:00\n",
      "Collecting futures\n",
      "  Downloading futures-3.0.5.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "      78.5/78.5 kB 25.0 MB/s eta 0:00:00\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.26.13-py3-none-any.whl (132 kB)\n",
      "      132.5/132.5 kB 37.5 MB/s eta 0:00:00\n",
      "Collecting python-rapidjson>=0.9.1\n",
      "  Downloading python_rapidjson-1.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "      1.6/1.6 MB 127.0 MB/s eta 0:00:00\n",
      "Collecting geventhttpclient<=2.0.2,>=1.4.4\n",
      "  Downloading geventhttpclient-2.0.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (100 kB)\n",
      "      100.3/100.3 kB 29.9 MB/s eta 0:00:00\n",
      "Collecting aiohttp>=3.8.1\n",
      "  Downloading aiohttp-3.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "      1.0/1.0 MB 122.5 MB/s eta 0:00:00\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
      "      61.5/61.5 kB 23.9 MB/s eta 0:00:00\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
      "      140.4/140.4 kB 40.1 MB/s eta 0:00:00\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2022.9.24-py3-none-any.whl (161 kB)\n",
      "      161.1/161.1 kB 50.3 MB/s eta 0:00:00\n",
      "Collecting charset-normalizer<3,>=2\n",
      "  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "Collecting s3transfer<0.7.0,>=0.6.0\n",
      "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
      "      79.6/79.6 kB 24.9 MB/s eta 0:00:00\n",
      "Collecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting botocore<1.30.0,>=1.29.13\n",
      "  Downloading botocore-1.29.13-py3-none-any.whl (9.9 MB)\n",
      "      9.9/9.9 MB 137.6 MB/s eta 0:00:00\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
      "      149.6/149.6 kB 44.7 MB/s eta 0:00:00\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "      114.5/114.5 kB 37.3 MB/s eta 0:00:00\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (263 kB)\n",
      "      264.0/264.0 kB 65.1 MB/s eta 0:00:00\n",
      "Collecting attrs>=17.3.0\n",
      "  Downloading attrs-22.1.0-py2.py3-none-any.whl (58 kB)\n",
      "      58.8/58.8 kB 20.1 MB/s eta 0:00:00\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting python-dateutil<3.0.0,>=2.1\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "      247.7/247.7 kB 63.5 MB/s eta 0:00:00\n",
      "Collecting brotli\n",
      "  Downloading Brotli-1.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.7 MB)\n",
      "      2.7/2.7 MB 132.3 MB/s eta 0:00:00\n",
      "Collecting gevent>=0.13\n",
      "  Downloading gevent-22.10.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
      "      6.4/6.4 MB 103.6 MB/s eta 0:00:00\n",
      "Collecting six\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting zope.interface\n",
      "  Downloading zope.interface-5.5.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (258 kB)\n",
      "      258.9/258.9 kB 54.0 MB/s eta 0:00:00\n",
      "Collecting zope.event\n",
      "  Downloading zope.event-4.5.0-py2.py3-none-any.whl (6.8 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/site-packages (from gevent>=0.13->geventhttpclient<=2.0.2,>=1.4.4->tritonclient[http]) (63.2.0)\n",
      "Collecting greenlet>=2.0.0\n",
      "  Downloading greenlet-2.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (539 kB)\n",
      "      539.9/539.9 kB 78.2 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: futures\n",
      "  Building wheel for futures (setup.py): started\n",
      "  Building wheel for futures (setup.py): finished with status 'done'\n",
      "  Created wheel for futures: filename=futures-3.0.5-py3-none-any.whl size=14069 sha256=ca532d3e84db71790113c3be393de6ca8830e1a248a0721c522334fc800507b5\n",
      "  Stored in directory: /root/.cache/pip/wheels/ef/af/93/48739d464ba97d4cdc77c627d282f9794c8d276e42aaa92160\n",
      "Successfully built futures\n",
      "Installing collected packages: futures, brotli, zope.interface, zope.event, urllib3, tqdm, six, python-rapidjson, pillow, numpy, multidict, jmespath, idna, greenlet, frozenlist, charset-normalizer, certifi, attrs, async-timeout, yarl, tritonclient, requests, python-dateutil, gevent, aiosignal, geventhttpclient, botocore, aiohttp, s3transfer, boto3\n",
      "Successfully installed aiohttp-3.8.3 aiosignal-1.3.1 async-timeout-4.0.2 attrs-22.1.0 boto3-1.26.13 botocore-1.29.13 brotli-1.0.9 certifi-2022.9.24 charset-normalizer-2.1.1 frozenlist-1.3.3 futures-3.0.5 gevent-22.10.2 geventhttpclient-2.0.2 greenlet-2.0.1 idna-3.4 jmespath-1.0.1 multidict-6.0.2 numpy-1.23.5 pillow-9.3.0 python-dateutil-2.8.2 python-rapidjson-1.9 requests-2.28.1 s3transfer-0.6.0 six-1.16.0 tqdm-4.64.1 tritonclient-2.27.0 urllib3-1.26.12 yarl-1.8.1 zope.event-4.5.0 zope.interface-5.5.2\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\u001b[91m\n",
      "[notice] A new release of pip available: 22.2.2 -> 22.3.1\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "\u001b[0mRemoving intermediate container 03d783c5dd57\n",
      " ---> 2ba0a6f21fa7\n",
      "Successfully built 2ba0a6f21fa7\n",
      "Successfully tagged sagemaker-studio-d-gqidcsbwvhei:default-1663683956516\n",
      "\n",
      "[Container] 2022/11/20 15:23:00 Running command docker tag $IMAGE_REPO_NAME:$IMAGE_TAG $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
      "\n",
      "[Container] 2022/11/20 15:23:00 Phase complete: BUILD State: SUCCEEDED\n",
      "[Container] 2022/11/20 15:23:00 Phase context status code:  Message:\n",
      "[Container] 2022/11/20 15:23:00 Entering phase POST_BUILD\n",
      "[Container] 2022/11/20 15:23:00 Running command echo Build completed on `date`\n",
      "Build completed on Sun Nov 20 15:23:00 UTC 2022\n",
      "\n",
      "[Container] 2022/11/20 15:23:00 Running command echo Pushing the Docker image...\n",
      "Pushing the Docker image...\n",
      "\n",
      "[Container] 2022/11/20 15:23:00 Running command docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
      "The push refers to repository [225730023796.dkr.ecr.eu-west-1.amazonaws.com/sagemaker-studio-d-gqidcsbwvhei]\n",
      "461fea559e72: Preparing\n",
      "3d011be3d58f: Preparing\n",
      "f872162e70f3: Preparing\n",
      "0c35e033bcca: Preparing\n",
      "31b0e56b113e: Preparing\n",
      "371dda325867: Preparing\n",
      "381f4f0a6ea8: Preparing\n",
      "155c77c325cb: Preparing\n",
      "4d19f53ef378: Preparing\n",
      "d6dff9eed369: Preparing\n",
      "371dda325867: Waiting\n",
      "381f4f0a6ea8: Waiting\n",
      "155c77c325cb: Waiting\n",
      "4d19f53ef378: Waiting\n",
      "d6dff9eed369: Waiting\n",
      "f872162e70f3: Pushed\n",
      "3d011be3d58f: Pushed\n",
      "31b0e56b113e: Pushed\n",
      "0c35e033bcca: Pushed\n",
      "155c77c325cb: Pushed\n",
      "4d19f53ef378: Pushed\n",
      "381f4f0a6ea8: Pushed\n",
      "d6dff9eed369: Pushed\n",
      "461fea559e72: Pushed\n",
      "\n",
      "371dda325867: Pushed\n",
      "default-1663683956516: digest: sha256:c7b8348e89fc51ba3ed25c11ba2381141d3b8bb20a78ab55f6177fbc53629784 size: 2431\n",
      "\n",
      "[Container] 2022/11/20 15:23:39 Phase complete: POST_BUILD State: SUCCEEDED\n",
      "[Container] 2022/11/20 15:23:39 Phase context status code:  Message:\n",
      "Image URI: 225730023796.dkr.ecr.eu-west-1.amazonaws.com/sagemaker-studio-d-gqidcsbwvhei:default-1663683956516\n"
     ]
    }
   ],
   "source": [
    "!sm-docker build . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  loadt-test-endpoints-2022-11-20-15-25-09-036\n",
      "Inputs:  [{'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-eu-west-1-225730023796/loadt-test-endpoints-2022-11-20-15-25-09-036/input/code/preprocess.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  []\n",
      "......................................................\u001b[33m/opt/ml/processing/input/code/preprocess.py:36: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  img = img.resize((w, h), Image.ANTIALIAS)\u001b[0m\n",
      "\u001b[35m/opt/ml/processing/input/code/preprocess.py:36: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  img = img.resize((w, h), Image.ANTIALIAS)\u001b[0m\n",
      "\u001b[34m/opt/ml/processing/input/code/preprocess.py:36: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  img = img.resize((w, h), Image.ANTIALIAS)\u001b[0m\n",
      "\u001b[36m/opt/ml/processing/input/code/preprocess.py:36: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  img = img.resize((w, h), Image.ANTIALIAS)\u001b[0m\n",
      "\u001b[35m/opt/ml/processing/input/code/preprocess.py:36: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  img = img.resize((w, h), Image.ANTIALIAS)\u001b[0m\n",
      "\u001b[32m/opt/ml/processing/input/code/preprocess.py:36: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  img = img.resize((w, h), Image.ANTIALIAS)\u001b[0m\n",
      "\u001b[34m/opt/ml/processing/input/code/preprocess.py:36: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  img = img.resize((w, h), Image.ANTIALIAS)\u001b[0m\n",
      "\u001b[32m/opt/ml/processing/input/code/preprocess.py:36: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  img = img.resize((w, h), Image.ANTIALIAS)\u001b[0m\n",
      "\u001b[36m/opt/ml/processing/input/code/preprocess.py:36: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  img = img.resize((w, h), Image.ANTIALIAS)\u001b[0m\n",
      "\u001b[33m/opt/ml/processing/input/code/preprocess.py:36: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  img = img.resize((w, h), Image.ANTIALIAS)\u001b[0m\n",
      "\u001b[34mstart\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/ml/processing/input/code/preprocess.py\", line 103, in <module>\n",
      "    run()\n",
      "  File \"/opt/ml/processing/input/code/preprocess.py\", line 94, in run\n",
      "    invoke_endpoint(buffer)\n",
      "  File \"/opt/ml/processing/input/code/preprocess.py\", line 63, in invoke_endpoint\n",
      "    response = runtime_sm_client.invoke_endpoint(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/botocore/client.py\", line 515, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/botocore/client.py\", line 934, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\u001b[0m\n",
      "\u001b[34mbotocore.errorfactory.ValidationError: An error occurred (ValidationError) when calling the InvokeEndpoint operation: Endpoint od-load-test-model of account 225730023796 not found.\u001b[0m\n",
      "\u001b[33mstart\u001b[0m\n",
      "\u001b[33mTraceback (most recent call last):\n",
      "  File \"/opt/ml/processing/input/code/preprocess.py\", line 103, in <module>\n",
      "    run()\n",
      "  File \"/opt/ml/processing/input/code/preprocess.py\", line 94, in run\n",
      "    invoke_endpoint(buffer)\n",
      "  File \"/opt/ml/processing/input/code/preprocess.py\", line 63, in invoke_endpoint\n",
      "    response = runtime_sm_client.invoke_endpoint(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/botocore/client.py\", line 515, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/botocore/client.py\", line 934, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\u001b[0m\n",
      "\u001b[33mbotocore.errorfactory.ValidationError: An error occurred (ValidationError) when calling the InvokeEndpoint operation: Endpoint od-load-test-model of account 225730023796 not found.\u001b[0m\n",
      "\u001b[36mstart\u001b[0m\n",
      "\u001b[36mTraceback (most recent call last):\n",
      "  File \"/opt/ml/processing/input/code/preprocess.py\", line 103, in <module>\n",
      "    run()\n",
      "  File \"/opt/ml/processing/input/code/preprocess.py\", line 94, in run\n",
      "    invoke_endpoint(buffer)\n",
      "  File \"/opt/ml/processing/input/code/preprocess.py\", line 63, in invoke_endpoint\n",
      "    response = runtime_sm_client.invoke_endpoint(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/botocore/client.py\", line 515, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/botocore/client.py\", line 934, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\u001b[0m\n",
      "\u001b[36mbotocore.errorfactory.ValidationError: An error occurred (ValidationError) when calling the InvokeEndpoint operation: Endpoint od-load-test-model of account 225730023796 not found.\u001b[0m\n",
      "\u001b[32mstart\u001b[0m\n",
      "\u001b[32mTraceback (most recent call last):\n",
      "  File \"/opt/ml/processing/input/code/preprocess.py\", line 103, in <module>\n",
      "    run()\n",
      "  File \"/opt/ml/processing/input/code/preprocess.py\", line 94, in run\n",
      "    invoke_endpoint(buffer)\n",
      "  File \"/opt/ml/processing/input/code/preprocess.py\", line 63, in invoke_endpoint\n",
      "    response = runtime_sm_client.invoke_endpoint(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/botocore/client.py\", line 515, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/botocore/client.py\", line 934, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\u001b[0m\n",
      "\u001b[32mbotocore.errorfactory.ValidationError: An error occurred (ValidationError) when calling the InvokeEndpoint operation: Endpoint od-load-test-model of account 225730023796 not found.\u001b[0m\n",
      "\u001b[32mstart\u001b[0m\n",
      "\u001b[32mTraceback (most recent call last):\n",
      "  File \"/opt/ml/processing/input/code/preprocess.py\", line 103, in <module>\n",
      "    run()\n",
      "  File \"/opt/ml/processing/input/code/preprocess.py\", line 94, in run\n",
      "    invoke_endpoint(buffer)\n",
      "  File \"/opt/ml/processing/input/code/preprocess.py\", line 63, in invoke_endpoint\n",
      "    response = runtime_sm_client.invoke_endpoint(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/botocore/client.py\", line 515, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/botocore/client.py\", line 934, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\u001b[0m\n",
      "\u001b[32mbotocore.errorfactory.ValidationError: An error occurred (ValidationError) when calling the InvokeEndpoint operation: Endpoint od-load-test-model of account 225730023796 not found.\u001b[0m\n",
      "\n",
      "\u001b[36mstart\u001b[0m\n",
      "\u001b[36mTraceback (most recent call last):\n",
      "  File \"/opt/ml/processing/input/code/preprocess.py\", line 103, in <module>\n",
      "    run()\n",
      "  File \"/opt/ml/processing/input/code/preprocess.py\", line 94, in run\n",
      "    invoke_endpoint(buffer)\n",
      "  File \"/opt/ml/processing/input/code/preprocess.py\", line 63, in invoke_endpoint\n",
      "    response = runtime_sm_client.invoke_endpoint(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/botocore/client.py\", line 515, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/botocore/client.py\", line 934, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\u001b[0m\n",
      "\u001b[36mbotocore.errorfactory.ValidationError: An error occurred (ValidationError) when calling the InvokeEndpoint operation: Endpoint od-load-test-model of account 225730023796 not found.\u001b[0m\n",
      "\u001b[35mstart\u001b[0m\n",
      "\u001b[35mTraceback (most recent call last):\n",
      "  File \"/opt/ml/processing/input/code/preprocess.py\", line 103, in <module>\n",
      "    run()\n",
      "  File \"/opt/ml/processing/input/code/preprocess.py\", line 94, in run\n",
      "    invoke_endpoint(buffer)\n",
      "  File \"/opt/ml/processing/input/code/preprocess.py\", line 63, in invoke_endpoint\n",
      "    response = runtime_sm_client.invoke_endpoint(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/botocore/client.py\", line 515, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/botocore/client.py\", line 934, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\u001b[0m\n",
      "\u001b[35mbotocore.errorfactory.ValidationError: An error occurred (ValidationError) when calling the InvokeEndpoint operation: Endpoint od-load-test-model of account 225730023796 not found.\u001b[0m\n",
      "\u001b[33mTraceback (most recent call last):\n",
      "  File \"/opt/ml/processing/input/code/preprocess.py\", line 103, in <module>\u001b[0m\n",
      "\u001b[33mstart\n",
      "    run()\n",
      "  File \"/opt/ml/processing/input/code/preprocess.py\", line 94, in run\n",
      "    invoke_endpoint(buffer)\n",
      "  File \"/opt/ml/processing/input/code/preprocess.py\", line 63, in invoke_endpoint\n",
      "    response = runtime_sm_client.invoke_endpoint(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/botocore/client.py\", line 515, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/botocore/client.py\", line 934, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\u001b[0m\n",
      "\u001b[33mbotocore.errorfactory.ValidationError: An error occurred (ValidationError) when calling the InvokeEndpoint operation: Endpoint od-load-test-model of account 225730023796 not found.\u001b[0m\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Processing job loadt-test-endpoints-2022-11-20-15-25-09-036: Failed. Reason: AlgorithmError: See job logs for more information",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-0e4546a1a508>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mcode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"preprocess.py\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     logs=True)\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/workflow/pipeline_context.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrun_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/processing.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, code, inputs, outputs, arguments, wait, logs, job_name, experiment_config, kms_key)\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_include_code_in_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkms_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/processing.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \"\"\"\n\u001b[1;32m    985\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_processing_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_processing_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_processing_job\u001b[0;34m(self, job_name, wait, poll)\u001b[0m\n\u001b[1;32m   3941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3942\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3943\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ProcessingJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3944\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3945\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   3393\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3394\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3395\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3396\u001b[0m             )\n\u001b[1;32m   3397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Processing job loadt-test-endpoints-2022-11-20-15-25-09-036: Failed. Reason: AlgorithmError: See job logs for more information"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ScriptProcessor, ProcessingInput\n",
    "import sagemaker\n",
    "\n",
    "script_processor = ScriptProcessor(\n",
    "    base_job_name=\"loadt-test-endpoints\",\n",
    "    image_uri=\"225730023796.dkr.ecr.eu-west-1.amazonaws.com/sagemaker-studio-d-gqidcsbwvhei:default-1663683956516\", #\"423151156806.dkr.ecr.eu-west-1.amazonaws.com/sagemaker-studio-d-v8zfns8jon6p:aviad\",\n",
    "    command=[\"python3\"],\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    instance_count=10,\n",
    "    instance_type=\"ml.t3.medium\",\n",
    "    env={\"mode\": \"python\"},\n",
    ")\n",
    "\n",
    "\n",
    "script_processor.run(\n",
    "    code=\"preprocess.py\",\n",
    "    wait=True,\n",
    "    logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Collecting tritonclient[http]\n",
      "  Using cached tritonclient-2.27.0-py3-none-manylinux1_x86_64.whl (11.7 MB)\n",
      "Collecting python-rapidjson>=0.9.1\n",
      "  Using cached python_rapidjson-1.9-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "Requirement already satisfied: numpy>=1.19.1 in /opt/conda/lib/python3.7/site-packages (from tritonclient[http]) (1.21.6)\n",
      "Collecting geventhttpclient<=2.0.2,>=1.4.4\n",
      "  Using cached geventhttpclient-2.0.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (100 kB)\n",
      "Requirement already satisfied: aiohttp>=3.8.1 in /opt/conda/lib/python3.7/site-packages (from tritonclient[http]) (3.8.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp>=3.8.1->tritonclient[http]) (6.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp>=3.8.1->tritonclient[http]) (1.3.3)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp>=3.8.1->tritonclient[http]) (0.13.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp>=3.8.1->tritonclient[http]) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp>=3.8.1->tritonclient[http]) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp>=3.8.1->tritonclient[http]) (2.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp>=3.8.1->tritonclient[http]) (22.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp>=3.8.1->tritonclient[http]) (1.8.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from aiohttp>=3.8.1->tritonclient[http]) (4.4.0)\n",
      "Requirement already satisfied: gevent>=0.13 in /opt/conda/lib/python3.7/site-packages (from geventhttpclient<=2.0.2,>=1.4.4->tritonclient[http]) (1.4.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from geventhttpclient<=2.0.2,>=1.4.4->tritonclient[http]) (2022.9.24)\n",
      "Collecting brotli\n",
      "  Downloading Brotli-1.0.9-cp37-cp37m-manylinux1_x86_64.whl (357 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m357.2/357.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from geventhttpclient<=2.0.2,>=1.4.4->tritonclient[http]) (1.14.0)\n",
      "Requirement already satisfied: greenlet>=0.4.14 in /opt/conda/lib/python3.7/site-packages (from gevent>=0.13->geventhttpclient<=2.0.2,>=1.4.4->tritonclient[http]) (0.4.15)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.7/site-packages (from yarl<2.0,>=1.0->aiohttp>=3.8.1->tritonclient[http]) (2.8)\n",
      "Installing collected packages: brotli, python-rapidjson, tritonclient, geventhttpclient\n",
      "Successfully installed brotli-1.0.9 geventhttpclient-2.0.2 python-rapidjson-1.9 tritonclient-2.27.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tritonclient[http]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import concurrent.futures\n",
    "import tritonclient.http as httpclient\n",
    "from botocore.config import Config\n",
    "import numpy as np\n",
    "import random\n",
    "import boto3\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "w,h = 856,480\n",
    "\n",
    "urls = [\n",
    "    \"https://m.media-amazon.com/images/M/MV5BNDcwZDc2NTEtMzU0Ni00YTQyLWIyYTQtNTI3YjM0MzhmMmI4XkEyXkFqcGdeQXVyNTgyNTA4MjM@._V1_.jpg\",\n",
    "    \"https://lh3.googleusercontent.com/05JfZ1ZdyzrRNvhJosUFdcjjJRFE7k2KhmeM2ujqeCbrcrCb1hkq7O_JdUBpQ3r9hi0YeSn4WgmKx3Ai8LHdM2SucxSzl9TRZ4fCAqETJ6WtHgE=s0\",\n",
    "    \"https://assets.nintendo.com/image/upload/f_auto/q_auto/dpr_2.625/c_scale,w_400/ncom/en_US/games/switch/n/new-pokemon-snap-switch/hero\",\n",
    "    \"https://images.nintendolife.com/d358c9f9118af/pokemon-go.900x.jpg\",\n",
    "    \"https://cdn.vox-cdn.com/thumbor/IKt535q8LMnJDddmLL74TBtzv88=/0x266:1024x949/1280x854/cdn.vox-cdn.com/uploads/chorus_image/image/48942277/N3DS_PokemonSuperMysteryDungeon_MainIllustration_png_jpgcopy.0.0.jpg\",\n",
    "    \"https://i.imgflip.com/3sn9mp.jpg\",\n",
    "    \"https://techcrunch.com/wp-content/uploads/2017/08/cbsn.png\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "endpoint_name = \"od-load-test-model\"\n",
    "def read_image(i):\n",
    "    url = random.choice(urls)\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "\n",
    "    img = img.resize((w, h), Image.ANTIALIAS)\n",
    "    return np.asarray(img, dtype='uint8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def invoke_endpoint(images):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    input_data = np.asarray(images, dtype='uint8')\n",
    "    inputs.append(httpclient.InferInput(\"INPUT__0\", [ len(input_data),h, w,3], \"UINT8\"))\n",
    "    inputs[0].set_data_from_numpy(input_data, binary_data=True)\n",
    "    outputs.append(httpclient.InferRequestedOutput(\"BBOX\", binary_data=True))\n",
    "    outputs.append(httpclient.InferRequestedOutput(\"LABELS\", binary_data=True))\n",
    "    outputs.append(httpclient.InferRequestedOutput(\"SCORES\", binary_data=True))\n",
    "    request_body, header_length = httpclient.InferenceServerClient.generate_request_body(\n",
    "        inputs, outputs=outputs\n",
    "    )\n",
    "\n",
    "\n",
    "    runtime_sm_client = boto3.client(\"sagemaker-runtime\",region_name=\"eu-west-1\", config=Config(connect_timeout=5,\n",
    "                                                                                 read_timeout=120,\n",
    "                                                                                 retries={\n",
    "                                                                                     'max_attempts': 20,\n",
    "                                                                                     'mode': 'standard'\n",
    "\n",
    "                                                                                 }))\n",
    "    response = runtime_sm_client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        ContentType=\"application/vnd.sagemaker-triton.binary+json;json-header-size={}\".format(\n",
    "            header_length\n",
    "        ),\n",
    "        Body=request_body,\n",
    "        \n",
    "    )\n",
    "    header_length_prefix = \"application/vnd.sagemaker-triton.binary+json;json-header-size=\"\n",
    "    header_length_str = response[\"ContentType\"][len(header_length_prefix) :]\n",
    "    result = httpclient.InferenceServerClient.parse_response_body(\n",
    "        response[\"Body\"].read(), \n",
    "        header_length=int(header_length_str)\n",
    "    )\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 12\n",
    "samples = 20\n",
    "\n",
    "def run():\n",
    "    j = 0 \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        while j < 100000:\n",
    "            images_future = [executor.submit(read_image, i) for i in range(samples*batch_size)]\n",
    "            buffer = []\n",
    "            for i, future in enumerate(concurrent.futures.as_completed(images_future)):\n",
    "                buffer.append(future.result())\n",
    "                if len(buffer) >= batch_size:\n",
    "                    st_time = time.time()\n",
    "                    invoke_endpoint(buffer)\n",
    "                    print(i, len(buffer),time.time() - st_time)\n",
    "                    buffer.clear()\n",
    "            if j % 5 == 0:\n",
    "                print(\"j=\",j)\n",
    "            j+=1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:35: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 12 26.824105262756348\n",
      "23 12 5.339818716049194\n",
      "35 12 51.8453414440155\n",
      "47 12 51.857054233551025\n",
      "59 12 106.01303791999817\n",
      "71 12 53.19753122329712\n",
      "83 12 52.97249102592468\n",
      "95 12 5.2242491245269775\n",
      "107 12 3.3581738471984863\n",
      "119 12 55.068113565444946\n",
      "131 12 49.649627447128296\n",
      "143 12 10.65463137626648\n",
      "155 12 53.033745765686035\n",
      "167 12 47.64116454124451\n",
      "179 12 3.825765609741211\n",
      "191 12 54.106940507888794\n",
      "203 12 50.772104024887085\n",
      "215 12 4.235815048217773\n",
      "227 12 54.194751024246216\n",
      "239 12 50.604727029800415\n",
      "j= 0\n",
      "11 12 5.334282875061035\n",
      "23 12 53.142837047576904\n",
      "35 12 52.85909175872803\n",
      "47 12 4.331985950469971\n",
      "59 12 53.17338728904724\n",
      "71 12 46.69490313529968\n",
      "83 12 3.9397337436676025\n",
      "95 12 48.00019955635071\n",
      "107 12 46.3467698097229\n",
      "119 12 4.1943089962005615\n",
      "131 12 48.45679235458374\n",
      "143 12 46.61094260215759\n",
      "155 12 4.049340486526489\n",
      "167 12 48.785634994506836\n",
      "179 12 48.044116735458374\n",
      "191 12 4.065878868103027\n",
      "203 12 52.23169946670532\n",
      "215 12 50.64727830886841\n",
      "227 12 4.310130596160889\n",
      "239 12 53.42579913139343\n",
      "11 12 50.80714154243469\n",
      "23 12 4.129952669143677\n",
      "35 12 53.32447600364685\n",
      "47 12 50.73086357116699\n",
      "59 12 4.13210916519165\n",
      "71 12 54.0752739906311\n",
      "83 12 51.13259410858154\n",
      "95 12 3.362325668334961\n",
      "107 12 54.97404932975769\n",
      "119 12 49.56204795837402\n",
      "131 12 5.0295515060424805\n",
      "143 12 52.47782897949219\n",
      "155 12 51.060407400131226\n",
      "167 12 4.883991956710815\n",
      "179 12 51.78041172027588\n",
      "191 12 51.164050579071045\n",
      "203 12 4.551002025604248\n",
      "215 12 52.29996585845947\n",
      "227 12 51.8313684463501\n",
      "239 12 3.8126134872436523\n",
      "11 12 49.69799757003784\n",
      "23 12 52.78048610687256\n",
      "35 12 3.9933383464813232\n",
      "47 12 9.919540643692017\n",
      "59 12 51.79021143913269\n",
      "71 12 45.86941719055176\n",
      "83 12 2.934593439102173\n",
      "95 12 56.173638343811035\n",
      "107 12 51.16656827926636\n",
      "119 12 3.918205499649048\n",
      "131 12 54.30729627609253\n",
      "143 12 49.92926216125488\n",
      "155 12 4.012073040008545\n",
      "167 12 49.70758652687073\n",
      "179 12 53.89394807815552\n",
      "191 12 1.9468023777008057\n",
      "203 12 10.201037406921387\n",
      "215 12 52.28345203399658\n",
      "227 12 47.60053253173828\n",
      "239 12 4.378852605819702\n",
      "11 12 53.02956509590149\n",
      "23 12 47.641488552093506\n",
      "35 12 2.8932859897613525\n",
      "47 12 50.76647138595581\n",
      "59 12 47.05583095550537\n",
      "71 12 3.308366060256958\n",
      "83 12 45.995301723480225\n",
      "95 12 49.06994605064392\n",
      "107 12 4.97616171836853\n",
      "119 12 4.127357482910156\n",
      "131 12 50.40047240257263\n",
      "143 12 50.51710891723633\n",
      "155 12 3.937619686126709\n",
      "167 12 54.577197790145874\n",
      "179 12 50.69487023353577\n",
      "191 12 4.562815427780151\n",
      "203 12 53.510414361953735\n",
      "215 12 50.23997664451599\n",
      "227 12 3.907999038696289\n",
      "239 12 54.280670404434204\n",
      "11 12 50.59749436378479\n",
      "23 12 4.042354583740234\n",
      "35 12 52.87590956687927\n",
      "47 12 51.560481548309326\n",
      "59 12 3.9640865325927734\n",
      "71 12 54.0913462638855\n",
      "83 12 50.13805937767029\n",
      "95 12 4.334739446640015\n",
      "107 12 53.26834034919739\n",
      "119 12 50.368951082229614\n",
      "131 12 4.187332391738892\n",
      "143 12 53.05862522125244\n",
      "155 12 50.69015884399414\n",
      "167 12 1.9199237823486328\n",
      "179 12 1.953697681427002\n",
      "191 12 2.1448099613189697\n",
      "203 12 1.9173030853271484\n",
      "215 12 1.9522755146026611\n",
      "227 12 1.9207212924957275\n",
      "239 12 1.939255714416504\n",
      "j= 5\n",
      "11 12 2.059516668319702\n",
      "23 12 2.043398857116699\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-ec9775ede022>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-146-6ec2e8f7567c>\u001b[0m in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                     \u001b[0mst_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                     \u001b[0minvoke_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mst_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                     \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-145-19f4cf04dda3>\u001b[0m in \u001b[0;36minvoke_endpoint\u001b[0;34m(images)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mheader_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         ),\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mBody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_body\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    513\u001b[0m                 )\n\u001b[1;32m    514\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mapply_request_checksum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             http, parsed_response = self._make_request(\n\u001b[0;32m--> 918\u001b[0;31m                 \u001b[0moperation_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m             )\n\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, operation_model, request_dict, request_context)\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_endpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m             self.meta.events.emit(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore/endpoint.py\u001b[0m in \u001b[0;36mmake_request\u001b[0;34m(self, operation_model, request_dict)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mrequest_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         )\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore/endpoint.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, request_dict, operation_model)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         success_response, exception = self._get_response(\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         )\n\u001b[1;32m    202\u001b[0m         while self._needs_retry(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore/endpoint.py\u001b[0m in \u001b[0;36m_get_response\u001b[0;34m(self, request, operation_model, context)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;31m# If no exception occurs then exception is None.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         success_response, exception = self._do_get_response(\n\u001b[0;32m--> 242\u001b[0;31m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m         )\n\u001b[1;32m    244\u001b[0m         kwargs_to_emit = {\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore/endpoint.py\u001b[0m in \u001b[0;36m_do_get_response\u001b[0;34m(self, request, operation_model, context)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mhttp_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_non_none_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhttp_response\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m                 \u001b[0mhttp_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPClientError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore/endpoint.py\u001b[0m in \u001b[0;36m_send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_send\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore/httpsession.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    462\u001b[0m                 \u001b[0mpreload_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m                 \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m             )\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m             )\n\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1367\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1370\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1069\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
