{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d2064a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "account_id_map = {\n",
    "    'us-east-1': '785573368785',\n",
    "    'us-east-2': '007439368137',\n",
    "    'us-west-1': '710691900526',\n",
    "    'us-west-2': '301217895009',\n",
    "    'eu-west-1': '802834080501',\n",
    "    'eu-west-2': '205493899709',\n",
    "    'eu-west-3': '254080097072',\n",
    "    'eu-north-1': '601324751636',\n",
    "    'eu-south-1': '966458181534',\n",
    "    'eu-central-1': '746233611703',\n",
    "    'ap-east-1': '110948597952',\n",
    "    'ap-south-1': '763008648453',\n",
    "    'ap-northeast-1': '941853720454',\n",
    "    'ap-northeast-2': '151534178276',\n",
    "    'ap-southeast-1': '324986816169',\n",
    "    'ap-southeast-2': '355873309152',\n",
    "    'cn-northwest-1': '474822919863',\n",
    "    'cn-north-1': '472730292857',\n",
    "    'sa-east-1': '756306329178',\n",
    "    'ca-central-1': '464438896020',\n",
    "    'me-south-1': '836785723513',\n",
    "    'af-south-1': '774647643957'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "627f8f60",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting transformers[torch]\n",
      "  Downloading transformers-4.22.0-py3-none-any.whl (4.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.9.0\n",
      "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.7/120.7 KB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from transformers[torch]) (3.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from transformers[torch]) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from transformers[torch]) (2021.11.10)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from transformers[torch]) (21.3)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from transformers[torch]) (2.26.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from transformers[torch]) (1.21.2)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from transformers[torch]) (4.62.3)\n",
      "Requirement already satisfied: torch!=0.12.0,>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from transformers[torch]) (1.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.9.0->transformers[torch]) (4.0.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from packaging>=20.0->transformers[torch]) (3.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests->transformers[torch]) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests->transformers[torch]) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests->transformers[torch]) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests->transformers[torch]) (2.0.7)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.22.0\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p38/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dae037f2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting nvidia-pyindex\n",
      "  Downloading nvidia-pyindex-1.0.9.tar.gz (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: nvidia-pyindex\n",
      "  Building wheel for nvidia-pyindex (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nvidia-pyindex: filename=nvidia_pyindex-1.0.9-py3-none-any.whl size=8413 sha256=03d4e5f8b678c8e0714d13efba42d37b3c32e94b7bdefdbcf6d41ea087df0add\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/e0/c2/fb/5cf4e1cfaf28007238362cb746fb38fc2dd76348331a748d54\n",
      "Successfully built nvidia-pyindex\n",
      "Installing collected packages: nvidia-pyindex\n",
      "Successfully installed nvidia-pyindex-1.0.9\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p38/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com, https://pypi.ngc.nvidia.com\n",
      "Collecting tritonclient[http]\n",
      "  Downloading tritonclient-2.25.0-py3-none-manylinux1_x86_64.whl (11.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m341.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting python-rapidjson>=0.9.1\n",
      "  Downloading python_rapidjson-1.8-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m386.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.19.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from tritonclient[http]) (1.21.2)\n",
      "Collecting geventhttpclient>=1.4.4\n",
      "  Downloading geventhttpclient-2.0.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (100 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.9/100.9 KB\u001b[0m \u001b[31m289.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp>=3.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from tritonclient[http]) (3.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp>=3.8.1->tritonclient[http]) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp>=3.8.1->tritonclient[http]) (5.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp>=3.8.1->tritonclient[http]) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp>=3.8.1->tritonclient[http]) (21.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp>=3.8.1->tritonclient[http]) (1.7.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp>=3.8.1->tritonclient[http]) (2.0.7)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp>=3.8.1->tritonclient[http]) (4.0.1)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from geventhttpclient>=1.4.4->tritonclient[http]) (2021.10.8)\n",
      "Requirement already satisfied: gevent>=0.13 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from geventhttpclient>=1.4.4->tritonclient[http]) (21.8.0)\n",
      "Collecting brotli\n",
      "  Downloading Brotli-1.0.9-cp38-cp38-manylinux1_x86_64.whl (357 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m357.2/357.2 KB\u001b[0m \u001b[31m353.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from geventhttpclient>=1.4.4->tritonclient[http]) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from async-timeout<5.0,>=4.0.0a3->aiohttp>=3.8.1->tritonclient[http]) (4.0.0)\n",
      "Requirement already satisfied: greenlet<2.0,>=1.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from gevent>=0.13->geventhttpclient>=1.4.4->tritonclient[http]) (1.1.2)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from gevent>=0.13->geventhttpclient>=1.4.4->tritonclient[http]) (59.2.0)\n",
      "Requirement already satisfied: zope.event in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from gevent>=0.13->geventhttpclient>=1.4.4->tritonclient[http]) (4.5.0)\n",
      "Requirement already satisfied: zope.interface in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from gevent>=0.13->geventhttpclient>=1.4.4->tritonclient[http]) (5.4.0)\n",
      "Requirement already satisfied: idna>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from yarl<2.0,>=1.0->aiohttp>=3.8.1->tritonclient[http]) (3.1)\n",
      "Installing collected packages: brotli, python-rapidjson, tritonclient, geventhttpclient\n",
      "Successfully installed brotli-1.0.9 geventhttpclient-2.0.2 python-rapidjson-1.8 tritonclient-2.25.0\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p38/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.0.1 requires botocore<1.22.9,>=1.22.8, but you have botocore 1.27.73 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install nvidia-pyindex\n",
    "!pip install tritonclient[http]\n",
    "\n",
    "!pip install -qU pip awscli boto3 sagemaker transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e36d590",
   "metadata": {},
   "source": [
    "### Test Create BERT model from HuggingFace\n",
    "**If you use from BERT it comes without HEAD o you need to add Head or alternately download from HuggingFace or using Auto so you get with Head**\n",
    "\n",
    "**Test how to create BERT torchscript model**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "378a3205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT:Tokenized:Text=['[CLS]', 'who', 'was', 'jim', 'henson', '?', '[SEP]', 'jim', 'henson', 'was', 'a', 'puppet', '##eer', '[SEP]']:::\n",
      "BERT:indexed_tokens:=[101, 2040, 2001, 3958, 27227, 1029, 102, 3958, 103, 2001, 1037, 13997, 11510, 102]::\n",
      "BERT:Combining:DICT: all: creating dummy:input:Model:={'input_ids': tensor([[  101,  2040,  2001,  3958, 27227,  1029,   102,  3958,   103,  2001,\n",
      "          1037, 13997, 11510,   102]]), 'attention_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]])}::\n",
      "BERT:Finally combining all: creating dummy:input=[tensor([[  101,  2040,  2001,  3958, 27227,  1029,   102,  3958,   103,  2001,\n",
      "          1037, 13997, 11510,   102]]), tensor([[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]])]::\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer, BertConfig\n",
    "import torch\n",
    "\n",
    "enc = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenizing input text\n",
    "text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]\"\n",
    "tokenized_text = enc.tokenize(text)\n",
    "print(f\"BERT:Tokenized:Text={tokenized_text}:::\")\n",
    "\n",
    "# Masking one of the input tokens\n",
    "masked_index = 8\n",
    "tokenized_text[masked_index] = '[MASK]'\n",
    "indexed_tokens = enc.convert_tokens_to_ids(tokenized_text)\n",
    "print(f\"BERT:indexed_tokens:={indexed_tokens}::\")\n",
    "\n",
    "# -- segments id's\n",
    "segments_ids = [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "# Creating a dummy input\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "dummy_model_input = {'input_ids':tokens_tensor, 'attention_mask':segments_tensors }\n",
    "print(f\"BERT:Combining:DICT: all: creating dummy:input:Model:={dummy_model_input}::\")\n",
    "\n",
    "dummy_input = [tokens_tensor, segments_tensors]\n",
    "print(f\"BERT:Finally combining all: creating dummy:input={dummy_input}::\")\n",
    "\n",
    "# Initializing the model with the torchscript flag\n",
    "# Flag set to True even though it is not necessary as this model does not have an LM Head.\n",
    "config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,\n",
    "    num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072, torchscript=True)\n",
    "\n",
    "# Instantiating the model\n",
    "model = BertModel(config)\n",
    "\n",
    "# The model needs to be in evaluation mode for torchscript \n",
    "model.eval()\n",
    "\n",
    "# If you are instantiating the model with `from_pretrained` you can also easily set the TorchScript flag\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\", torchscript=True)\n",
    "\n",
    "# Creating the trace\n",
    "traced_model = torch.jit.trace(model, [tokens_tensor, segments_tensors])\n",
    "#torch.jit.save(traced_model, \"./bert-uc/traced_bert.pt\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1c93951f",
   "metadata": {},
   "source": [
    "for quantized export of the model to reduce size\n",
    "\n",
    "python convert_graph_to_onnx.py --framework <pt, tf> --model bert-base-cased --quantize bert-base-cased.onnx\n",
    "\n",
    "from transformers import converst_graph_to_onnx\n",
    "!python convert_graph_to_onnx.py --framework pt --model ./bert-uc/traced_bert.pt --quantize bert-base-uncased.onnx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60fbdfd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the BERT Tokensizer::\n",
      "[101, 2040, 2001, 3958, 27227, 1029, 102, 3958, 103, 2001, 1037, 13997, 11510, 102]\n",
      "[tensor([[  101,  2040,  2001,  3958, 27227,  1029,   102,  3958,   103,  2001,\n",
      "          1037, 13997, 11510,   102]]), tensor([[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]])]\n",
      "{'input_ids': tensor([[  101,  2040,  2001,  3958, 27227,  1029,   102,  3958,   103,  2001,\n",
      "          1037, 13997, 11510,   102]]), 'attention_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "print(\"Using the BERT Tokensizer::\")\n",
    "\n",
    "print(indexed_tokens)\n",
    "print(dummy_input)\n",
    "print(dummy_model_input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59af7dd",
   "metadata": {},
   "source": [
    "dummy_model_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574d9e1d",
   "metadata": {},
   "source": [
    "**Test Tokenizers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6947af65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71592a155ca34f5cb792b1dac7f2bff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f669416795545678c858f3edec744a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55483c5286424f92a037ea818296e0e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8f6adbf31e64cf098e66279eb3a1571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the BERT:AUTO:TOKENSIZER: Tokenizer::\n",
      "{'input_ids': tensor([[ 101, 2023, 2003, 1037, 7099,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# load model and tokenizer\n",
    "model_id = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "dummy_model_bert_input = tokenizer(\"This is a sample\", return_tensors=\"pt\")\n",
    "\n",
    "print(\"Using the BERT:AUTO:TOKENSIZER: Tokenizer::\")\n",
    "print(dummy_model_bert_input) # -- dict -- input id's and attention mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403b0812",
   "metadata": {},
   "source": [
    "### Export as ONYX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a05c3c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py:219: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  mask, torch.tensor(torch.finfo(scores.dtype).min)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# export\n",
    "torch.onnx.export(\n",
    "    model, \n",
    "    tuple(dummy_model_input.values()), #tuple(dummy_model_input.values()),\n",
    "    f=\"./bert-uc/torch-model.onnx\",  \n",
    "    input_names=['input_ids', 'attention_mask'], \n",
    "    output_names=['logits'], \n",
    "    dynamic_axes={'input_ids': {0: 'batch_size', 1: 'sequence'}, \n",
    "                  'attention_mask': {0: 'batch_size', 1: 'sequence'}, \n",
    "                  'logits': {0: 'batch_size', 1: 'sequence'}}, \n",
    "    do_constant_folding=True, \n",
    "    opset_version=13, \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793e0301",
   "metadata": {},
   "outputs": [],
   "source": [
    "[tokens_tensor, segments_tensors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a81ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "358ebdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 <class 'tuple'> <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer, BertConfig\n",
    "import torch\n",
    "\n",
    "\n",
    "# If you are instantiating the model with `from_pretrained` you can also easily set the TorchScript flag\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\", torchscript=True)\n",
    "\n",
    "# Change to eva lmodel\n",
    "model.eval()\n",
    "\n",
    "# run a dummy prediction of tokens by tensors\n",
    "output = model(tokens_tensor)\n",
    "print(len(output), type(output), type(output[0]))\n",
    "\n",
    "# Creating the trace\n",
    "traced_model = torch.jit.trace(model, [tokens_tensor, segments_tensors])\n",
    "#torch.jit.save(traced_model, \"./triton-serve/bert-uc/1/model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20d1c02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT:Tokenized:Text=['[CLS]', 'who', 'was', 'jim', 'henson', '?', '[SEP]', 'jim', 'henson', 'was', 'a', 'puppet', '##eer', '[SEP]']:::\n",
      "BERT:indexed_tokens:=[101, 2040, 2001, 3958, 27227, 1029, 102, 3958, 103, 2001, 1037, 13997, 11510, 102]::\n",
      "tensor([[  101,  2040,  2001,  3958, 27227,  1029,   102,  3958,   103,  2001,\n",
      "          1037, 13997, 11510,   102]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer, BertConfig\n",
    "import torch\n",
    "\n",
    "enc = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenizing input text\n",
    "text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]\"\n",
    "tokenized_text = enc.tokenize(text)\n",
    "print(f\"BERT:Tokenized:Text={tokenized_text}:::\")\n",
    "\n",
    "# Masking one of the input tokens\n",
    "masked_index = 8\n",
    "tokenized_text[masked_index] = '[MASK]'\n",
    "indexed_tokens = enc.convert_tokens_to_ids(tokenized_text)\n",
    "print(f\"BERT:indexed_tokens:={indexed_tokens}::\")\n",
    "\n",
    "# -- segments id's -- CAN WE GENERATE THEM via model\n",
    "segments_ids = [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "# Creating a dummy input\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "print(tokens_tensor)\n",
    "print(segments_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922eec4d",
   "metadata": {},
   "source": [
    "### Neo Compilers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "43fb30ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role, Session, image_uris\n",
    "from sagemaker.utils import name_from_base\n",
    "import boto3\n",
    "region = boto3.Session().region_name\n",
    "session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "sm_client = boto3.client(service_name=\"sagemaker\")\n",
    "runtime_sm_client = boto3.client(\"sagemaker-runtime\")\n",
    "sess_bucket=session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d2054755",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[485, 452, 842, 316, 726, 504, 361, 606, 326, 376,  39, 873, 298, 223,\n",
       "          265, 844, 180, 805,  17, 714, 446, 305, 274, 512, 797, 704, 966, 181,\n",
       "          500, 221, 188, 945, 275, 994, 710, 413, 922, 368, 131, 292, 775, 585,\n",
       "          387, 427,  90, 342, 734, 734, 831, 734, 964, 240, 975, 679, 445, 132,\n",
       "          161, 403, 379,  54, 585, 384, 359, 947, 861, 951, 855, 527, 576,  67,\n",
       "          524, 601, 121, 380, 331, 163, 520, 736, 463, 874, 613, 608, 574, 869,\n",
       "          755, 924, 532, 329, 919, 518, 121,  62,   2, 513, 594, 543,  34, 953,\n",
       "          314, 460, 980, 702, 443, 176, 934, 260, 458, 364, 825, 859, 309, 726,\n",
       "          993, 243, 273, 935,  96, 847, 585, 658,  32, 214, 270, 930,   6, 854,\n",
       "          157, 424, 765, 684, 701, 417, 859, 302, 368,  47, 438, 949, 906, 485,\n",
       "           82,  92,  95, 482, 504, 976, 335, 160, 933, 610, 349, 980,  57, 964,\n",
       "          332, 582, 389, 261, 288, 806,   2, 492, 620,  72, 679, 250, 847, 589,\n",
       "          268, 108,  38, 828, 296, 541,  15, 167, 771, 707, 873, 481, 533, 381,\n",
       "          970, 559,  63, 925, 623, 492, 474, 790, 908, 961, 930, 300, 148, 560,\n",
       "          606, 840, 507,   8,  46, 835, 344, 111, 826, 227, 942, 907,  90, 547,\n",
       "          477, 436, 465, 104, 826, 993, 418, 881, 379, 797, 323, 602, 172,  72,\n",
       "          959, 299, 453, 591, 680, 780,  68, 676, 353, 756, 396, 808, 569, 383,\n",
       "           65, 216, 885, 679, 146, 826, 853, 284, 294, 273, 895, 847, 897, 280,\n",
       "          537, 581, 178, 591, 906, 630,  47,  14, 378, 148,  55, 774, 174, 915,\n",
       "          529,  91, 243, 325, 567, 322, 627, 236, 178, 389, 354, 209, 197, 927,\n",
       "          582, 460, 387, 198, 459, 655,  70, 719, 195, 470,  74, 308,  96, 649,\n",
       "          479, 601, 751, 972, 278, 403, 793,  37, 865, 426, 550, 343, 696,  74,\n",
       "          173, 344, 915, 766, 807, 588, 630, 737, 207, 456, 351, 225, 752, 631,\n",
       "          496, 783, 459, 580, 149, 726, 150, 288, 395,   3, 959, 718,  17, 308,\n",
       "          850, 872, 969, 195, 575, 286, 462, 194, 785, 263, 294,   1, 331, 314,\n",
       "          472, 756, 579, 492, 785,  16, 926, 184, 929, 237, 567, 550, 257, 485,\n",
       "          626, 121, 302,  84, 842, 666, 851,  68, 992, 172, 483, 297, 444, 472,\n",
       "           10, 795, 945, 662, 436, 404, 167, 942, 402, 672, 541, 655,  41, 791,\n",
       "          764, 793, 222, 485, 583, 269, 169, 535, 269, 200, 215, 896, 564, 614,\n",
       "          119, 468, 745,  69, 631, 827, 259,   2, 194, 605, 852, 600, 498, 937,\n",
       "          814, 953, 601, 622, 873,  56, 304, 764,  54, 936, 708, 293, 329, 431,\n",
       "          342, 642, 146,  80, 678, 953, 685, 593, 654, 649, 247, 737, 779, 980,\n",
       "          843, 261, 934,   0, 598,  62, 442, 987, 831, 340, 330, 828, 463,  38,\n",
       "           15, 243, 948, 955, 812, 445, 888, 957, 452, 206, 438, 619, 337, 341,\n",
       "          897, 710, 300, 966,  22, 789, 376,  42, 513, 896, 222, 579, 689, 206,\n",
       "          918, 457, 714, 316, 788, 548, 747, 285, 496, 893,  84, 626, 655, 784,\n",
       "          647, 271, 191, 765, 964, 464, 796, 219]]),\n",
       " tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0]], dtype=torch.int32)]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    torch.randint(1000, (bs, seq_len)).to(device),\n",
    "    torch.zeros(bs, seq_len, dtype=torch.int).to(device),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "74493d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 5672, 2033, 2011, 2151, 3793, 2017, 1005, 1040, 2066, 1012,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_inputs_neo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "21082ae4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved BertModel(\n",
      "  original_name=BertModel\n",
      "  (embeddings): BertEmbeddings(\n",
      "    original_name=BertEmbeddings\n",
      "    (word_embeddings): Embedding(original_name=Embedding)\n",
      "    (position_embeddings): Embedding(original_name=Embedding)\n",
      "    (token_type_embeddings): Embedding(original_name=Embedding)\n",
      "    (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "    (dropout): Dropout(original_name=Dropout)\n",
      "  )\n",
      "  (encoder): BertEncoder(\n",
      "    original_name=BertEncoder\n",
      "    (layer): ModuleList(\n",
      "      original_name=ModuleList\n",
      "      (0): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (1): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (2): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (3): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (4): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (5): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (6): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (7): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (8): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (9): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (10): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (11): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (12): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (13): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (14): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (15): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (16): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (17): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (18): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (19): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (20): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (21): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (22): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (23): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): BertPooler(\n",
      "    original_name=BertPooler\n",
      "    (dense): Linear(original_name=Linear)\n",
      "    (activation): Tanh(original_name=Tanh)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Prepare sample input for jit model tracing\n",
    "seq_0 = \"This is just sample text for model tracing, the length of the sequence does not matter because we will pad to the max length that Bert accepts.\"\n",
    "seq_1 = seq_0\n",
    "max_length = 512\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "# -- IF you use from bert it comes without HEAD \n",
    "model_neo = BertModel.from_pretrained(\"bert-large-uncased\", return_dict=False)\n",
    "tokenizer_neo = AutoTokenizer.from_pretrained(\"bert-large-uncased\")\n",
    "\n",
    "tokenized_sequence_pair_neo = tokenizer_neo.encode_plus(\n",
    "    seq_0, seq_1, max_length=max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "example_neo = tokenized_sequence_pair_neo[\"input_ids\"], tokenized_sequence_pair_neo[\"attention_mask\"]\n",
    "\n",
    "traced_model_neo = torch.jit.trace(model_neo.eval(), example_neo)\n",
    "#traced_model.save(\"traced_model/model.pth\")\n",
    "\n",
    "# Just another way of tracing -- or encoding with a single input to the tokenizer\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "\n",
    "# Both work\n",
    "dummy_inputs_neo = tokenizer_neo(text, max_length=max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "dummy_inputs_neo = tokenizer_neo.encode_plus(text, max_length=max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "example_neo = dummy_inputs_neo[\"input_ids\"], dummy_inputs_neo[\"attention_mask\"]\n",
    "\n",
    "traced_model_neo = torch.jit.trace(model_neo.eval(), example_neo)\n",
    "\n",
    "\n",
    "torch.jit.save(traced_model_neo, \"./inferentia-code/model.pth\")\n",
    "\n",
    "print(\"Saved {}\".format(traced_model_neo))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16045b0a",
   "metadata": {},
   "source": [
    "tar --exclude=\".git\" --exclude=\".gitattributes\" --exclude=\"model.tar.gz\" --exclude=\"*.bin\" -zcvf model.tar.gz *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7e83e5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-622343165275/neo/bert-uc/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "traced_model_neo_url = sagemaker.s3.S3Uploader().upload(\n",
    "    local_path=\"./inferentia-code/model.tar.gz\",\n",
    "    desired_s3_uri=\"s3://sagemaker-us-east-1-622343165275/neo/bert-uc\",\n",
    "    sagemaker_session=session\n",
    ")\n",
    "print(traced_model_neo_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "48bdac0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-622343165275/neo/bert-uc/model.tar.gz\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2022-09-16 18:48:30 1244066527 model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "print(traced_model_neo_url)\n",
    "! aws s3 ls $traced_model_neo_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206ba93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "from sagemaker.predictor import Predictor\n",
    "from datetime import datetime\n",
    "\n",
    "prefix = \"neuron-experiments/bert-seq-classification\"\n",
    "flavour = \"normal\"\n",
    "date_string = datetime.now().strftime(\"%Y%m-%d%H-%M%S\")\n",
    "\n",
    "compiled_sm_model = PyTorchModel(\n",
    "    model_data=traced_model_neo_url,\n",
    "    predictor_cls=Predictor,\n",
    "    framework_version=\"1.7\", #\"1.5.1\",\n",
    "    role=role,\n",
    "    sagemaker_session=session,\n",
    "    entry_point=\"inference_inf1.py\",\n",
    "    #source_dir=\"inferentia-code\",\n",
    "    py_version=\"py3\",\n",
    "    name=f\"{flavour}-bert-pt181-{date_string}\",\n",
    "    env={\"SAGEMAKER_CONTAINER_LOG_LEVEL\": \"10\"},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6616cee1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "????????????????????????????.................................................................................................................................................................................*"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Compilation job bert-compiled-inf-inf1-202209-1618-4850: Failed. Reason: TimeoutException: Compilation stopped due to exceeded time-limit  For further troubleshooting common failures please visit: https://docs.aws.amazon.com/sagemaker/latest/dg/neo-troubleshooting-compilation.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/sagemaker/model.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, target_instance_family, input_shape, output_path, role, tags, job_name, compile_max_run, framework, framework_version, target_platform_os, target_platform_arch, target_platform_accelerator, compiler_options)\u001b[0m\n\u001b[1;32m    986\u001b[0m         )\n\u001b[1;32m    987\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 988\u001b[0;31m         \u001b[0mjob_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_compilation_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    989\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob_status\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ModelArtifacts\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"S3ModelArtifacts\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarget_instance_family\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mwait_for_compilation_job\u001b[0;34m(self, job, poll)\u001b[0m\n\u001b[1;32m   3265\u001b[0m         \"\"\"\n\u001b[1;32m   3266\u001b[0m         \u001b[0mdesc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wait_until\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_compilation_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3267\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CompilationJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3268\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   3390\u001b[0m                     \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3391\u001b[0m                 )\n\u001b[0;32m-> 3392\u001b[0;31m             raise exceptions.UnexpectedStatusException(\n\u001b[0m\u001b[1;32m   3393\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3394\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Compilation job bert-compiled-inf-inf1-202209-1618-4850: Failed. Reason: TimeoutException: Compilation stopped due to exceeded time-limit  For further troubleshooting common failures please visit: https://docs.aws.amazon.com/sagemaker/latest/dg/neo-troubleshooting-compilation.html"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import json\n",
    "\n",
    "hardware = \"inf1\"\n",
    "flavour = \"compiled-inf\"\n",
    "compilation_job_name = f\"bert-{flavour}-{hardware}-\" + date_string\n",
    "\n",
    "compiled_inf1_model = compiled_sm_model.compile(\n",
    "    target_instance_family=f\"ml_{hardware}\",\n",
    "    input_shape={\"input_ids\": [1, 512], \"attention_mask\": [1, 512]},\n",
    "    job_name=compilation_job_name,\n",
    "    role=role,\n",
    "    framework=\"pytorch\",\n",
    "    framework_version=\"1.7\", #\"1.5.1\",\n",
    "    output_path=f\"s3://{sess_bucket}/{prefix}/neo-compilations/{flavour}-model\",\n",
    "    compiler_options=json.dumps(\"--dtype int64\"),\n",
    "    #     compiler_options={'dtype': 'int64'},    # For compiling to \"normal\" instance types, cpu or gpu-based\n",
    "    compile_max_run=900,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1fe9ed",
   "metadata": {},
   "source": [
    "**End NEO Compilers for Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfa9ef5",
   "metadata": {},
   "source": [
    "## Start actual BERT with Head for Triton\n",
    "\n",
    "### This model from HuggingFace does not take the attension ID's so accepts only 1 input\n",
    "input [\n",
    "  {\n",
    "    name: \"INPUT__0\"\n",
    "    data_type: TYPE_INT32\n",
    "    dims: [512]\n",
    "  },\n",
    "  \n",
    "  \n",
    "    {\n",
    "    name: \"INPUT__1\"\n",
    "    data_type: TYPE_INT32\n",
    "    dims: [512]\n",
    "  }\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee6cd9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting triton-serve/bert-uc/config.pbtxt\n"
     ]
    }
   ],
   "source": [
    "%%writefile triton-serve/bert-uc/config.pbtxt\n",
    "platform: \"pytorch_libtorch\"\n",
    "max_batch_size: 32\n",
    "input [\n",
    "  {\n",
    "    name: \"INPUT__0\"\n",
    "    data_type: TYPE_INT32\n",
    "    dims: [512]\n",
    "  },\n",
    "  {\n",
    "    name: \"INPUT__1\"\n",
    "    data_type: TYPE_INT32\n",
    "    dims: [512]\n",
    "  }\n",
    "]\n",
    "output [\n",
    "  {\n",
    "    name: \"OUTPUT__0\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [512, 768]\n",
    "  },\n",
    "  {\n",
    "    name: \"1634__1\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [768]\n",
    "  }\n",
    "]\n",
    "instance_group {\n",
    "  count: 1\n",
    "  kind: KIND_GPU\n",
    "}\n",
    "dynamic_batching {\n",
    "  preferred_batch_size: 32\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba4a981",
   "metadata": {},
   "source": [
    "### Run for Triton server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec079557",
   "metadata": {},
   "source": [
    "**Note**: Amazon SageMaker expects the model tarball file to have a top level directory with the same name as the model defined in the `config.pbtxt`. Below is the sample model directory structure\n",
    "\n",
    "```\n",
    "bert-uc\n",
    "├── 1\n",
    "│   └── model.pt\n",
    "└── config.pbtxt\n",
    "```"
   ]
  },
  {
   "cell_type": "raw",
   "id": "02c8019c",
   "metadata": {},
   "source": [
    "tar --exclude=\".git\" --exclude=\".gitattributes\" --exclude=\"model.tar.gz\" --exclude=\"*.bin\" -zcvf model.tar.gz bert-uc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a576b1e",
   "metadata": {},
   "source": [
    "**Have to use the same Tokenizer to generate the input to test as BERT uncased**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769d635d",
   "metadata": {},
   "source": [
    "### Create the BERT Model in Torch Script mode -- .pt model\n",
    "use the ore trained and use torchscript flag here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc6d894",
   "metadata": {},
   "source": [
    "### Create the LARGE CASE BERT Model in Torch Script using dummy inputs -- .pt model\n",
    "Create using the dummy inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "736daf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPTJModel\n",
    "from transformers import GPTJForCausalLM, AutoTokenizer\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a3446e",
   "metadata": {},
   "source": [
    "### Run a simple test for BERT LARGE uncased \n",
    "\n",
    "    * We run multiple tests\n",
    "        * First we token ize and then de tokenize to make sure the vaues match\n",
    "        * Then we use the model and run predictions to get values\n",
    "        * Then we run on the traced Model and run predictions to get values \n",
    "        * Check to make sure they match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "46afe165",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.4472,  0.3378, -0.1825,  ..., -0.8584, -1.3538,  0.4175],\n",
       "         [-0.2535,  0.1439, -0.1481,  ..., -0.5559, -0.3288, -0.1320],\n",
       "         [-0.1767, -0.2466, -0.3732,  ..., -0.2728,  0.2910,  0.3882],\n",
       "         ...,\n",
       "         [-0.0674, -0.3769,  0.0228,  ...,  0.1540,  0.8440,  0.2331],\n",
       "         [ 0.0884,  0.4401, -0.8590,  ..., -0.2341, -1.5650, -0.2771],\n",
       "         [-0.3043,  0.1687, -0.3263,  ..., -0.2537,  0.0570,  0.5401]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.9507, -0.9791,  0.9999,  ..., -0.9996,  0.8956, -0.9869]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased', torchscript=True)\n",
    "model = BertModel.from_pretrained(\"bert-large-uncased\")\n",
    "\n",
    "text = \"Triton Inference Server provides a cloud and edge inferencing solution optimized for both CPUs and GPUs.\" #\"Replace me by any text you'd like.\"\n",
    "\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "output = model(**encoded_input)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4f5c6d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 101, 5672, 2033, 2011, 2151, 3793, 2017, 1005, 1040, 2066, 1012,  102]]),\n",
       " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_inputs['input_ids'], dummy_inputs['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "49e33dd8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2316: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved BertModel(\n",
      "  original_name=BertModel\n",
      "  (embeddings): BertEmbeddings(\n",
      "    original_name=BertEmbeddings\n",
      "    (word_embeddings): Embedding(original_name=Embedding)\n",
      "    (position_embeddings): Embedding(original_name=Embedding)\n",
      "    (token_type_embeddings): Embedding(original_name=Embedding)\n",
      "    (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "    (dropout): Dropout(original_name=Dropout)\n",
      "  )\n",
      "  (encoder): BertEncoder(\n",
      "    original_name=BertEncoder\n",
      "    (layer): ModuleList(\n",
      "      original_name=ModuleList\n",
      "      (0): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (1): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (2): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (3): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (4): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (5): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (6): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (7): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (8): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (9): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (10): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (11): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (12): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (13): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (14): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (15): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (16): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (17): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (18): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (19): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (20): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (21): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (22): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "      (23): BertLayer(\n",
      "        original_name=BertLayer\n",
      "        (attention): BertAttention(\n",
      "          original_name=BertAttention\n",
      "          (self): BertSelfAttention(\n",
      "            original_name=BertSelfAttention\n",
      "            (query): Linear(original_name=Linear)\n",
      "            (key): Linear(original_name=Linear)\n",
      "            (value): Linear(original_name=Linear)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "          (output): BertSelfOutput(\n",
      "            original_name=BertSelfOutput\n",
      "            (dense): Linear(original_name=Linear)\n",
      "            (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "            (dropout): Dropout(original_name=Dropout)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): BertIntermediate(\n",
      "          original_name=BertIntermediate\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (intermediate_act_fn): GELUActivation(original_name=GELUActivation)\n",
      "        )\n",
      "        (output): BertOutput(\n",
      "          original_name=BertOutput\n",
      "          (dense): Linear(original_name=Linear)\n",
      "          (LayerNorm): LayerNorm(original_name=LayerNorm)\n",
      "          (dropout): Dropout(original_name=Dropout)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): BertPooler(\n",
      "    original_name=BertPooler\n",
      "    (dense): Linear(original_name=Linear)\n",
      "    (activation): Tanh(original_name=Tanh)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "# -- IF you use from bert it comes without HEAD \n",
    "model = BertModel.from_pretrained(\"bert-large-uncased\", torchscript=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased\")\n",
    "\n",
    "\n",
    "bs = 1\n",
    "seq_len = 512\n",
    "dummy_inputs = [\n",
    "    torch.randint(1000, (bs, seq_len)).to(device),\n",
    "    torch.zeros(bs, seq_len, dtype=torch.int).to(device),\n",
    "]\n",
    "traced_model = torch.jit.trace(model, dummy_inputs)\n",
    "\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "dummy_inputs = tokenizer(text, return_tensors='pt', max_length=seq_len, padding=True, truncation=True, )\n",
    "traced_model = torch.jit.trace(model, dummy_inputs)\n",
    "\n",
    "model = model.eval()\n",
    "# model.to(device)\n",
    "torch.jit.save(traced_model, \"./triton-serve/bert-uc/1/model.pt\")\n",
    "\n",
    "print(\"Saved {}\".format(traced_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2bd95803",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 1024)\n",
       "    (token_type_embeddings): Embedding(2, 1024)\n",
       "    (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (12): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (13): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (14): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (15): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (16): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (17): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (18): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (19): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (20): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (21): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (22): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (23): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85246e13",
   "metadata": {},
   "source": [
    "#### Test encoders various methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0824610a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 13012, 2669, 28937, 8241, 3640, 1037, 6112, 1998, 3341, 1999, 7512, 2368, 6129, 5576, 23569, 27605, 5422, 2005, 2119, 17368, 2015, 1998, 14246, 2271, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\n",
    "    \"Triton Inference Server provides a cloud and edge inferencing solution optimized for both CPUs and GPUs.\", \n",
    "    padding=\"max_length\", \n",
    "    max_length=64\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d85b28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "encoded_tokens = tokenizer.encode_plus(\n",
    "    \"Triton Inference Server provides a cloud and edge inferencing solution optimized for both CPUs and GPUs.\",\n",
    "    add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "    max_length = 512,           \n",
    "    pad_to_max_length = True, # Pad & truncate all sentences\n",
    ")\n",
    "#encoded_tokens "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715e8e84",
   "metadata": {},
   "source": [
    "**Predict test using the traced model Needs Tokens and Attention mask both**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c1d945c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_tokens['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68920418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'triton inference server provides a cloud and edge inferencing solution optimized for both cpus and gpus.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(\n",
    "    encoded_tokens['input_ids'],\n",
    "    skip_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "#     max_length = 512,           \n",
    "#     pad_to_max_length = True, # Pad & truncate all sentences\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b91d085e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[  101, 13012,  2669, 28937,  8241,  3640,  1037,  6112,  1998,  3341,\n",
       "           1999,  7512,  2368,  6129,  5576, 23569, 27605,  5422,  2005,  2119,\n",
       "          17368,  2015,  1998, 14246,  2271,  1012,   102,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]),\n",
       " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0]])]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[encoded_input['input_ids'],encoded_input['attention_mask']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "80984984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.4472,  0.3378, -0.1825,  ..., -0.8584, -1.3538,  0.4175],\n",
       "         [-0.2535,  0.1439, -0.1481,  ..., -0.5559, -0.3288, -0.1320],\n",
       "         [-0.1767, -0.2466, -0.3732,  ..., -0.2728,  0.2910,  0.3882],\n",
       "         ...,\n",
       "         [ 0.0150,  0.6082,  0.0717,  ...,  0.3446, -0.2089, -0.2529],\n",
       "         [ 0.0930,  0.2063, -0.1411,  ..., -0.3262, -0.6821, -0.1691],\n",
       "         [ 0.0200,  0.7166,  0.0530,  ...,  0.1955, -0.1783, -0.2524]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.9507, -0.9791,  0.9999,  ..., -0.9996,  0.8956, -0.9869]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "encoded_input = tokenizer(\n",
    "    \"Triton Inference Server provides a cloud and edge inferencing solution optimized for both CPUs and GPUs.\", \n",
    "    return_tensors='pt',\n",
    "    add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "    max_length = 100, # -- this model has max length set to 100 -- not to 512,           \n",
    "    pad_to_max_length = True, # Pad & truncate all sentences\n",
    "\n",
    ")\n",
    "#unscripted_output = model.generate( # -- This is for GPTJ version of the model and so uses do_sample, temperature etc \n",
    "unscripted_output = model( # -- both work the same way \n",
    "    **encoded_input, \n",
    "    #inputs=encoded_input['attention_mask']],\n",
    "    return_dict=True, \n",
    "    output_attentions=False, \n",
    "    output_hidden_states=False,\n",
    "\n",
    "    #do_sample=True,\n",
    "    #temperature=0.9,\n",
    "    #max_length=128,\n",
    ")\n",
    "\n",
    "#tokenizer.decode(unscripted_output[0])\n",
    "unscripted_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "33f08e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.4472,  0.3378, -0.1825,  ..., -0.8584, -1.3538,  0.4175],\n",
       "          [-0.2535,  0.1439, -0.1481,  ..., -0.5559, -0.3288, -0.1320],\n",
       "          [-0.1767, -0.2466, -0.3732,  ..., -0.2728,  0.2910,  0.3882],\n",
       "          ...,\n",
       "          [ 0.0150,  0.6082,  0.0717,  ...,  0.3446, -0.2089, -0.2529],\n",
       "          [ 0.0930,  0.2063, -0.1411,  ..., -0.3262, -0.6821, -0.1691],\n",
       "          [ 0.0200,  0.7166,  0.0530,  ...,  0.1955, -0.1783, -0.2524]]],\n",
       "        grad_fn=<NativeLayerNormBackward0>),\n",
       " tensor([[-0.9507, -0.9791,  0.9999,  ..., -0.9996,  0.8956, -0.9869]],\n",
       "        grad_fn=<TanhBackward0>))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "encoded_input = tokenizer(\n",
    "    \"Triton Inference Server provides a cloud and edge inferencing solution optimized for both CPUs and GPUs.\", \n",
    "    return_tensors='pt',\n",
    "    add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "    max_length = 100, # -- this model has max length set to 100 -- not to 512,           \n",
    "    pad_to_max_length = True, # Pad & truncate all sentences\n",
    "\n",
    ")\n",
    "# Traced Model expects ONLY the INPUT ID's\n",
    "unscripted_traced_output = traced_model( # -- both work the same way \n",
    "    encoded_input['input_ids'] , encoded_input['attention_mask']\n",
    ")\n",
    "\n",
    "#tokenizer.decode(unscripted_output[0])\n",
    "unscripted_traced_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dedcb78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9045, -0.9739,  0.9999,  ..., -0.9985,  0.8936, -0.9707]],\n",
       "       grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unscripted_output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b878a8fa",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tokenizer.batch_decode(unscripted_output[1])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7b2bfed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101, 13012,  2669, 28937,  8241,  3640,  1037,  6112,  1998,  3341,\n",
       "          1999,  7512,  2368,  6129,  5576, 23569, 27605,  5422,  2005,  2119,\n",
       "         17368,  2015,  1998, 14246,  2271,  1012,   102,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "         19101, 26256, 17884,   524, 21002,  7116, 29986, 25690, 24989, 11437,\n",
       "         25153, 18364, 20228,  8929, 12011, 16143, 15691, 25636, 13067,  9410,\n",
       "          1842, 11753,  1594, 18910, 12128, 20549,  6186, 24852]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unscripted_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66669905",
   "metadata": {},
   "source": [
    "### Use the single input to create the traced model in case the model accepts 1 inputs \n",
    "### In case Model accepts 2 inputs like BERT then use 2 to create Traced scripting model\n",
    "**torch.save(model, \"./triton-serve/bert-uc/1/model.pt\") Does not work**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34790ced",
   "metadata": {},
   "source": [
    "### UPLOAD of the Model.tar after it has been created correctly by \n",
    "\n",
    "Because we share the same model tar with bloom and with bert-uc\n",
    "rm model.tar.gz in the triton-serve directory\n",
    "\n",
    "\n",
    "tar --exclude=\".git\" --exclude=\".gitattributes\" --exclude=\"model.tar.gz\" --exclude=\"*.bin\" --exclude \"*.tar\" -zcvf model.tar.gz bert-uc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feed1b55",
   "metadata": {},
   "source": [
    "**Upload the model.tar.gz to S3 location**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8e9ba035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role, Session, image_uris\n",
    "from sagemaker.utils import name_from_base\n",
    "import boto3\n",
    "region = boto3.Session().region_name\n",
    "session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "sm_client = boto3.client(service_name=\"sagemaker\")\n",
    "runtime_sm_client = boto3.client(\"sagemaker-runtime\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "86f0d03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-622343165275/bloom/triton_models/bert-uc/model.tar.gz\n",
      "s3://sagemaker-us-east-1-622343165275/bloom/triton_models/\n"
     ]
    }
   ],
   "source": [
    "s3_model_path_triton = sagemaker.s3.S3Uploader().upload(\n",
    "    local_path=\"./triton-serve/model.tar.gz\",\n",
    "    desired_s3_uri=\"s3://sagemaker-us-east-1-622343165275/bloom/triton_models/bert-uc\",\n",
    "    sagemaker_session=session\n",
    ")\n",
    "s3_mme_model_path='s3://sagemaker-us-east-1-622343165275/bloom/triton_models/'\n",
    "print(s3_model_path_triton)\n",
    "print(s3_mme_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae2b009",
   "metadata": {},
   "source": [
    "#### Start Single Model Triton for starting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741da45c",
   "metadata": {},
   "source": [
    "**Triton Image download and sagemaker variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d863f79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785573368785.dkr.ecr.us-east-1.amazonaws.com/sagemaker-tritonserver:22.07-py3\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import get_execution_role, Session, image_uris\n",
    "import boto3\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "role = get_execution_role()\n",
    "sm_client = boto3.client(service_name=\"sagemaker\")\n",
    "runtime_sm_client = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "base = \"amazonaws.com.cn\" if region.startswith(\"cn-\") else \"amazonaws.com\"\n",
    "triton_image_uri = \"{account_id}.dkr.ecr.{region}.{base}/sagemaker-tritonserver:22.07-py3\".format(\n",
    "    account_id=account_id_map[region], region=region, base=base\n",
    ")\n",
    "print(triton_image_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82661f3",
   "metadata": {},
   "source": [
    "**Model creation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f05affc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p5-bert-uc--2022-09-16-18-09-53-901\n",
      "{'ModelArn': 'arn:aws:sagemaker:us-east-1:622343165275:model/p5-bert-uc--2022-09-16-18-09-53-901', 'ResponseMetadata': {'RequestId': '1a6f3ab1-2375-4898-86c9-f7c3488a4537', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '1a6f3ab1-2375-4898-86c9-f7c3488a4537', 'content-type': 'application/x-amz-json-1.1', 'content-length': '97', 'date': 'Fri, 16 Sep 2022 18:09:54 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "endpoint_name_p5 = name_from_base(f\"p5-bert-uc-\")\n",
    "print(endpoint_name_p5)\n",
    "\n",
    "container_p5 = {\n",
    "    'Image': triton_image_uri,\n",
    "    'ModelDataUrl': s3_model_path_triton,\n",
    "    'Environment': {\n",
    "        #'SAGEMAKER_PROGRAM' : 'inference.py',\n",
    "        #'SAGEMAKER_SUBMIT_DIRECTORY' : 'code',\n",
    "        'SAGEMAKER_TRITON_DEFAULT_MODEL_NAME': 'bert-uc',\n",
    "        \"SAGEMAKER_TRITON_BATCH_SIZE\": \"16\",\n",
    "        \"SAGEMAKER_TRITON_MAX_BATCH_DELAY\": \"1000\",\n",
    "        \"SAGEMAKER_TRITON_SHM_DEFAULT_BYTE_SIZE\" : \"16777216\", #\"16777216000\",\n",
    "        \"SAGEMAKER_TRITON_SHM_GROWTH_BYTE_SIZE\": \"1048576\"\n",
    "    }\n",
    "}\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName=endpoint_name_p5, ExecutionRoleArn=role, PrimaryContainer=container_p5\n",
    ")\n",
    "print(create_model_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ba56d7",
   "metadata": {},
   "source": [
    "**Endpoint config**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a8e83ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Config Arn: arn:aws:sagemaker:us-east-1:622343165275:endpoint-config/p5-bert-uc--2022-09-16-18-09-53-901\n"
     ]
    }
   ],
   "source": [
    "# Sampling percentage. Choose an integer value between 0 and 100\n",
    "initial_sampling_percentage = 10                                                                                                                                                                                                                        \n",
    "\n",
    "# The S3 URI of where to store captured data in S3\n",
    "s3_capture_upload_path = 's3://sagemaker-us-east-1-622343165275/bloom/triton_models/datacapture'\n",
    "data_capture_prefix = 'bloom/triton_models/datacapture'\n",
    "\n",
    "# Specify either Input, Output, or both\n",
    "capture_modes = [\"Input\"] # --[ \"Input\",  \"Output\" ] \n",
    "\n",
    "create_endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_name_p5,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"InstanceType\": \"ml.g5.8xlarge\", #\"ml.g4dn.xlarge\",\n",
    "            \"InitialVariantWeight\": 1,\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"ModelName\": endpoint_name_p5,\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "        }\n",
    "    ],\n",
    "    DataCaptureConfig= {\n",
    "        'EnableCapture': True, # Whether data should be captured or not.\n",
    "        'InitialSamplingPercentage' : initial_sampling_percentage,\n",
    "        'DestinationS3Uri': s3_capture_upload_path,\n",
    "        'CaptureOptions': [{\"CaptureMode\" : capture_mode} for capture_mode in capture_modes] # \n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response[\"EndpointConfigArn\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe59ec7",
   "metadata": {},
   "source": [
    "**Endpoint**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0d85217c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Arn: arn:aws:sagemaker:us-east-1:622343165275:endpoint/p5-bert-uc--2022-09-16-18-09-53-901\n"
     ]
    }
   ],
   "source": [
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name_p5, EndpointConfigName=endpoint_name_p5\n",
    ")\n",
    "\n",
    "print(\"Endpoint Arn: \" + create_endpoint_response[\"EndpointArn\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "81f5e1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SINGLE:Model:endpoint:Triton:Status: Creating\n",
      "Single:model:triton:Status: Creating\n",
      "Single:model:triton:Status: Creating\n",
      "Single:model:triton:Status: Creating\n",
      "Single:model:triton:Status: Creating\n",
      "Single:model:triton:Status: Creating\n",
      "Single:model:triton:Status: Creating\n",
      "Single:model:triton:Status: Creating\n",
      "Single:model:triton:Status: Creating\n",
      "Single:model:triton:Status: Creating\n",
      "Single:model:triton:Status: InService\n",
      "Arn: arn:aws:sagemaker:us-east-1:622343165275:endpoint/p5-bert-uc--2022-09-16-18-09-53-901\n",
      "Single:model:triton:Status: InService\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name_p5)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"SINGLE:Model:endpoint:Triton:Status: \" + status)\n",
    "\n",
    "while status == \"Creating\":\n",
    "    time.sleep(60)\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpoint_name_p5)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "    print(\"Single:model:triton:Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp[\"EndpointArn\"])\n",
    "print(\"Single:model:triton:Status: \" + status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcb90ea",
   "metadata": {},
   "source": [
    "**Now Invoke The endpoint**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "898da12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tritonclient.http as httpclient\n",
    "from transformers import BertTokenizer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def tokenize_text(text, enc, max_length=512):\n",
    "    #enc = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    print(f\"Tokenize:text:why??::max_length={max_length}::Tokenizer={enc}\")\n",
    "    encoded_text = enc(text, padding=\"max_length\", max_length=max_length)\n",
    "    return encoded_text[\"input_ids\"], encoded_text[\"attention_mask\"]\n",
    "\n",
    "\n",
    "def _get_sample_tokenized_text_binary(text, input_names, output_names, enc, max_length=512):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    inputs.append(httpclient.InferInput(input_names[0], [1, max_length], \"INT32\"))\n",
    "    inputs.append(httpclient.InferInput(input_names[1], [1, max_length], \"INT32\"))\n",
    "    indexed_tokens, attention_mask = tokenize_text(text,enc)\n",
    "\n",
    "    indexed_tokens = np.array(indexed_tokens, dtype=np.int32)\n",
    "    indexed_tokens = np.expand_dims(indexed_tokens, axis=0)\n",
    "    inputs[0].set_data_from_numpy(indexed_tokens, binary_data=True)\n",
    "\n",
    "    attention_mask = np.array(attention_mask, dtype=np.int32)\n",
    "    attention_mask = np.expand_dims(attention_mask, axis=0)\n",
    "    inputs[1].set_data_from_numpy(attention_mask, binary_data=True)\n",
    "\n",
    "    outputs.append(httpclient.InferRequestedOutput(output_names[0], binary_data=True))\n",
    "    outputs.append(httpclient.InferRequestedOutput(output_names[1], binary_data=True))\n",
    "    request_body, header_length = httpclient.InferenceServerClient.generate_request_body(\n",
    "        inputs, outputs=outputs\n",
    "    )\n",
    "    return request_body, header_length\n",
    "\n",
    "\n",
    "def get_sample_tokenized_text_binary_pt(text, enc, max_length=512):\n",
    "    return _get_sample_tokenized_text_binary(\n",
    "        text, [\"INPUT__0\", \"INPUT__1\"], [\"OUTPUT__0\", \"1634__1\"], enc, max_length\n",
    "    )\n",
    "\n",
    "\n",
    "def get_sample_tokenized_text_binary_trt(text, enc):\n",
    "    return _get_sample_tokenized_text_binary(text, [\"token_ids\", \"attn_mask\"], [\"output\", \"1634\"], enc, max_length)\n",
    "\n",
    "def get_decoded_text(tensors_tokens, enc):\n",
    "    return_text=tokenizer.batch_decode(gen_tokens)[0]\n",
    "    return return_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "32d674e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leverage the Tokenizer=PreTrainedTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_len=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})::max_seq_length=512:: create above when creating the model \n",
      "Tokenize:text:why??::max_length=512::Tokenizer=PreTrainedTokenizerFast(name_or_path='bert-large-uncased', vocab_size=30522, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n",
      "dict_keys(['model_name', 'model_version', 'outputs'])\n",
      "CPU times: user 211 ms, sys: 27.3 ms, total: 238 ms\n",
      "Wall time: 519 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import json\n",
    "max_seq_length=512\n",
    "text_triton = \"Triton Inference Server provides a cloud and edge inferencing solution optimized for both CPUs and GPUs.\"\n",
    "print(f\"Leverage the Tokenizer={enc}::max_seq_length={max_seq_length}:: create above when creating the model \")\n",
    "\n",
    "input_ids, attention_mask = tokenize_text(text_triton, tokenizer, max_length=max_seq_length)\n",
    "\n",
    "payload = {\n",
    "    \"inputs\": [\n",
    "        {\"name\": \"INPUT__0\", \"shape\": [1, max_seq_length], \"datatype\": \"INT32\", \"data\": input_ids},\n",
    "        {\"name\": \"INPUT__1\", \"shape\": [1, max_seq_length], \"datatype\": \"INT32\", \"data\": attention_mask},\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = runtime_sm_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name_p5, ContentType=\"application/octet-stream\", Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "output = json.loads(response[\"Body\"].read().decode(\"utf8\"))\n",
    "\n",
    "print(output.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ed92b242",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.4471989870071411,\n",
       " 0.337833970785141,\n",
       " -0.18249152600765228,\n",
       " -0.1867922991514206,\n",
       " 0.32078203558921814,\n",
       " 0.8711028099060059,\n",
       " 0.17235425114631653,\n",
       " -0.5893635749816895,\n",
       " 0.26671886444091797,\n",
       " -0.06457437574863434,\n",
       " -0.03806910291314125,\n",
       " -0.1377534419298172,\n",
       " -0.2331186980009079,\n",
       " -1.0004020929336548,\n",
       " 0.2067660540342331,\n",
       " 0.6279619932174683,\n",
       " -0.23859216272830963,\n",
       " 0.6072220802307129,\n",
       " 0.08589115738868713,\n",
       " -0.47479569911956787,\n",
       " -0.016673872247338295,\n",
       " 0.04392702132463455,\n",
       " -0.5811214447021484,\n",
       " -0.07257696986198425,\n",
       " -0.2536969482898712,\n",
       " 0.1400335133075714,\n",
       " -0.05290088802576065,\n",
       " -0.16839829087257385,\n",
       " 0.6422528028488159,\n",
       " -0.21113884449005127,\n",
       " -0.2637954354286194,\n",
       " 0.30578044056892395,\n",
       " -0.11204861104488373,\n",
       " -0.5515584945678711,\n",
       " -0.12893611192703247,\n",
       " 0.7867868542671204,\n",
       " 0.05056419223546982,\n",
       " 0.4449392855167389,\n",
       " -0.9341664910316467,\n",
       " -0.23110724985599518,\n",
       " -0.271898478269577,\n",
       " 0.34832245111465454,\n",
       " 0.3622068166732788,\n",
       " -0.911349356174469,\n",
       " 0.2844811975955963,\n",
       " 0.707587718963623,\n",
       " -0.41299477219581604,\n",
       " 0.1964031308889389,\n",
       " 0.23099391162395477,\n",
       " 0.4905405342578888,\n",
       " 0.04095259681344032,\n",
       " 0.12575386464595795,\n",
       " -0.320840448141098,\n",
       " -0.4143877327442169,\n",
       " 0.27459943294525146,\n",
       " 0.9196459054946899,\n",
       " 0.1524278223514557,\n",
       " -0.21744903922080994,\n",
       " -0.12509003281593323,\n",
       " -0.2419794648885727,\n",
       " 0.44868624210357666,\n",
       " -0.44727227091789246,\n",
       " -0.7104277610778809,\n",
       " -0.013915878720581532,\n",
       " -0.2410355806350708,\n",
       " 0.6513211727142334,\n",
       " 0.5752782821655273,\n",
       " 0.31489697098731995,\n",
       " -0.20167416334152222,\n",
       " 0.5965295433998108,\n",
       " 0.07997474074363708,\n",
       " 0.5450897216796875,\n",
       " 0.3994375765323639,\n",
       " -0.04049426317214966,\n",
       " -0.4171146750450134,\n",
       " -0.19291050732135773,\n",
       " -0.922330379486084,\n",
       " -0.31296685338020325,\n",
       " -0.67184978723526,\n",
       " -0.43216270208358765,\n",
       " 0.19388172030448914,\n",
       " 0.2063332349061966,\n",
       " -0.21057923138141632,\n",
       " 0.10455533117055893,\n",
       " -0.21029840409755707,\n",
       " 0.2952425181865692,\n",
       " -0.26155170798301697,\n",
       " 0.06362077593803406,\n",
       " -0.8435340523719788,\n",
       " 0.16716782748699188,\n",
       " -0.39817631244659424,\n",
       " 0.27894484996795654,\n",
       " 0.5905508995056152,\n",
       " 0.5304151773452759,\n",
       " -0.5212888121604919,\n",
       " 0.6799615621566772,\n",
       " -0.37112686038017273,\n",
       " 0.9911031723022461,\n",
       " 0.3935025930404663,\n",
       " 0.7454338073730469,\n",
       " 0.40670543909072876,\n",
       " -0.9980747699737549,\n",
       " -0.5633459687232971,\n",
       " 0.4142659604549408,\n",
       " -0.23348423838615417,\n",
       " 0.08971596509218216,\n",
       " 0.2845161557197571,\n",
       " 0.11197818070650101,\n",
       " 0.27494269609451294,\n",
       " -0.033593643456697464,\n",
       " 0.06621820479631424,\n",
       " 0.20460383594036102,\n",
       " -0.31089359521865845,\n",
       " -0.11455164849758148,\n",
       " 0.27741506695747375,\n",
       " -0.23610781133174896,\n",
       " -0.7115929126739502,\n",
       " 0.09148425608873367,\n",
       " 0.0405779629945755,\n",
       " 0.5576881766319275,\n",
       " -0.9605026245117188,\n",
       " -0.4441398084163666,\n",
       " 0.4852745532989502,\n",
       " 0.12105919420719147,\n",
       " -0.16551660001277924,\n",
       " -0.29894402623176575,\n",
       " 0.13597901165485382,\n",
       " 0.7040570974349976,\n",
       " -0.5649731755256653,\n",
       " -0.4160013794898987,\n",
       " 0.7765767574310303,\n",
       " 0.45139482617378235,\n",
       " 0.34308838844299316,\n",
       " 0.7765421271324158,\n",
       " 0.1989733874797821,\n",
       " -0.19597145915031433,\n",
       " -0.02715804986655712,\n",
       " -0.13644888997077942,\n",
       " 0.1773727685213089,\n",
       " 0.2741064727306366,\n",
       " -1.2216168642044067,\n",
       " -0.42999860644340515,\n",
       " -0.46713873744010925,\n",
       " 0.9150181412696838,\n",
       " 0.4925577640533447,\n",
       " 0.8827351927757263,\n",
       " -0.175002321600914,\n",
       " -0.8920252323150635,\n",
       " -0.23488986492156982,\n",
       " -0.461496502161026,\n",
       " 0.4746457636356354,\n",
       " 0.36737149953842163,\n",
       " -0.2850940525531769,\n",
       " -0.01716097630560398,\n",
       " 0.010260139591991901,\n",
       " -0.17106613516807556,\n",
       " -0.7762380242347717,\n",
       " 0.9405664801597595,\n",
       " -0.36135637760162354,\n",
       " 0.3494105339050293,\n",
       " 0.6432245969772339,\n",
       " 0.1247381642460823,\n",
       " -0.234538733959198,\n",
       " -0.28673192858695984,\n",
       " 0.4161677956581116,\n",
       " -0.33298051357269287,\n",
       " -0.5543251037597656,\n",
       " 0.5727287530899048,\n",
       " -0.8906505703926086,\n",
       " -0.6096687912940979,\n",
       " -0.07500861585140228,\n",
       " 0.12409041821956635,\n",
       " 0.3269844651222229,\n",
       " 0.4636983275413513,\n",
       " -0.17449966073036194,\n",
       " 0.09863781929016113,\n",
       " -0.2022075057029724,\n",
       " -0.11717211455106735,\n",
       " 0.06753066927194595,\n",
       " 0.5161523222923279,\n",
       " -0.12438145279884338,\n",
       " -0.8150772452354431,\n",
       " 0.018228530883789062,\n",
       " 0.4832160174846649,\n",
       " 0.34881654381752014,\n",
       " 0.5695779323577881,\n",
       " -0.6078699231147766,\n",
       " -0.23577426373958588,\n",
       " -0.24756313860416412,\n",
       " -0.4000242352485657,\n",
       " -0.7473559379577637,\n",
       " 0.4457734525203705,\n",
       " 0.06513654440641403,\n",
       " -0.22204753756523132,\n",
       " 0.4184019863605499,\n",
       " -0.3912333548069,\n",
       " 0.4964160621166229,\n",
       " 0.6449246406555176,\n",
       " 0.23830516636371613,\n",
       " -0.2102915197610855,\n",
       " 0.01643548347055912,\n",
       " -0.1195274293422699,\n",
       " -0.038850054144859314,\n",
       " 0.5405601859092712,\n",
       " 0.41098877787590027,\n",
       " 0.7947524785995483,\n",
       " 0.04686205834150314,\n",
       " 0.3739304840564728,\n",
       " -0.7417510747909546,\n",
       " 0.037544794380664825,\n",
       " 0.08665122091770172,\n",
       " -0.09034810960292816,\n",
       " -0.0738733783364296,\n",
       " 0.649245023727417,\n",
       " -0.14157986640930176,\n",
       " -0.9195590019226074,\n",
       " -0.15843038260936737,\n",
       " -0.08795497566461563,\n",
       " 0.5450043082237244,\n",
       " 0.10128208994865417,\n",
       " 0.7088544368743896,\n",
       " -0.5729035139083862,\n",
       " -0.5921100378036499,\n",
       " -0.024375414475798607,\n",
       " -0.39292702078819275,\n",
       " 0.33571934700012207,\n",
       " 1.04441237449646,\n",
       " 0.5770500898361206,\n",
       " -0.04923059418797493,\n",
       " -0.5575367212295532,\n",
       " -0.016640430316329002,\n",
       " 0.061489153653383255,\n",
       " -0.4526273012161255,\n",
       " 0.3031458854675293,\n",
       " 0.3892691135406494,\n",
       " 0.08874418586492538,\n",
       " 0.18764032423496246,\n",
       " -0.054897841066122055,\n",
       " 0.18168404698371887,\n",
       " 0.4466710090637207,\n",
       " -1.0028061866760254,\n",
       " -0.07024871557950974,\n",
       " 0.24651116132736206,\n",
       " 0.7043933868408203,\n",
       " 1.0371438264846802,\n",
       " -0.35810667276382446,\n",
       " 0.09684503078460693,\n",
       " 0.15795667469501495,\n",
       " -0.441497266292572,\n",
       " 0.9048190116882324,\n",
       " 0.536085844039917,\n",
       " 0.33600589632987976,\n",
       " -0.4703940451145172,\n",
       " 0.3264979124069214,\n",
       " 0.017634756863117218,\n",
       " -0.630216121673584,\n",
       " 0.14985617995262146,\n",
       " -0.12415481358766556,\n",
       " 0.029517844319343567,\n",
       " -0.566296398639679,\n",
       " 0.9100966453552246,\n",
       " 0.39622440934181213,\n",
       " -0.0547216422855854,\n",
       " 1.014493703842163,\n",
       " 0.7191777229309082,\n",
       " 0.5819230675697327,\n",
       " 0.3973703682422638,\n",
       " -0.28365203738212585,\n",
       " -0.9345409274101257,\n",
       " 0.34863099455833435,\n",
       " -0.9163963794708252,\n",
       " -0.12120627611875534,\n",
       " 0.3215041756629944,\n",
       " 0.6777503490447998,\n",
       " -0.5486400127410889,\n",
       " -0.3321591913700104,\n",
       " 0.9688162803649902,\n",
       " -0.07436452060937881,\n",
       " -0.493160605430603,\n",
       " -0.8489237427711487,\n",
       " 0.1510460376739502,\n",
       " 0.18796870112419128,\n",
       " 0.185940220952034,\n",
       " 0.2939177453517914,\n",
       " 0.36140766739845276,\n",
       " 0.44443362951278687,\n",
       " -0.3036964535713196,\n",
       " 1.1248747110366821,\n",
       " 0.2742585241794586,\n",
       " -0.4187951385974884,\n",
       " -0.6396521925926208,\n",
       " -0.1963827908039093,\n",
       " 0.4354134798049927,\n",
       " 0.025743108242750168,\n",
       " 0.7537137866020203,\n",
       " -0.6653603315353394,\n",
       " 0.07845165580511093,\n",
       " -0.08390972018241882,\n",
       " -0.36710649728775024,\n",
       " 0.1921808272600174,\n",
       " 0.783412516117096,\n",
       " 0.607661783695221,\n",
       " 0.2426314353942871,\n",
       " 0.05782901123166084,\n",
       " 0.5273898243904114,\n",
       " 1.2298909425735474,\n",
       " 1.1887667179107666,\n",
       " 0.5870838165283203,\n",
       " 0.13967587053775787,\n",
       " 0.5579794049263,\n",
       " -0.7670117020606995,\n",
       " 0.6134117245674133,\n",
       " 0.3704683482646942,\n",
       " -0.48681414127349854,\n",
       " -0.727206826210022,\n",
       " 0.2904522120952606,\n",
       " -0.2567310929298401,\n",
       " -0.4394034147262573,\n",
       " -0.9697468280792236,\n",
       " -0.16285456717014313,\n",
       " -1.0428270101547241,\n",
       " -0.7887163758277893,\n",
       " -0.20720341801643372,\n",
       " 0.353608101606369,\n",
       " -0.7921478152275085,\n",
       " 0.3145379424095154,\n",
       " -0.1109633594751358,\n",
       " -2.0697031021118164,\n",
       " 0.4148084819316864,\n",
       " 0.4825013279914856,\n",
       " 0.1572856456041336,\n",
       " 0.024212567135691643,\n",
       " -0.020168287679553032,\n",
       " 0.7051973342895508,\n",
       " 0.5159284472465515,\n",
       " 0.20292794704437256,\n",
       " -0.09088333696126938,\n",
       " 1.0594841241836548,\n",
       " -0.47607898712158203,\n",
       " 0.7075425982475281,\n",
       " 0.4538332223892212,\n",
       " 0.4477240741252899,\n",
       " 0.42674949765205383,\n",
       " 1.048729419708252,\n",
       " -0.17366060614585876,\n",
       " 0.460570365190506,\n",
       " -0.006360695231705904,\n",
       " -0.9931479692459106,\n",
       " 0.45373964309692383,\n",
       " -0.2228447049856186,\n",
       " -0.726690411567688,\n",
       " 0.5919947624206543,\n",
       " 0.04507220536470413,\n",
       " -0.10914761573076248,\n",
       " -0.5355623364448547,\n",
       " 0.4232383966445923,\n",
       " 0.5870340466499329,\n",
       " -0.568674623966217,\n",
       " 0.29029133915901184,\n",
       " 0.4073449671268463,\n",
       " 0.4069296419620514,\n",
       " -0.7471120357513428,\n",
       " 0.07021821290254593,\n",
       " 0.48769721388816833,\n",
       " -0.27940571308135986,\n",
       " -0.732069730758667,\n",
       " -1.2397551536560059,\n",
       " -0.22892314195632935,\n",
       " 0.8431639671325684,\n",
       " -0.6933753490447998,\n",
       " -0.30926796793937683,\n",
       " -0.9858009219169617,\n",
       " -0.6631206274032593,\n",
       " -0.12976352870464325,\n",
       " -0.33318132162094116,\n",
       " 0.23518072068691254,\n",
       " 0.34233927726745605,\n",
       " 0.07233668863773346,\n",
       " -0.45329979062080383,\n",
       " -0.2000623494386673,\n",
       " -0.23503199219703674,\n",
       " -0.1851397454738617,\n",
       " -1.007652997970581,\n",
       " 0.392503947019577,\n",
       " -0.18185484409332275,\n",
       " 0.50789874792099,\n",
       " 0.20163583755493164,\n",
       " 0.18260720372200012,\n",
       " -0.21723489463329315,\n",
       " 0.2781158685684204,\n",
       " 0.6897745132446289,\n",
       " -0.12411577999591827,\n",
       " -0.29182082414627075,\n",
       " -0.48108112812042236,\n",
       " -0.14799727499485016,\n",
       " -0.247246652841568,\n",
       " -0.23792193830013275,\n",
       " 0.21808557212352753,\n",
       " 0.23577328026294708,\n",
       " -0.028104137629270554,\n",
       " 0.37529656291007996,\n",
       " -0.48237231373786926,\n",
       " -0.1709061712026596,\n",
       " 0.929652988910675,\n",
       " -0.09307222813367844,\n",
       " -1.1727488040924072,\n",
       " -1.039528250694275,\n",
       " -0.0009062463068403304,\n",
       " 0.19706372916698456,\n",
       " 0.015475749969482422,\n",
       " -0.641356885433197,\n",
       " 0.9732972383499146,\n",
       " -0.15878383815288544,\n",
       " -0.9851582646369934,\n",
       " -0.09596755355596542,\n",
       " 0.8737438917160034,\n",
       " 0.037202268838882446,\n",
       " -0.2995707094669342,\n",
       " -0.22306358814239502,\n",
       " -0.012123572640120983,\n",
       " 0.8512201905250549,\n",
       " 0.05439099669456482,\n",
       " -0.26875635981559753,\n",
       " 0.5803765058517456,\n",
       " -0.10826392471790314,\n",
       " -0.2768206298351288,\n",
       " 0.6240940093994141,\n",
       " 1.3768802881240845,\n",
       " -0.6036564707756042,\n",
       " 0.27190569043159485,\n",
       " 0.22989654541015625,\n",
       " -0.4981890320777893,\n",
       " 0.3590271472930908,\n",
       " -0.009164177812635899,\n",
       " -0.703536868095398,\n",
       " -0.19440540671348572,\n",
       " 0.2174481898546219,\n",
       " -0.3257687985897064,\n",
       " 0.6361746191978455,\n",
       " -0.6304510235786438,\n",
       " 0.11755072325468063,\n",
       " -0.08089440315961838,\n",
       " -0.7950376868247986,\n",
       " -0.261026531457901,\n",
       " 0.3401847779750824,\n",
       " 0.840207040309906,\n",
       " 0.14107123017311096,\n",
       " 0.8289647102355957,\n",
       " -0.26840588450431824,\n",
       " -0.4876329004764557,\n",
       " 0.017791828140616417,\n",
       " -0.6417235732078552,\n",
       " 0.12816715240478516,\n",
       " 0.17878851294517517,\n",
       " -0.27309805154800415,\n",
       " -0.0020449396688491106,\n",
       " -0.12002444267272949,\n",
       " 0.48338744044303894,\n",
       " -0.2937834858894348,\n",
       " -0.3522127866744995,\n",
       " 1.487264633178711,\n",
       " -0.6078321933746338,\n",
       " 0.511600911617279,\n",
       " -1.7568752765655518,\n",
       " -0.7361083626747131,\n",
       " 0.20117688179016113,\n",
       " 0.35306456685066223,\n",
       " -1.0836020708084106,\n",
       " 0.2839377522468567,\n",
       " 0.023331329226493835,\n",
       " -0.6498609781265259,\n",
       " 0.06743393838405609,\n",
       " -0.4496530294418335,\n",
       " 0.24658764898777008,\n",
       " -0.2027714103460312,\n",
       " -0.14041997492313385,\n",
       " -0.18829345703125,\n",
       " -0.6443983316421509,\n",
       " 0.44421786069869995,\n",
       " -0.38646483421325684,\n",
       " -0.45378199219703674,\n",
       " -0.6317684054374695,\n",
       " 1.3184877634048462,\n",
       " 0.367311030626297,\n",
       " -0.34892380237579346,\n",
       " -0.1043209508061409,\n",
       " -0.024700036272406578,\n",
       " 0.051243871450424194,\n",
       " -0.14745396375656128,\n",
       " -0.2437080293893814,\n",
       " -1.3200184106826782,\n",
       " 0.5698771476745605,\n",
       " 0.30662626028060913,\n",
       " -0.017847247421741486,\n",
       " -0.30052250623703003,\n",
       " 0.5136590003967285,\n",
       " -0.9393507838249207,\n",
       " 0.28879427909851074,\n",
       " 3.5330777168273926,\n",
       " -0.8410101532936096,\n",
       " -0.030776286497712135,\n",
       " 0.26757538318634033,\n",
       " -0.6287545561790466,\n",
       " -0.4844852685928345,\n",
       " -0.2195838987827301,\n",
       " -1.1234703063964844,\n",
       " -0.45344048738479614,\n",
       " 1.233665943145752,\n",
       " 0.22185584902763367,\n",
       " -0.1807849407196045,\n",
       " -0.5774424076080322,\n",
       " -0.27651000022888184,\n",
       " -0.8229734301567078,\n",
       " -0.19832973182201385,\n",
       " -0.30869168043136597,\n",
       " -0.5248482823371887,\n",
       " -0.4888782203197479,\n",
       " -0.33873143792152405,\n",
       " 0.20070376992225647,\n",
       " -0.24258482456207275,\n",
       " -0.30678659677505493,\n",
       " -0.38146743178367615,\n",
       " -0.7444150447845459,\n",
       " 0.027151798829436302,\n",
       " 0.43233534693717957,\n",
       " -0.4154685437679291,\n",
       " 0.025152040645480156,\n",
       " -0.5984070897102356,\n",
       " 0.31508803367614746,\n",
       " 0.9599103927612305,\n",
       " -0.32392454147338867,\n",
       " 0.2767959535121918,\n",
       " 0.24111779034137726,\n",
       " -1.053036093711853,\n",
       " -0.07309921830892563,\n",
       " 0.524817168712616,\n",
       " -0.24395762383937836,\n",
       " 0.3420567512512207,\n",
       " 0.6146640777587891,\n",
       " 0.07048920542001724,\n",
       " 0.3202421963214874,\n",
       " -0.8812935948371887,\n",
       " -1.5188908576965332,\n",
       " 0.15158267319202423,\n",
       " -0.3032478094100952,\n",
       " 0.29823926091194153,\n",
       " 0.6548852324485779,\n",
       " 0.6279541850090027,\n",
       " 0.3882916569709778,\n",
       " 1.1272512674331665,\n",
       " 0.5593950748443604,\n",
       " 0.6850253939628601,\n",
       " -0.29389962553977966,\n",
       " 0.6211252808570862,\n",
       " -0.4085462987422943,\n",
       " -0.9702088832855225,\n",
       " -0.5171200633049011,\n",
       " 0.4860158860683441,\n",
       " 0.5339854955673218,\n",
       " -0.6329067349433899,\n",
       " -0.2670170068740845,\n",
       " -0.7039741277694702,\n",
       " -0.5918809175491333,\n",
       " 0.14554180204868317,\n",
       " -0.6338706016540527,\n",
       " 0.4303288161754608,\n",
       " -0.7407158017158508,\n",
       " -0.3051813244819641,\n",
       " 0.034763459116220474,\n",
       " -0.12210546433925629,\n",
       " 0.5869418978691101,\n",
       " 0.52289879322052,\n",
       " 0.38135671615600586,\n",
       " 1.0527206659317017,\n",
       " -0.10708779096603394,\n",
       " -1.256535530090332,\n",
       " -1.6474289894104004,\n",
       " -0.18632352352142334,\n",
       " 0.5680813789367676,\n",
       " 0.3282635509967804,\n",
       " 0.2589636743068695,\n",
       " -0.33758288621902466,\n",
       " 0.3988112509250641,\n",
       " -0.4759068489074707,\n",
       " -0.4033982455730438,\n",
       " 0.03343358635902405,\n",
       " -0.34725210070610046,\n",
       " 0.34040215611457825,\n",
       " -0.38674411177635193,\n",
       " 0.07666897028684616,\n",
       " 0.15551471710205078,\n",
       " 0.47106191515922546,\n",
       " 1.345163106918335,\n",
       " -0.4084891676902771,\n",
       " 0.3975812792778015,\n",
       " -0.4962477684020996,\n",
       " -0.19483068585395813,\n",
       " 0.4001941382884979,\n",
       " -0.1737227588891983,\n",
       " -0.5510486364364624,\n",
       " -0.8920404314994812,\n",
       " -0.3257114589214325,\n",
       " 0.005335917696356773,\n",
       " -0.09977442771196365,\n",
       " -0.31933099031448364,\n",
       " -0.8483879566192627,\n",
       " 0.06705105304718018,\n",
       " 0.4322080612182617,\n",
       " 1.1435925960540771,\n",
       " -0.07731906324625015,\n",
       " 0.19987444579601288,\n",
       " 1.2691057920455933,\n",
       " 0.3661527633666992,\n",
       " -0.040438462048769,\n",
       " -0.3117540180683136,\n",
       " 0.9117517471313477,\n",
       " 0.2756732404232025,\n",
       " -0.042583853006362915,\n",
       " 1.9620261192321777,\n",
       " 0.8407147526741028,\n",
       " -0.9177184104919434,\n",
       " -0.4616604745388031,\n",
       " -0.07084131240844727,\n",
       " -0.4908592104911804,\n",
       " 0.02542373724281788,\n",
       " 0.0004814181011170149,\n",
       " 0.7235596776008606,\n",
       " -0.47925880551338196,\n",
       " -0.7423931956291199,\n",
       " -0.005875980015844107,\n",
       " -0.560615062713623,\n",
       " 0.9309077262878418,\n",
       " -0.1244790330529213,\n",
       " 0.09237252175807953,\n",
       " -0.5275636911392212,\n",
       " -0.3850323557853699,\n",
       " 0.9999313950538635,\n",
       " -0.37800657749176025,\n",
       " 0.3570760190486908,\n",
       " 0.09910697489976883,\n",
       " -0.3145195543766022,\n",
       " -0.15971249341964722,\n",
       " -0.8689588308334351,\n",
       " -1.0654202699661255,\n",
       " 0.16370238363742828,\n",
       " 0.11303465813398361,\n",
       " -0.2914072871208191,\n",
       " -0.36657994985580444,\n",
       " -0.5204228162765503,\n",
       " 1.039963722229004,\n",
       " 0.289791077375412,\n",
       " -0.01600467972457409,\n",
       " -0.636987030506134,\n",
       " -1.1018095016479492,\n",
       " -0.20792995393276215,\n",
       " -0.2674020528793335,\n",
       " -0.8733808994293213,\n",
       " -0.39331644773483276,\n",
       " 0.19421878457069397,\n",
       " -0.008990679867565632,\n",
       " -0.36189383268356323,\n",
       " 0.1845426857471466,\n",
       " -0.4834144413471222,\n",
       " -0.8280614018440247,\n",
       " 1.0828715562820435,\n",
       " 0.7993700504302979,\n",
       " -0.11944209784269333,\n",
       " -0.5268149971961975,\n",
       " 0.4515030086040497,\n",
       " -0.7300760746002197,\n",
       " 0.10705771297216415,\n",
       " 0.42418092489242554,\n",
       " -0.14887474477291107,\n",
       " -0.09161467850208282,\n",
       " 0.31442439556121826,\n",
       " 0.9564956426620483,\n",
       " 0.8224374055862427,\n",
       " -0.31530603766441345,\n",
       " -0.7119831442832947,\n",
       " -0.03860742971301079,\n",
       " -0.11415867507457733,\n",
       " 0.4117213785648346,\n",
       " -0.5865216851234436,\n",
       " -0.9725049734115601,\n",
       " 0.39327290654182434,\n",
       " -0.14606808125972748,\n",
       " 1.4457533359527588,\n",
       " 0.2506959140300751,\n",
       " 0.7295678853988647,\n",
       " -0.04114025831222534,\n",
       " 1.2124884128570557,\n",
       " -0.6912539601325989,\n",
       " -0.29352760314941406,\n",
       " 0.3955034017562866,\n",
       " -1.134324073791504,\n",
       " -0.48598620295524597,\n",
       " -0.3934626579284668,\n",
       " -0.44421905279159546,\n",
       " -0.7032271027565002,\n",
       " -0.5365797281265259,\n",
       " 0.7316368222236633,\n",
       " 0.3130369782447815,\n",
       " 0.16236713528633118,\n",
       " 0.35205426812171936,\n",
       " -0.3020896911621094,\n",
       " 0.5259050130844116,\n",
       " 0.47448137402534485,\n",
       " 0.3400506377220154,\n",
       " -0.33796945214271545,\n",
       " -0.249041348695755,\n",
       " 0.001796563039533794,\n",
       " -0.38046741485595703,\n",
       " -0.32875099778175354,\n",
       " -0.335965096950531,\n",
       " 0.6419379115104675,\n",
       " -0.3080253601074219,\n",
       " -0.4416622519493103,\n",
       " 0.3769664764404297,\n",
       " -0.4983822703361511,\n",
       " -0.5174685120582581,\n",
       " 0.19006001949310303,\n",
       " -0.35746559500694275,\n",
       " 1.1880804300308228,\n",
       " 0.09499305486679077,\n",
       " 1.079991102218628,\n",
       " -0.49367842078208923,\n",
       " -0.43092024326324463,\n",
       " 0.15274131298065186,\n",
       " 0.15560346841812134,\n",
       " 0.5706004500389099,\n",
       " 0.23364876210689545,\n",
       " -0.16062583029270172,\n",
       " 2.934493064880371,\n",
       " 0.2794678211212158,\n",
       " 0.38162872195243835,\n",
       " 0.21795272827148438,\n",
       " -0.5971975922584534,\n",
       " -0.7949930429458618,\n",
       " -0.6369667053222656,\n",
       " -0.15885964035987854,\n",
       " 0.40835508704185486,\n",
       " 1.9545730352401733,\n",
       " 0.5652443766593933,\n",
       " -0.07608160376548767,\n",
       " 0.11729021370410919,\n",
       " 0.07527533918619156,\n",
       " 0.16948185861110687,\n",
       " -0.8501560688018799,\n",
       " -1.0907422304153442,\n",
       " 0.34898748993873596,\n",
       " 0.008172834292054176,\n",
       " 0.315592885017395,\n",
       " -0.1640084683895111,\n",
       " -0.48845383524894714,\n",
       " -0.06896849721670151,\n",
       " -0.09117475897073746,\n",
       " 0.3862726092338562,\n",
       " 0.3559025824069977,\n",
       " -0.3593657910823822,\n",
       " 0.6928740739822388,\n",
       " 0.42580193281173706,\n",
       " -0.546772837638855,\n",
       " 0.429407000541687,\n",
       " 0.21781831979751587,\n",
       " 0.537306547164917,\n",
       " -0.45144400000572205,\n",
       " -0.22061027586460114,\n",
       " -0.03908821567893028,\n",
       " -0.438358336687088,\n",
       " 0.18444697558879852,\n",
       " -0.7384244203567505,\n",
       " -0.5102630257606506,\n",
       " 0.5138769745826721,\n",
       " 1.0691324472427368,\n",
       " 0.8977082967758179,\n",
       " -0.18902739882469177,\n",
       " -0.7009614706039429,\n",
       " -0.4758504629135132,\n",
       " -0.023669607937335968,\n",
       " 0.2851443290710449,\n",
       " -0.1053842306137085,\n",
       " 0.12384584546089172,\n",
       " 0.02646593749523163,\n",
       " -0.37771013379096985,\n",
       " -0.4612596035003662,\n",
       " -1.1996726989746094,\n",
       " 0.687531590461731,\n",
       " 0.5195532441139221,\n",
       " -0.921008825302124,\n",
       " 0.5187345743179321,\n",
       " -0.3283698260784149,\n",
       " 0.7157884836196899,\n",
       " -0.245234876871109,\n",
       " -0.12848885357379913,\n",
       " -0.2429543286561966,\n",
       " 1.504120111465454,\n",
       " 0.056862860918045044,\n",
       " -0.023444922640919685,\n",
       " 0.7151116132736206,\n",
       " 0.20173083245754242,\n",
       " 0.22970454394817352,\n",
       " 0.5928652882575989,\n",
       " -0.07741709053516388,\n",
       " -0.07289227843284607,\n",
       " 0.4022737741470337,\n",
       " -0.3420562744140625,\n",
       " -0.09045174717903137,\n",
       " 0.045294228941202164,\n",
       " 0.5321696400642395,\n",
       " 0.5454322695732117,\n",
       " -0.052991848438978195,\n",
       " -0.8126137256622314,\n",
       " -0.6191069483757019,\n",
       " 0.35711514949798584,\n",
       " -0.5282539129257202,\n",
       " -0.2118804007768631,\n",
       " 0.32950592041015625,\n",
       " 1.04133939743042,\n",
       " -0.543548047542572,\n",
       " -0.06487118452787399,\n",
       " 0.5927451252937317,\n",
       " 0.751079797744751,\n",
       " 0.09301215410232544,\n",
       " 1.301193118095398,\n",
       " -1.0506399869918823,\n",
       " 0.1348312348127365,\n",
       " 1.1680147647857666,\n",
       " -0.03144879639148712,\n",
       " 0.0023510854225605726,\n",
       " -0.4427950978279114,\n",
       " 0.3041944205760956,\n",
       " -0.27959564328193665,\n",
       " 0.26502320170402527,\n",
       " 0.1171136125922203,\n",
       " -1.21697998046875,\n",
       " -0.3243309557437897,\n",
       " 0.10469286143779755,\n",
       " 0.07509196549654007,\n",
       " -0.6518372297286987,\n",
       " -1.0904878377914429,\n",
       " 1.308241605758667,\n",
       " -0.663432776927948,\n",
       " -0.6700096130371094,\n",
       " 0.10880238562822342,\n",
       " -0.04380584508180618,\n",
       " 0.08958195894956589,\n",
       " -0.09325079619884491,\n",
       " -0.6895375847816467,\n",
       " -0.1101115494966507,\n",
       " -0.5539480447769165,\n",
       " 0.858070433139801,\n",
       " -0.977700412273407,\n",
       " 0.37857452034950256,\n",
       " 0.759552001953125,\n",
       " -0.2158336043357849,\n",
       " -0.5583582520484924,\n",
       " 0.38124024868011475,\n",
       " -0.4993663430213928,\n",
       " 1.1229774951934814,\n",
       " -0.056580204516649246,\n",
       " -0.4183832108974457,\n",
       " 0.6678688526153564,\n",
       " 0.19672945141792297,\n",
       " -1.036855936050415,\n",
       " -0.6252296566963196,\n",
       " -0.8184446096420288,\n",
       " -0.057428110390901566,\n",
       " 0.8180485963821411,\n",
       " -1.1884069442749023,\n",
       " 0.30141907930374146,\n",
       " 0.2088104635477066,\n",
       " -0.10463616251945496,\n",
       " -0.8946132063865662,\n",
       " 0.15165941417217255,\n",
       " 0.29221686720848083,\n",
       " -0.40092918276786804,\n",
       " 0.9875969290733337,\n",
       " 0.24689894914627075,\n",
       " -0.4649529755115509,\n",
       " 0.08052729070186615,\n",
       " -0.29265040159225464,\n",
       " 0.20065991580486298,\n",
       " -0.8984163999557495,\n",
       " 0.31017228960990906,\n",
       " 0.36179202795028687,\n",
       " -0.05680219829082489,\n",
       " -0.21965456008911133,\n",
       " 0.6406672596931458,\n",
       " -0.7355846166610718,\n",
       " -0.08831377327442169,\n",
       " -0.0017022198298946023,\n",
       " -0.5454414486885071,\n",
       " -0.15668217837810516,\n",
       " -0.20817019045352936,\n",
       " -0.24270488321781158,\n",
       " 0.8523383140563965,\n",
       " -1.6634597778320312,\n",
       " 0.19782018661499023,\n",
       " 0.06410583108663559,\n",
       " -0.24783611297607422,\n",
       " 0.21466250717639923,\n",
       " 0.24438436329364777,\n",
       " 0.16618435084819794,\n",
       " 0.39898771047592163,\n",
       " 0.4631251096725464,\n",
       " 0.07762489467859268,\n",
       " -0.04192767292261124,\n",
       " 0.32047346234321594,\n",
       " -0.17294946312904358,\n",
       " -0.41746360063552856,\n",
       " -0.5219990015029907,\n",
       " -0.3682551383972168,\n",
       " -0.6305020451545715,\n",
       " 0.2299419790506363,\n",
       " -0.5231903791427612,\n",
       " -0.08176586031913757,\n",
       " -0.17609348893165588,\n",
       " 0.7675356268882751,\n",
       " -0.3017789125442505,\n",
       " -0.09846937656402588,\n",
       " 0.3313823640346527,\n",
       " -0.28223860263824463,\n",
       " 0.014885680750012398,\n",
       " -0.8324708342552185,\n",
       " 0.20601825416088104,\n",
       " 0.16478031873703003,\n",
       " -0.929919421672821,\n",
       " -0.30019864439964294,\n",
       " -0.592158854007721,\n",
       " 4.0530171394348145,\n",
       " -0.2439989447593689,\n",
       " -0.2908742129802704,\n",
       " -0.5052964091300964,\n",
       " 0.11150477826595306,\n",
       " 0.19659282267093658,\n",
       " 0.2986645996570587,\n",
       " -0.7087465524673462,\n",
       " 0.6650316119194031,\n",
       " -0.2941649258136749,\n",
       " 0.5595126152038574,\n",
       " -0.5251683592796326,\n",
       " 0.4887728989124298,\n",
       " 0.05889751762151718,\n",
       " 0.4683058559894562,\n",
       " 1.1295344829559326,\n",
       " -0.7741627097129822,\n",
       " -0.9298524260520935,\n",
       " 0.10547398030757904,\n",
       " -0.588926374912262,\n",
       " -0.5914996266365051,\n",
       " -0.06931716948747635,\n",
       " -0.36110368371009827,\n",
       " -0.3791101574897766,\n",
       " 0.6483224034309387,\n",
       " 0.6826115846633911,\n",
       " -0.2155928909778595,\n",
       " 0.269473671913147,\n",
       " -0.1936064511537552,\n",
       " 0.6196022033691406,\n",
       " -0.7200145125389099,\n",
       " -0.16559965908527374,\n",
       " -0.09499189257621765,\n",
       " 0.7212955355644226,\n",
       " 0.10958720743656158,\n",
       " -0.41536465287208557,\n",
       " -0.7051762938499451,\n",
       " -0.5647898316383362,\n",
       " -0.2432594895362854,\n",
       " 0.6498500108718872,\n",
       " 0.37936604022979736,\n",
       " 0.48793211579322815,\n",
       " 0.3865810036659241,\n",
       " -0.41570743918418884,\n",
       " 0.5600760579109192,\n",
       " -0.12834544479846954,\n",
       " 0.11185115575790405,\n",
       " -0.8803532123565674,\n",
       " -0.5937649607658386,\n",
       " -0.3902920186519623,\n",
       " 0.6336241960525513,\n",
       " -0.21290193498134613,\n",
       " 0.1849551945924759,\n",
       " -0.08977079391479492,\n",
       " 0.6344279050827026,\n",
       " 0.08845552802085876,\n",
       " 0.1408882737159729,\n",
       " 0.4969451427459717,\n",
       " -0.22988952696323395,\n",
       " -0.2723810076713562,\n",
       " -0.25644174218177795,\n",
       " -0.032966937869787216,\n",
       " 0.20608720183372498,\n",
       " 0.20186775922775269,\n",
       " 0.08352679759263992,\n",
       " -0.7560837268829346,\n",
       " -0.20223815739154816,\n",
       " -0.26745766401290894,\n",
       " -0.5448283553123474,\n",
       " -0.20237433910369873,\n",
       " 0.41624343395233154,\n",
       " ...]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['outputs'][0]['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6062e4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(\n",
    "    torch.tensor(output['outputs'][0]['data']), #tokenizer.decode(unscripted_output[0])\n",
    "    skip_special_tokens=True,\n",
    "    clean_up=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1745887a",
   "metadata": {},
   "source": [
    "### View Captured Data for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "14a4cb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:capture:S_capture_upload_path:=s3://sagemaker-us-east-1-622343165275/bloom/triton_models/datacapture:\n",
      "Data:capture:prefix:=bloom/triton_models/datacapture\n",
      "Found Capture Files:\n",
      "bloom/triton_models/datacapture/p5-bert-uc--2022-09-16-18-09-53-901/AllTraffic/2022/09/16/19/39-48-038-4f7b8ae0-1597-44c0-be0a-3603245c82bc.jsonl\n",
      " bloom/triton_models/datacapture/p5-bert-uc--2022-09-16-18-09-53-901/AllTraffic/2022/09/18/17/12-43-677-21d2da2d-80b0-411f-97c4-edb75f0c27ee.jsonl\n"
     ]
    }
   ],
   "source": [
    "#Note: It takes a few minutes for the capture data to appear in S3\n",
    "\n",
    "import boto3\n",
    "\n",
    "s3_client = boto3.Session().client('s3')\n",
    "\n",
    "print(f\"Data:capture:S_capture_upload_path:={s3_capture_upload_path}:\")\n",
    "# The S3 URI of where to store captured data in S3\n",
    "print(f\"Data:capture:prefix:={data_capture_prefix }\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "current_endpoint_capture_prefix = \"{}/{}\".format(data_capture_prefix, endpoint_name_p5)\n",
    "result = s3_client.list_objects(Bucket=sess_bucket, Prefix=current_endpoint_capture_prefix)\n",
    "\n",
    "capture_files = [capture_file.get(\"Key\") for capture_file in result.get(\"Contents\")]\n",
    "print(\"Found Capture Files:\")\n",
    "print(\"\\n \".join(capture_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "882d0903",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"captureData\":{\"endpointInput\":{\"observedContentType\":\"application/octet-stream\",\"mode\":\"INPUT\",\"data\":\"eyJpbnB1dHMiOiBbeyJuYW1lIjogIklOUFVUX18wIiwgInNoYXBlIjogWzEsIDUxMl0sICJkYXRhdHlwZSI6ICJJTlQzMiIsICJkYXRhIjogWzEwMSwgMjAyMywgMjAwMywgMTAzNywgNTU0MSwgMzAxNSwgNjkxMiwgMTAxMiwgMjkxNywgMTAxMCwgMjAxNywgMTAwNSwgMjIyMiwgMjAyMiwgMjQ0NSwgMTAzNywgMjU3MzIsIDEwMTIsIDIxMTUsIDI0NjYsIDIzMjMsIDIwMjIsIDIyNDEsIDIwMDYsIDE5OTYsIDI1NzMyLCAxMDEyLCAyNTczMiwgMTAyNCwgMTAzNywgMTI0NTksIDI0NjYsIDIwNTUsIDEwMzcsIDExMTcxLCA4MDAwLCAyNDY2LCAxMDI0LCAyMDA2LCAxMDM3LCAyNjAxLCAxOTk4LCAyNDE2NiwgMjMwNSwgMTAxMCwgMTk5NiwgODAwMCwgMTMxNDcsIDE5OTksIDE5OTYsIDYyODEsIDEwMTIsIDEwMiwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCwgMCw\n"
     ]
    }
   ],
   "source": [
    "def get_obj_body(obj_key):\n",
    "    return s3_client.get_object(Bucket=sess_bucket, Key=obj_key).get('Body').read().decode(\"utf-8\")\n",
    "\n",
    "capture_file = get_obj_body(capture_files[-1])\n",
    "print(capture_file[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf37379d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "print(json.dumps(json.loads(capture_file.split('\\n')[0]), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "2de8208a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([\"Our friends won't buy this analysis, let alone the next one we propose.\",\n",
       "       \"One more pseudo generalization and I'm giving up.\",\n",
       "       \"One more pseudo generalization or I'm giving up.\",\n",
       "       'The more we study verbs, the crazier they get.',\n",
       "       'Day by day the facts are getting murkier.',\n",
       "       \"I'll fix you a drink.\", 'Fred watered the plants flat.',\n",
       "       'Bill coughed his way out of the restaurant.',\n",
       "       \"We're dancing the night away.\", 'Herman hammered the metal flat.',\n",
       "       'The critics laughed the play off the stage.',\n",
       "       'The pond froze solid.', 'Bill rolled out of the room.',\n",
       "       'The gardener watered the flowers flat.',\n",
       "       'The gardener watered the flowers.',\n",
       "       'Bill broke the bathtub into pieces.', 'Bill broke the bathtub.',\n",
       "       'They drank the pub dry.', 'They drank the pub.',\n",
       "       'The professor talked us into a stupor.',\n",
       "       'The professor talked us.', 'We yelled ourselves hoarse.',\n",
       "       'We yelled ourselves.', 'We yelled Harry hoarse.',\n",
       "       'Harry coughed himself into a fit.', 'Harry coughed himself.',\n",
       "       'Harry coughed us into a fit.',\n",
       "       'Bill followed the road into the forest.',\n",
       "       'We drove Highway 5 from SD to SF.',\n",
       "       'Fred tracked the leak to its source.',\n",
       "       'John danced waltzes across the room.',\n",
       "       'Bill urinated out the window.', 'Bill coughed out the window.',\n",
       "       'Bill bled on the floor.',\n",
       "       'The toilet leaked through the floor into the kitchen below.',\n",
       "       'Bill ate off the floor.', 'Bill drank from the hose.',\n",
       "       'This metal hammers flat easily.', 'They made him president.',\n",
       "       'They made him angry.',\n",
       "       'They caused him to become angry by making him.',\n",
       "       'They caused him to become president by making him.',\n",
       "       'They made him to exhaustion.', 'They made him into a monster.',\n",
       "       'The trolley rumbled through the tunnel.',\n",
       "       'The wagon rumbled down the road.',\n",
       "       'The bullets whistled past the house.',\n",
       "       'The knee replacement candidate groaned up the stairs.',\n",
       "       'The car honked down the road.', 'The dog barked out of the room.',\n",
       "       'The dog barked its way out of the room.',\n",
       "       'Bill whistled his way past the house.',\n",
       "       'The witch vanished into the forest.',\n",
       "       'Bill disappeared down the road.',\n",
       "       'The witch went into the forest by vanishing.',\n",
       "       'The witch went into the forest and thereby vanished.',\n",
       "       'The building is tall and wide.', 'The building is tall and tall.',\n",
       "       'This building is taller and wider than that one.',\n",
       "       'This building got taller and wider than that one.',\n",
       "       'This building got taller and taller.',\n",
       "       'This building is taller and taller.',\n",
       "       'This building got than that one.',\n",
       "       'This building is than that one.', 'Bill floated into the cave.',\n",
       "       'Bill floated into the cave for hours.',\n",
       "       'Bill pushed Harry off the sofa for hours.',\n",
       "       'Bill floated down the river for hours.',\n",
       "       'Bill floated down the river.',\n",
       "       'Bill pushed Harry along the trail for hours.',\n",
       "       'Bill pushed Harry along the trail.',\n",
       "       'The road zigzagged down the hill.',\n",
       "       'The rope stretched over the pulley.',\n",
       "       'The weights stretched the rope over the pulley.',\n",
       "       'The weights kept the rope stretched over the pulley.',\n",
       "       'Sam cut himself free.', 'Sam got free by cutting his finger.',\n",
       "       'Bill cried himself to sleep.', 'Bill cried Sue to sleep.',\n",
       "       'Bill squeezed himself through the hole.',\n",
       "       'Bill sang himself to sleep.',\n",
       "       'Bill squeezed the puppet through the hole.',\n",
       "       'Bill sang Sue to sleep.',\n",
       "       'The elevator rumbled itself to the ground.',\n",
       "       'If the telephone rang, it could ring itself silly.',\n",
       "       'She yelled hoarse.', 'Ted cried to sleep.',\n",
       "       'The tiger bled to death.',\n",
       "       'He coughed awake and we were all overjoyed, especially Sierra.',\n",
       "       'John coughed awake, rubbing his nose and cursing under his breath.',\n",
       "       'John coughed himself awake on the bank of the lake where he and Bill had their play.',\n",
       "       'Ron yawned himself awake.',\n",
       "       'She coughed herself awake as the leaf landed on her nose.',\n",
       "       'The worm wriggled onto the carpet.',\n",
       "       'The chocolate melted onto the carpet.',\n",
       "       'The ball wriggled itself loose.', 'Bill wriggled himself loose.',\n",
       "       'Aliza wriggled her tooth loose.',\n",
       "       'The off center spinning flywheel shook itself loose.',\n",
       "       'The more you eat, the less you want.'], dtype=object)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\n",
    "    \"./nlp_drift/cola_public/raw/in_domain_train.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    usecols=[1, 3],\n",
    "    names=[\"label\", \"sentence\"],\n",
    ").iloc[:100,:]\n",
    "sentences = df.sentence.values\n",
    "labels = df.label.values\n",
    "print(len(sentences))\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcecc5a",
   "metadata": {},
   "source": [
    "### Generate BASELINE Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "f536bbce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end:sentense:\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# use the model created above\n",
    "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "#model = BertModel.from_pretrained('bert-base-uncased',output_hidden_states = True, ) # Whether the model returns all hidden-states.\n",
    "\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "sentence_embeddings = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 64,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(encoded_dict['input_ids'], encoded_dict['attention_mask'])\n",
    "        #print(outputs) # tensor tuple\n",
    "        hidden_states = outputs[0] #outputs[2]\n",
    "        #print(hidden_states)\n",
    "        token_vecs = hidden_states[0][0] #hidden_states[-2][0]\n",
    "        sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "        sentence_embeddings.append(sentence_embedding)\n",
    "print(\"end:sentense:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "46d6ea19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "sentence_embeddings_list = []\n",
    "print(len(sentence_embeddings))\n",
    "for i in sentence_embeddings:\n",
    "    sentence_embeddings_list.append(i.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "7f872a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('nlp_drift/embeddings_bertllm.npy', sentence_embeddings_list)\n",
    "baseline_nlp_stats_s3 = f\"s3://{sess_bucket}/bertllm/baseline-embeddings/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "70b9011b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-622343165275/bertllm/embeddings/'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_nlp_stats_s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "aed159d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "upload: nlp_drift/embeddings_bertllm.npy to s3://sagemaker-us-east-1-622343165275/bertllm/embeddings/embeddings_bertllm.npy\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp ./nlp_drift/embeddings_bertllm.npy $baseline_nlp_stats_s3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57759f1",
   "metadata": {},
   "source": [
    "#### Create the DockerFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754d9889",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile docker-nlp/Dockerfile\n",
    "FROM python:3.7-slim-buster\n",
    "\n",
    "RUN pip3 install sagemaker\n",
    "RUN pip3 install scipy\n",
    "RUN pip3 install transformers\n",
    "RUN pip3 install torch\n",
    "RUN pip3 install s3fs\n",
    "\n",
    "ENV PYTHONUNBUFFERED=TRUE\n",
    "\n",
    "ADD evaluation.py /\n",
    "\n",
    "ENTRYPOINT [\"python3\", \"/evaluation.py\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446fa276",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile nlp_drift/code/evaluate.py\n",
    "\"\"\"Custom Model Monitoring script for Detecting Data Drift in NLP using SageMaker Model Monitor\n",
    "\"\"\"\n",
    "\n",
    "# Python Built-Ins:\n",
    "from collections import defaultdict\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import traceback\n",
    "from types import SimpleNamespace\n",
    "\n",
    "# External Dependencies:\n",
    "import numpy as np\n",
    "import boto3\n",
    "from scipy.spatial.distance import cosine\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "\n",
    "def get_environment():\n",
    "    \"\"\"Load configuration variables for SM Model Monitoring job\n",
    "\n",
    "    See https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-byoc-contract-inputs.html\n",
    "    \"\"\"\n",
    "    print(f\"nlp-drift::get_environment()::\")\n",
    "    try:\n",
    "        with open(\"/opt/ml/config/processingjobconfig.json\", \"r\") as conffile:\n",
    "            defaults = json.loads(conffile.read())[\"Environment\"]\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        print(\"Unable to read environment vars from SM processing config file\")\n",
    "        defaults = {}\n",
    "\n",
    "    return SimpleNamespace(\n",
    "        dataset_format=os.environ.get(\"dataset_format\", defaults.get(\"dataset_format\")),\n",
    "        dataset_source=os.environ.get(\n",
    "            \"dataset_source\",\n",
    "            defaults.get(\"dataset_source\", \"/opt/ml/processing/input/endpoint\"),\n",
    "        ),\n",
    "        end_time=os.environ.get(\"end_time\", defaults.get(\"end_time\")),\n",
    "        output_path=os.environ.get(\n",
    "            \"output_path\",\n",
    "            defaults.get(\"output_path\", \"/opt/ml/processing/resultdata\"),\n",
    "        ),\n",
    "        publish_cloudwatch_metrics=os.environ.get(\n",
    "            \"publish_cloudwatch_metrics\",\n",
    "            defaults.get(\"publish_cloudwatch_metrics\", \"Enabled\"),\n",
    "        ),\n",
    "        sagemaker_endpoint_name=os.environ.get(\n",
    "            \"sagemaker_endpoint_name\",\n",
    "            defaults.get(\"sagemaker_endpoint_name\"),\n",
    "        ),\n",
    "        sagemaker_monitoring_schedule_name=os.environ.get(\n",
    "            \"sagemaker_monitoring_schedule_name\",\n",
    "            defaults.get(\"sagemaker_monitoring_schedule_name\"),\n",
    "        ),\n",
    "        start_time=os.environ.get(\n",
    "            \"start_time\", \n",
    "            defaults.get(\"start_time\")),\n",
    "        max_ratio_threshold=float(os.environ.get(\n",
    "            \"THRESHOLD\", \n",
    "             defaults.get(\"THRESHOLD\", \"nan\"))),\n",
    "        bucket=os.environ.get(\n",
    "            \"bucket\",\n",
    "            defaults.get(\"bucket\", \"None\")),\n",
    "    )\n",
    "\n",
    "\n",
    "def download_embeddings_file():\n",
    "    \n",
    "    env = get_environment()\n",
    "    print(f\"nlp-drift::Starting s3fs: download\")\n",
    "    \n",
    "    from s3fs.core import S3FileSystem\n",
    "    s3 = S3FileSystem()\n",
    "    \n",
    "    key = 'sagemaker/nlp-data-drift-bert-model/embeddings/embeddings.npy'\n",
    "    bucket = env.bucket\n",
    "    print(f\"nlp-drift::S3 bucket name is={bucket}\")\n",
    "\n",
    "    return np.load(s3.open('{}/{}'.format(bucket, key)))\n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "\n",
    "    env = get_environment()\n",
    "    print(f\"nlp-drift::Starting evaluation with config\\n{env}\")\n",
    "\n",
    "    print(f\"nlp-drift::Downloading Embedding File\")\n",
    "    \n",
    "    #download BERT embedding file used for fine-tuning BertForSequenceClassification\n",
    "    embedding_list = download_embeddings_file()\n",
    "    \n",
    "    # Load pre-trained model tokenizer (vocabulary)\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    # Load pre-trained model (weights)\n",
    "    model = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                      output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "                                      )\n",
    "\n",
    "    # Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "    sent_cosine_dict = {}\n",
    "    violations = []\n",
    "    \n",
    "    total_record_count = 0  # Including error predictions that we can't read the response for\n",
    "    error_record_count = 0\n",
    "    counts = defaultdict(int)  # dict defaulting to 0 when unseen keys are requested\n",
    "    print(f\"nlp-drift::counts={counts}::\")\n",
    "    \n",
    "    for path, directories, filenames in os.walk(env.dataset_source):\n",
    "        for filename in filter(lambda f: f.lower().endswith(\".jsonl\"), filenames):\n",
    "            print(f\"nlp-drift::starting:DRIFT:Analysis:filename={filename}:\")\n",
    "            \n",
    "            with open(os.path.join(path, filename), \"r\") as file:\n",
    "                for entry in file:\n",
    "                    total_record_count += 1\n",
    "                    try:\n",
    "                        response = json.loads(json.loads(entry)[\"captureData\"][\"endpointInput\"][\"data\"])\n",
    "                    except:\n",
    "                        continue\n",
    "                \n",
    "                    for record in response:\n",
    "                        encoded_dict = tokenizer.encode_plus(\n",
    "                            record, \n",
    "                            add_special_tokens = True,\n",
    "                            max_length = 64,\n",
    "                            padding= True,\n",
    "                            return_attention_mask = True,\n",
    "                            return_tensors = 'pt',\n",
    "                            truncation=True,\n",
    "                            )\n",
    "\n",
    "                        with torch.no_grad():\n",
    "                            outputs = model(encoded_dict['input_ids'], encoded_dict['attention_mask'])\n",
    "                            hidden_states = outputs[2]\n",
    "                            token_vecs = hidden_states[-2][0]\n",
    "                            input_sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "                        \n",
    "                        cosine_score = 0\n",
    "                        \n",
    "                        for embed_item in embedding_list:\n",
    "                            cosine_score += (1 - cosine(input_sentence_embedding, embed_item))\n",
    "                            print(f\"nlp-drift::cos:={cosine_score}\")\n",
    "                            \n",
    "                        cosine_score_avg = cosine_score/(len(embedding_list))\n",
    "                        if cosine_score_avg < env.max_ratio_threshold:\n",
    "                            error_record_count += 1\n",
    "                            sent_cosine_dict[record] = cosine_score_avg\n",
    "                            violations.append({\n",
    "                                    \"sentence\": record,\n",
    "                                    \"avg_cosine_score\": cosine_score_avg,\n",
    "                                    \"feature_name\": \"sent_cosine_score\",\n",
    "                                    \"constraint_check_type\": \"baseline_drift_check\",\n",
    "                                    \"endpoint_name\" : env.sagemaker_endpoint_name,\n",
    "                                    \"monitoring_schedule_name\": env.sagemaker_monitoring_schedule_name\n",
    "                                })\n",
    "        \n",
    "    print(f\"nlp-drift::Checking for constraint violations...\")\n",
    "    print(f\"nlp-drift::Violations: {violations if len(violations) else 'None'}\")\n",
    "\n",
    "    print(f\"nlp-drift::Writing violations file...\")\n",
    "    with open(os.path.join(env.output_path, \"constraints_violations.json\"), \"w\") as outfile:\n",
    "        outfile.write(json.dumps(\n",
    "            { \"violations\": violations },\n",
    "            indent=4,\n",
    "        ))\n",
    "    \n",
    "    print(f\"nlp-drift::Writing overall status output...\")\n",
    "    with open(\"/opt/ml/output/message\", \"w\") as outfile:\n",
    "        if len(violations):\n",
    "            msg = ''\n",
    "            for v in violations:\n",
    "                msg += f\"CompletedWithViolations: {v['sentence']}\"\n",
    "                msg +=\"\\n\"\n",
    "        else:\n",
    "            msg = \"Completed: Job completed successfully with no violations.\"\n",
    "        outfile.write(msg)\n",
    "        print(msg)\n",
    "\n",
    "    if True:\n",
    "    #if env.publish_cloudwatch_metrics:\n",
    "        print(f\"nlp-drift::Writing CloudWatch metrics...\")\n",
    "        with open(\"/opt/ml/output/metrics/cloudwatch/cloudwatch_metrics.jsonl\", \"a+\") as outfile:\n",
    "            # One metric per line (JSONLines list of dictionaries)\n",
    "            # Remember these metrics are aggregated in graphs, so we report them as statistics on our dataset\n",
    "            outfile.write(json.dumps(\n",
    "            { \"violations\": violations },\n",
    "            indent=4,\n",
    "            ))\n",
    "    print(f\"nlp-drift::Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18067ec",
   "metadata": {},
   "source": [
    "#### Build custom container for Model Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "ffc62b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "ecr_repository = 'nlp-data-drift-bert-v1'\n",
    "tag = ':latest'\n",
    "\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "sm = boto3.client('sagemaker')\n",
    "\n",
    "uri_suffix = 'amazonaws.com'\n",
    "if region in ['cn-north-1', 'cn-northwest-1']:\n",
    "    uri_suffix = 'amazonaws.com.cn'\n",
    "processing_repository_uri = f'{account_id}.dkr.ecr.{region}.{uri_suffix}/{ecr_repository + tag}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "e6b56dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Repository name is nlp-bert-llm-drift\n",
      "account got =622343165275\n",
      "region got=us-east-1 \n",
      "Login Succeeded\n",
      "sha256:9af1451c3dcc51944a619729e081c6966a38ed7edb5f09c7206768b7f5ce0fe0\n",
      "Docker image created repo:name:or:algorithm_name=nlp-bert-llm-drift fullName= 622343165275.dkr.ecr.us-east-1.amazonaws.com/nlp-bert-llm-drift:latest\n",
      "Docker push full name image=622343165275.dkr.ecr.us-east-1.amazonaws.com/nlp-bert-llm-drift:latest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=nlp-bert-llm-drift\n",
    "\n",
    "cd docker-nlp\n",
    "\n",
    "echo \"Repository name is $algorithm_name\"\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "echo \"account got =$account\"\n",
    "# Get the region defined in the current configuration (default to us-east-1 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-east-1}\n",
    "echo \"region got=$region \"\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build -q -t ${algorithm_name} .\n",
    "\n",
    "echo \"Docker image created repo:name:or:algorithm_name=$algorithm_name fullName= $fullname\"\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}\n",
    "\n",
    "echo \"Docker push full name image=$fullname\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "7943385e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'622343165275.dkr.ecr.us-east-1.amazonaws.com/nlp-bert-llm-drift:latest'"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#image_uri_processing = sagemaker.image_uris.retrieve('processing_repository_uri', 'us-east-1')\n",
    "container = \"{}.dkr.ecr.{}.amazonaws.com/nlp-bert-llm-drift:latest\".format(\n",
    "    account_id, region\n",
    ")\n",
    "container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "13efb644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-622343165275/bloom/triton_models/datacapture/p5-bert-uc--2022-09-16-18-09-53-901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-622343165275/neuron-experiments/bert-seq-classification/p5-bert-uc--2022-09-16-18-09-53-901/monitoring_schedule'"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_files = \"s3://{}/{}/{}\".format(sess_bucket, data_capture_prefix,endpoint_name_p5)\n",
    "print(input_files)\n",
    "destination = f's3://{sess_bucket}/{prefix}/{endpoint_name_p5}/monitoring_schedule'\n",
    "destination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb3c631",
   "metadata": {},
   "source": [
    "### Manually run the processing Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "477f4cdd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  bert-llm-monitor-2022-09-20-00-11-15-546\n",
      "Inputs:  [{'InputName': 'endpointdata', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-622343165275/bloom/triton_models/datacapture/p5-bert-uc--2022-09-16-18-09-53-901', 'LocalPath': '/opt/ml/processing/input/endpoint', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'result', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-622343165275/neuron-experiments/bert-seq-classification/p5-bert-uc--2022-09-16-18-09-53-901/monitoring_schedule', 'LocalPath': '/opt/ml/processing/resultdata', 'S3UploadMode': 'EndOfJob'}}]\n",
      "...........................\u001b[34mMoving 0 files to the new cache system\u001b[0m\n",
      "\u001b[34mThe cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\u001b[0m\n",
      "\u001b[34m#0150it [00:00, ?it/s]#0150it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34mnlp-drift::get_environment()::\u001b[0m\n",
      "\u001b[34mnlp-drift::Starting evaluation with config\u001b[0m\n",
      "\u001b[34mnamespace(bucket='sagemaker-us-east-1-622343165275', dataset_format=None, dataset_source='/opt/ml/processing/input/endpoint', end_time=None, max_ratio_threshold=0.5, output_path='/opt/ml/processing/resultdata', publish_cloudwatch_metrics='Enabled', sagemaker_endpoint_name=None, sagemaker_monitoring_schedule_name=None, start_time=None)\u001b[0m\n",
      "\u001b[34mnlp-drift::Downloading Embedding File\u001b[0m\n",
      "\u001b[34mnlp-drift::get_environment()::\u001b[0m\n",
      "\u001b[34mnlp-drift::Starting s3fs: download\u001b[0m\n",
      "\u001b[34mnlp-drift::S3 bucket name is=sagemaker-us-east-1-622343165275\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]#015Downloading: 100%|██████████| 232k/232k [00:00<00:00, 48.2MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]#015Downloading: 100%|██████████| 28.0/28.0 [00:00<00:00, 31.6kB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]#015Downloading: 100%|██████████| 570/570 [00:00<00:00, 727kB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]#015Downloading:   1%|          | 5.35M/440M [00:00<00:08, 53.5MB/s]#015Downloading:   3%|▎         | 11.5M/440M [00:00<00:07, 58.5MB/s]#015Downloading:   4%|▍         | 17.8M/440M [00:00<00:07, 60.2MB/s]#015Downloading:   5%|▌         | 24.0M/440M [00:00<00:06, 60.9MB/s]#015Downloading:   7%|▋         | 30.0M/440M [00:00<00:06, 60.6MB/s]#015Downloading:   8%|▊         | 36.3M/440M [00:00<00:06, 61.1MB/s]#015Downloading:  10%|▉         | 42.5M/440M [00:00<00:06, 61.4MB/s]#015Downloading:  11%|█         | 48.6M/440M [00:00<00:06, 61.1MB/s]#015Downloading:  12%|█▏        | 54.8M/440M [00:00<00:06, 61.4MB/s]#015Downloading:  14%|█▍        | 61.0M/440M [00:01<00:06, 60.6MB/s]#015Downloading:  15%|█▌        | 67.2M/440M [00:01<00:06, 61.0MB/s]#015Downloading:  17%|█▋        | 73.4M/440M [00:01<00:05, 61.3MB/s]#015Downloading:  18%|█▊        | 79.6M/440M [00:01<00:05, 61.5MB/s]#015Downloading:  19%|█▉        | 85.8M/440M [00:01<00:05, 61.6MB/s]#015Downloading:  21%|██        | 91.9M/440M [00:01<00:05, 61.7MB/s]#015Downloading:  22%|██▏       | 98.1M/440M [00:01<00:05, 61.7MB/s]#015Downloading:  24%|██▎       | 104M/440M [00:01<00:05, 61.6MB/s] #015Downloading:  25%|██▌       | 110M/440M [00:01<00:05, 59.8MB/s]#015Downloading:  26%|██▋       | 116M/440M [00:01<00:05, 57.1MB/s]#015Downloading:  28%|██▊       | 122M/440M [00:02<00:05, 57.0MB/s]#015Downloading:  29%|██▉       | 128M/440M [00:02<00:05, 58.4MB/s]#015Downloading:  31%|███       | 135M/440M [00:02<00:05, 59.4MB/s]#015Downloading:  32%|███▏      | 141M/440M [00:02<00:04, 60.2MB/s]#015Downloading:  33%|███▎      | 147M/440M [00:02<00:04, 60.3MB/s]#015Downloading:  35%|███▍      | 153M/440M [00:02<00:04, 60.8MB/s]#015Downloading:  36%|███▌      | 159M/440M [00:02<00:04, 60.6MB/s]#015Downloading:  38%|███▊      | 165M/440M [00:02<00:04, 61.0MB/s]#015Downloading:  39%|███▉      | 172M/440M [00:02<00:04, 61.3MB/s]#015Downloading:  40%|████      | 178M/440M [00:02<00:04, 61.5MB/s]#015Downloading:  42%|████▏     | 184M/440M [00:03<00:04, 60.3MB/s]#015Downloading:  43%|████▎     | 190M/440M [00:03<00:04, 60.7MB/s]#015Downloading:  45%|████▍     | 196M/440M [00:03<00:03, 61.1MB/s]#015Downloading:  46%|████▌     | 202M/440M [00:03<00:03, 61.3MB/s]#015Downloading:  47%|████▋     | 209M/440M [00:03<00:03, 61.4MB/s]#015Downloading:  49%|████▉     | 215M/440M [00:03<00:03, 61.6MB/s]#015Downloading:  50%|█████     | 221M/440M [00:03<00:03, 61.1MB/s]#015Downloading:  52%|█████▏    | 227M/440M [00:03<00:03, 61.4MB/s]#015Downloading:  53%|█████▎    | 233M/440M [00:03<00:03, 60.9MB/s]#015Downloading:  54%|█████▍    | 240M/440M [00:03<00:03, 61.4MB/s]#015Downloading:  56%|█████▌    | 246M/440M [00:04<00:03, 60.5MB/s]#015Downloading:  57%|█████▋    | 252M/440M [00:04<00:03, 61.0MB/s]#015Downloading:  59%|█████▊    | 258M/440M [00:04<00:02, 61.3MB/s]#015Downloading:  60%|█████▉    | 264M/440M [00:04<00:02, 61.5MB/s]#015Downloading:  61%|██████▏   | 270M/440M [00:04<00:02, 61.5MB/s]#015Downloading:  63%|██████▎   | 277M/440M [00:04<00:02, 61.8MB/s]#015Downloading:  64%|██████▍   | 283M/440M [00:04<00:02, 61.8MB/s]#015Downloading:  66%|██████▌   | 289M/440M [00:04<00:02, 61.9MB/s]#015Downloading:  67%|██████▋   | 295M/440M [00:04<00:02, 61.9MB/s]#015Downloading:  68%|██████▊   | 301M/440M [00:04<00:02, 61.9MB/s]#015Downloading:  70%|██████▉   | 308M/440M [00:05<00:02, 61.0MB/s]#015Downloading:  71%|███████▏  | 314M/440M [00:05<00:02, 61.3MB/s]#015Downloading:  73%|███████▎  | 320M/440M [00:05<00:01, 61.5MB/s]#015Downloading:  74%|███████▍  | 326M/440M [00:05<00:01, 61.7MB/s]#015Downloading:  75%|███████▌  | 332M/440M [00:05<00:01, 61.2MB/s]#015Downloading:  77%|███████▋  | 339M/440M [00:05<00:01, 61.4MB/s]#015Downloading:  78%|███████▊  | 345M/440M [00:05<00:01, 61.5MB/s]#015Downloading:  80%|███████▉  | 351M/440M [00:05<00:01, 61.4MB/s]#015Downloading:  81%|████████  | 357M/440M [00:05<00:01, 61.3MB/s]#015Downloading:  82%|████████▏ | 363M/440M [00:05<00:01, 61.3MB/s]#015Downloading:  84%|████████▍ | 369M/440M [00:06<00:01, 59.7MB/s]#015Downloading:  85%|████████▌ | 376M/440M [00:06<00:01, 60.2MB/s]#015Downloading:  87%|████████▋ | 382M/440M [00:06<00:00, 60.7MB/s]#015Downloading:  88%|████████▊ | 388M/440M [00:06<00:00, 61.0MB/s]#015Downloading:  89%|████████▉ | 394M/440M [00:06<00:00, 61.0MB/s]#015Downloading:  91%|█████████ | 400M/440M [00:06<00:00, 61.2MB/s]#015Downloading:  92%|█████████▏| 406M/440M [00:06<00:00, 61.3MB/s]#015Downloading:  94%|█████████▎| 412M/440M [00:06<00:00, 61.3MB/s]#015Downloading:  95%|█████████▌| 419M/440M [00:06<00:00, 61.4MB/s]#015Downloading:  96%|█████████▋| 425M/440M [00:06<00:00, 61.3MB/s]#015Downloading:  98%|█████████▊| 431M/440M [00:07<00:00, 60.7MB/s]#015Downloading:  99%|█████████▉| 437M/440M [00:07<00:00, 61.0MB/s]#015Downloading: 100%|██████████| 440M/440M [00:07<00:00, 60.9MB/s]\u001b[0m\n",
      "\u001b[34mSome weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\u001b[0m\n",
      "\u001b[34m- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34mnlp-drift::counts=defaultdict(<class 'int'>, {})::\u001b[0m\n",
      "\u001b[34mnlp-drift::starting:DRIFT:Analysis:filename=12-43-677-21d2da2d-80b0-411f-97c4-edb75f0c27ee.jsonl:\u001b[0m\n",
      "\u001b[34mnlp-drift::starting:DRIFT:Analysis:filename=39-48-038-4f7b8ae0-1597-44c0-be0a-3603245c82bc.jsonl:\u001b[0m\n",
      "\u001b[34mnlp-drift::Checking for constraint violations...\u001b[0m\n",
      "\u001b[34mnlp-drift::Violations: None\u001b[0m\n",
      "\u001b[34mnlp-drift::Writing violations file...\u001b[0m\n",
      "\u001b[34mnlp-drift::Writing overall status output...\u001b[0m\n",
      "\u001b[34mCompleted: Job completed successfully with no violations.\u001b[0m\n",
      "\u001b[34mnlp-drift::Writing CloudWatch metrics...\u001b[0m\n",
      "\u001b[34mnlp-drift::Done\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import Processor\n",
    "from sagemaker.model_monitor import CronExpressionGenerator, MonitoringOutput\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "processor = Processor(\n",
    "    base_job_name='bert-llm-monitor',\n",
    "    role=role,\n",
    "    image_uri=container, #processing_repository_uri,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    env={ 'THRESHOLD':'0.5','bucket': sess_bucket },\n",
    ")\n",
    "    \n",
    "processor.run(\n",
    "    [ProcessingInput(\n",
    "        input_name='endpointdata',\n",
    "        source = input_files, #\"s3://{}/{}/{}\".format(bucket, data_capture_prefix,endpoint_name),\n",
    "        #source=f's3://{sagemaker_session.default_bucket()}/{s3_prefix}/endpoint/data_capture',\n",
    "        destination = '/opt/ml/processing/input/endpoint',\n",
    "    )],\n",
    "    [ProcessingOutput(\n",
    "        output_name='result',\n",
    "        source='/opt/ml/processing/resultdata',\n",
    "        destination=destination,\n",
    "    )],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5305609",
   "metadata": {},
   "source": [
    "#### Use the Binary Headers for Triton - faster but same results - BUT ERRORS out as NO RESPONSE is recieved \n",
    "\n",
    "We can also use binary+json as the payload format to get better performance for the inference call. The specification of this format is provided here.\n",
    "\n",
    "Note: With the binary+json format, we have to specify the length of the request metadata in the header to allow Triton to correctly parse the binary payload. This is done using a custom Content-Type header application/vnd.sagemaker-triton.binary+json;json-header-size={}.\n",
    "\n",
    "Please not, this is different from using Inference-Header-Content-Length header on a stand-alone Triton server since custom headers are not allowed in SageMaker.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b791862a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leverage the Tokenizer=PreTrainedTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_len=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})::max_seq_length=512:: create above when creating the model \n",
      "Tokenize:text:why??::max_length=512::Tokenizer=PreTrainedTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_len=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n",
      "Error in parsing respinse -- probably the body is empty\n",
      "CPU times: user 3.46 ms, sys: 9.35 ms, total: 12.8 ms\n",
      "Wall time: 32.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import json\n",
    "max_seq_length=512\n",
    "text_triton = \"Triton Inference Server provides a cloud and edge inferencing solution optimized for both CPUs and GPUs.\"\n",
    "print(f\"Leverage the Tokenizer={enc}::max_seq_length={max_seq_length}:: create above when creating the model \")\n",
    "\n",
    "#input_ids, attention_mask = tokenize_text(text_triton, enc, max_length=max_seq_length)\n",
    "\n",
    "request_body, header_length = get_sample_tokenized_text_binary_pt(text_triton, enc) # this returns \n",
    "\n",
    "\n",
    "response_binary = runtime_sm_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name_p5, \n",
    "    ContentType=\"application/vnd.sagemaker-triton.binary+json;json-header-size={}\".format(header_length), \n",
    "    Body=request_body\n",
    ")\n",
    "\n",
    "# Parse json header size length from the response\n",
    "header_length_prefix = \"application/vnd.sagemaker-triton.binary+json;json-header-size=\"\n",
    "header_length_str = response[\"ContentType\"][len(header_length_prefix) :]\n",
    "\n",
    "try:\n",
    "    # Read response body\n",
    "    result = httpclient.InferenceServerClient.parse_response_body(\n",
    "        response_binary[\"Body\"].read(), header_length=int(header_length_str)\n",
    "    )\n",
    "    output0_data = result.as_numpy(\"OUTPUT__0\")\n",
    "    output1_data = result.as_numpy(\"1634__1\")\n",
    "    print(output0_data)\n",
    "    print(output1_data)\n",
    "except:\n",
    "    print(\"Error in parsing respinse -- probably the body is empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "44a6def1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p5-bert-uc--2022-09-08-03-02-53-774'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_name_p5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1c1cdf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leverage the Tokenizer=PreTrainedTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_len=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})::max_seq_length=512:: create above when creating the model \n",
      "Tokenize:text:why??::max_length=512::Tokenizer=PreTrainedTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_len=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n",
      "CPU times: user 19 s, sys: 1.82 s, total: 20.9 s\n",
      "Wall time: 1min 31s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['model_name', 'model_version', 'outputs'])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import json\n",
    "\n",
    "max_seq_length=512\n",
    "text_triton = \"\"\"This is a creative writing exercise. Below, you'll be given a prompt. Your story should be based on the prompt.\n",
    "\n",
    "Prompt: A scary story about a haunted mouse\n",
    "Story: On a dark and stormy night, the mouse crept in the shadows. \"\"\"\n",
    "\n",
    "\n",
    "print(f\"Leverage the Tokenizer={enc}::max_seq_length={max_seq_length}:: create above when creating the model \")\n",
    "input_ids, attention_mask = tokenize_text(text_triton, enc, max_length=max_seq_length)\n",
    "\n",
    "payload = {\n",
    "    \"inputs\": [\n",
    "        {\"name\": \"INPUT__0\", \"shape\": [1, max_seq_length], \"datatype\": \"INT32\", \"data\": input_ids}, # -- enc.tokenize(text)}, #\n",
    "        {\"name\": \"INPUT__1\", \"shape\": [1, max_seq_length], \"datatype\": \"INT32\", \"data\": attention_mask},\n",
    "    ]\n",
    "}\n",
    "\n",
    "max_run = 100\n",
    "for ii in range(0, max_run):\n",
    "    response = runtime_sm_client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name_p5, ContentType=\"application/octet-stream\", Body=json.dumps(payload)\n",
    "    )\n",
    "\n",
    "    output_dict = json.loads(response[\"Body\"].read().decode(\"utf8\"))\n",
    "\n",
    "    # -- output_dict['outputs'][0]['data']  -- has 0 and 1 as 2 indexes in list \n",
    "    output_dict.keys()\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    #enc.decode(output_dict['outputs'][0]['data'], skip_special_tokens=True)\n",
    "output_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e36e5d9f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'OUTPUT__0',\n",
       " 'datatype': 'FP32',\n",
       " 'shape': [1, 512, 768],\n",
       " 'data': [-0.15243282914161682,\n",
       "  -0.8572331666946411,\n",
       "  0.06608188152313232,\n",
       "  -0.20899571478366852,\n",
       "  0.35779935121536255,\n",
       "  -0.4324319064617157,\n",
       "  0.21307486295700073,\n",
       "  0.7328435778617859,\n",
       "  0.2850395441055298,\n",
       "  -0.8913273811340332,\n",
       "  0.2898162603378296,\n",
       "  -0.2516830265522003,\n",
       "  0.17877909541130066,\n",
       "  0.22467152774333954,\n",
       "  -0.16646161675453186,\n",
       "  0.21520552039146423,\n",
       "  0.4105544686317444,\n",
       "  0.49988511204719543,\n",
       "  0.15959863364696503,\n",
       "  0.11675862967967987,\n",
       "  0.012811945751309395,\n",
       "  -0.6604794859886169,\n",
       "  0.46912506222724915,\n",
       "  0.11688332259654999,\n",
       "  0.15712383389472961,\n",
       "  -0.03815995156764984,\n",
       "  -0.13969361782073975,\n",
       "  0.015787124633789062,\n",
       "  0.11993402242660522,\n",
       "  0.3402771055698395,\n",
       "  -0.6780798435211182,\n",
       "  0.1458730399608612,\n",
       "  -0.25922656059265137,\n",
       "  -0.7832548022270203,\n",
       "  0.28116920590400696,\n",
       "  -0.12131515890359879,\n",
       "  -0.28475871682167053,\n",
       "  -0.2089376002550125,\n",
       "  -0.11570572853088379,\n",
       "  0.35242488980293274,\n",
       "  -0.9599204659461975,\n",
       "  0.19939231872558594,\n",
       "  0.09761316329240799,\n",
       "  -0.25746431946754456,\n",
       "  0.2714739441871643,\n",
       "  -0.4958275854587555,\n",
       "  -4.28070592880249,\n",
       "  0.0795796662569046,\n",
       "  0.06400274485349655,\n",
       "  -0.8140904307365417,\n",
       "  0.21850654482841492,\n",
       "  0.014872162602841854,\n",
       "  -0.38559287786483765,\n",
       "  0.49034759402275085,\n",
       "  0.21157188713550568,\n",
       "  0.28455108404159546,\n",
       "  -0.22176732122898102,\n",
       "  0.22864080965518951,\n",
       "  -0.060361556708812714,\n",
       "  -0.20122043788433075,\n",
       "  -0.005756697151809931,\n",
       "  -0.06988131254911423,\n",
       "  -0.15562108159065247,\n",
       "  -0.004894986283034086,\n",
       "  -0.7175312638282776,\n",
       "  0.5078800320625305,\n",
       "  -0.017568115144968033,\n",
       "  0.20313388109207153,\n",
       "  -0.27161484956741333,\n",
       "  0.59983891248703,\n",
       "  -0.24598833918571472,\n",
       "  0.18726643919944763,\n",
       "  0.17724545300006866,\n",
       "  -0.356765478849411,\n",
       "  0.3893219530582428,\n",
       "  0.04006847366690636,\n",
       "  -0.38726016879081726,\n",
       "  0.016088290140032768,\n",
       "  -0.6229373216629028,\n",
       "  0.013894503936171532,\n",
       "  -0.44776278734207153,\n",
       "  0.755653977394104,\n",
       "  0.46263158321380615,\n",
       "  0.047012973576784134,\n",
       "  0.4246334731578827,\n",
       "  0.15268069505691528,\n",
       "  -0.789059579372406,\n",
       "  0.0030534849502146244,\n",
       "  0.30108505487442017,\n",
       "  0.3011099696159363,\n",
       "  -0.6517355442047119,\n",
       "  -0.3106408715248108,\n",
       "  -0.8016434907913208,\n",
       "  0.3920685350894928,\n",
       "  0.21406258642673492,\n",
       "  0.052744146436452866,\n",
       "  -0.09847257286310196,\n",
       "  0.012269517406821251,\n",
       "  0.3281860649585724,\n",
       "  0.9568153023719788,\n",
       "  0.054322369396686554,\n",
       "  -0.5601522326469421,\n",
       "  0.14691179990768433,\n",
       "  -0.6472994089126587,\n",
       "  -0.06023532897233963,\n",
       "  0.30683863162994385,\n",
       "  0.23232325911521912,\n",
       "  -0.04246249049901962,\n",
       "  -0.2844262719154358,\n",
       "  -1.803192138671875,\n",
       "  -0.045831985771656036,\n",
       "  -0.003260977566242218,\n",
       "  0.21598969399929047,\n",
       "  -0.5739086270332336,\n",
       "  0.16243724524974823,\n",
       "  -0.22761230170726776,\n",
       "  0.6652820110321045,\n",
       "  -0.298556923866272,\n",
       "  0.06696085631847382,\n",
       "  -0.23198053240776062,\n",
       "  -0.18249568343162537,\n",
       "  -0.4174838364124298,\n",
       "  -0.09105788171291351,\n",
       "  -0.5179993510246277,\n",
       "  0.4876752197742462,\n",
       "  0.4783645570278168,\n",
       "  0.1439400464296341,\n",
       "  0.3334556818008423,\n",
       "  0.25536584854125977,\n",
       "  -0.21909332275390625,\n",
       "  0.6439536213874817,\n",
       "  0.20453940331935883,\n",
       "  -0.37209081649780273,\n",
       "  -0.17049318552017212,\n",
       "  -0.3931882977485657,\n",
       "  1.097961664199829,\n",
       "  -0.16415078938007355,\n",
       "  -0.18966242671012878,\n",
       "  -0.38879573345184326,\n",
       "  0.17658215761184692,\n",
       "  0.06191803142428398,\n",
       "  -0.11129635572433472,\n",
       "  -2.5897436141967773,\n",
       "  0.8232522010803223,\n",
       "  0.9554612040519714,\n",
       "  0.2858097553253174,\n",
       "  0.004961827769875526,\n",
       "  -0.2980957329273224,\n",
       "  -0.6197496652603149,\n",
       "  0.4078480899333954,\n",
       "  0.43433651328086853,\n",
       "  0.44900840520858765,\n",
       "  -0.298801451921463,\n",
       "  0.2750507593154907,\n",
       "  -0.6649825572967529,\n",
       "  0.4650048613548279,\n",
       "  -0.37900495529174805,\n",
       "  0.23983296751976013,\n",
       "  0.1963275820016861,\n",
       "  0.18936653435230255,\n",
       "  0.08404063433408737,\n",
       "  0.27934569120407104,\n",
       "  -0.1847696453332901,\n",
       "  0.2775258421897888,\n",
       "  -0.03290119022130966,\n",
       "  0.08018647134304047,\n",
       "  0.4324783980846405,\n",
       "  0.34535008668899536,\n",
       "  -0.4332107901573181,\n",
       "  -0.216921865940094,\n",
       "  -0.15295131504535675,\n",
       "  0.2409810721874237,\n",
       "  1.0469696521759033,\n",
       "  0.36875292658805847,\n",
       "  0.08053147792816162,\n",
       "  -0.1223502978682518,\n",
       "  -0.2162165343761444,\n",
       "  -0.007359195034950972,\n",
       "  0.5893856287002563,\n",
       "  -0.18758779764175415,\n",
       "  -0.8738098740577698,\n",
       "  0.30574169754981995,\n",
       "  -0.13024497032165527,\n",
       "  -0.09229726344347,\n",
       "  0.07358723878860474,\n",
       "  -0.3273221254348755,\n",
       "  0.3707204759120941,\n",
       "  -0.09124206751585007,\n",
       "  -0.07653260976076126,\n",
       "  -0.38909420371055603,\n",
       "  -0.3068927526473999,\n",
       "  -0.5193188190460205,\n",
       "  0.29507753252983093,\n",
       "  0.10124936699867249,\n",
       "  0.4992099404335022,\n",
       "  -0.5116150975227356,\n",
       "  0.0808495581150055,\n",
       "  -0.3332512378692627,\n",
       "  -0.3916238248348236,\n",
       "  -0.29075372219085693,\n",
       "  0.08020149916410446,\n",
       "  -0.33299875259399414,\n",
       "  0.5210301280021667,\n",
       "  0.22531406581401825,\n",
       "  -0.21531414985656738,\n",
       "  3.9804553985595703,\n",
       "  -0.5335700511932373,\n",
       "  -0.6236492395401001,\n",
       "  0.3646713197231293,\n",
       "  0.3299594521522522,\n",
       "  -0.7218930721282959,\n",
       "  0.11543698608875275,\n",
       "  -0.007148232776671648,\n",
       "  0.5000238418579102,\n",
       "  0.11779721081256866,\n",
       "  0.23821154236793518,\n",
       "  0.3014300465583801,\n",
       "  0.10538209229707718,\n",
       "  0.37916961312294006,\n",
       "  0.18390344083309174,\n",
       "  -0.5240735411643982,\n",
       "  0.3078731894493103,\n",
       "  -0.8637978434562683,\n",
       "  -0.07996610552072525,\n",
       "  -0.9679317474365234,\n",
       "  0.19479244947433472,\n",
       "  -0.27941086888313293,\n",
       "  0.3579581081867218,\n",
       "  0.30736058950424194,\n",
       "  -1.7784301042556763,\n",
       "  -0.35053661465644836,\n",
       "  -0.06332805752754211,\n",
       "  0.20748697221279144,\n",
       "  0.14578208327293396,\n",
       "  -0.3111460506916046,\n",
       "  0.07201452553272247,\n",
       "  -0.6581940054893494,\n",
       "  -0.6154274940490723,\n",
       "  -0.09685604274272919,\n",
       "  -0.17917901277542114,\n",
       "  0.18489520251750946,\n",
       "  0.566371738910675,\n",
       "  0.33499693870544434,\n",
       "  0.6630157232284546,\n",
       "  -0.14674519002437592,\n",
       "  0.11833595484495163,\n",
       "  0.3510623872280121,\n",
       "  0.13926023244857788,\n",
       "  0.5620833039283752,\n",
       "  -0.4351637363433838,\n",
       "  0.567243218421936,\n",
       "  0.13841907680034637,\n",
       "  0.7434300184249878,\n",
       "  0.11254368722438812,\n",
       "  0.32779985666275024,\n",
       "  0.41057053208351135,\n",
       "  -0.3029719591140747,\n",
       "  -0.2382582277059555,\n",
       "  -0.11079960316419601,\n",
       "  0.015436003915965557,\n",
       "  -0.13279466331005096,\n",
       "  0.12257592380046844,\n",
       "  -0.3194899559020996,\n",
       "  0.43891462683677673,\n",
       "  -0.6943170428276062,\n",
       "  -0.05838284641504288,\n",
       "  0.3810212016105652,\n",
       "  -0.09472791850566864,\n",
       "  0.3196665942668915,\n",
       "  0.11023896187543869,\n",
       "  -0.20110729336738586,\n",
       "  -0.19630540907382965,\n",
       "  -0.733989417552948,\n",
       "  -2.283050060272217,\n",
       "  -0.1596091091632843,\n",
       "  -0.3896175026893616,\n",
       "  0.25501734018325806,\n",
       "  0.5485239624977112,\n",
       "  0.7279982566833496,\n",
       "  -0.2977728843688965,\n",
       "  0.27647411823272705,\n",
       "  0.7247763276100159,\n",
       "  -0.625706136226654,\n",
       "  0.6716095805168152,\n",
       "  0.7512229681015015,\n",
       "  -0.6151925921440125,\n",
       "  0.5348860025405884,\n",
       "  0.26652613282203674,\n",
       "  -0.2668118476867676,\n",
       "  -0.059999823570251465,\n",
       "  -0.916610836982727,\n",
       "  0.05203899368643761,\n",
       "  -0.5905131101608276,\n",
       "  -0.5954939126968384,\n",
       "  -0.02916477434337139,\n",
       "  -0.05308451130986214,\n",
       "  0.7269306182861328,\n",
       "  0.64029461145401,\n",
       "  0.4839937090873718,\n",
       "  -0.0747174471616745,\n",
       "  -0.12876608967781067,\n",
       "  -0.3492620587348938,\n",
       "  0.42400145530700684,\n",
       "  0.31635794043540955,\n",
       "  0.001425330643542111,\n",
       "  0.37645307183265686,\n",
       "  -0.08180449157953262,\n",
       "  -0.682857096195221,\n",
       "  -2.667266368865967,\n",
       "  0.16403107345104218,\n",
       "  0.10986682027578354,\n",
       "  -0.3569868206977844,\n",
       "  -0.027537843212485313,\n",
       "  0.2773939073085785,\n",
       "  0.38499656319618225,\n",
       "  -0.008390780538320541,\n",
       "  -0.4786089062690735,\n",
       "  -0.09760541468858719,\n",
       "  0.24313293397426605,\n",
       "  -0.45595282316207886,\n",
       "  0.3337545096874237,\n",
       "  -0.010193522088229656,\n",
       "  0.6302138566970825,\n",
       "  0.01677335426211357,\n",
       "  0.34828659892082214,\n",
       "  -0.5686216950416565,\n",
       "  0.010367066599428654,\n",
       "  -0.13441316783428192,\n",
       "  -0.3208213150501251,\n",
       "  0.19600138068199158,\n",
       "  0.3707866668701172,\n",
       "  -0.22076064348220825,\n",
       "  0.5413828492164612,\n",
       "  0.6409174799919128,\n",
       "  -0.800566554069519,\n",
       "  -0.21035903692245483,\n",
       "  0.12587518990039825,\n",
       "  -0.13108915090560913,\n",
       "  0.405699223279953,\n",
       "  -0.4599815905094147,\n",
       "  -0.4158557951450348,\n",
       "  0.1859418898820877,\n",
       "  -0.48929986357688904,\n",
       "  -0.014476576820015907,\n",
       "  0.5688996911048889,\n",
       "  -0.1462414562702179,\n",
       "  0.6768046617507935,\n",
       "  0.3780023455619812,\n",
       "  -0.16517241299152374,\n",
       "  0.5860856771469116,\n",
       "  0.04229560121893883,\n",
       "  -0.14841297268867493,\n",
       "  0.5961641669273376,\n",
       "  0.050503432750701904,\n",
       "  0.7350917458534241,\n",
       "  -0.3551936745643616,\n",
       "  0.2134319543838501,\n",
       "  0.7498502135276794,\n",
       "  -0.06756069511175156,\n",
       "  0.2406913787126541,\n",
       "  1.6315383911132812,\n",
       "  0.03517923504114151,\n",
       "  0.42837265133857727,\n",
       "  0.13128745555877686,\n",
       "  0.004562667105346918,\n",
       "  -0.0020802682265639305,\n",
       "  -0.5440433621406555,\n",
       "  0.45915353298187256,\n",
       "  0.6549606323242188,\n",
       "  -0.8992667198181152,\n",
       "  -0.06954380124807358,\n",
       "  -0.3308899998664856,\n",
       "  0.7643892168998718,\n",
       "  -0.8476575613021851,\n",
       "  0.15809689462184906,\n",
       "  -0.411735862493515,\n",
       "  0.010811352171003819,\n",
       "  -0.1143619641661644,\n",
       "  0.33857402205467224,\n",
       "  0.22135883569717407,\n",
       "  -0.4099784195423126,\n",
       "  -1.6249817609786987,\n",
       "  0.3434310555458069,\n",
       "  -0.02272789552807808,\n",
       "  -0.3741368353366852,\n",
       "  0.16478930413722992,\n",
       "  -0.24276229739189148,\n",
       "  -0.3600810468196869,\n",
       "  0.1560140699148178,\n",
       "  -0.3518632650375366,\n",
       "  -0.15955300629138947,\n",
       "  0.3054552972316742,\n",
       "  -0.6356754302978516,\n",
       "  -0.4160648584365845,\n",
       "  0.10241243988275528,\n",
       "  0.1789943128824234,\n",
       "  -0.6628385186195374,\n",
       "  -0.43797510862350464,\n",
       "  0.09305015951395035,\n",
       "  0.21994896233081818,\n",
       "  0.2351069301366806,\n",
       "  0.2470349371433258,\n",
       "  -0.7779158353805542,\n",
       "  -0.07482749968767166,\n",
       "  0.042539793998003006,\n",
       "  -1.3215032815933228,\n",
       "  0.29316550493240356,\n",
       "  -0.11797415465116501,\n",
       "  0.5045604109764099,\n",
       "  0.36977142095565796,\n",
       "  0.12047497183084488,\n",
       "  -0.2272309958934784,\n",
       "  -0.4634229838848114,\n",
       "  0.03910891339182854,\n",
       "  -0.42650309205055237,\n",
       "  0.12236924469470978,\n",
       "  0.0734814777970314,\n",
       "  0.23430900275707245,\n",
       "  -0.4466637670993805,\n",
       "  -0.26380473375320435,\n",
       "  -0.4400947093963623,\n",
       "  -0.00739049119874835,\n",
       "  1.060275912284851,\n",
       "  -0.47253018617630005,\n",
       "  0.04528389126062393,\n",
       "  0.8045607209205627,\n",
       "  0.07821834087371826,\n",
       "  -0.37794145941734314,\n",
       "  0.49531713128089905,\n",
       "  0.009510708041489124,\n",
       "  0.17018736898899078,\n",
       "  -0.4015081226825714,\n",
       "  0.3611564338207245,\n",
       "  -0.15230809152126312,\n",
       "  0.14244310557842255,\n",
       "  -0.23516149818897247,\n",
       "  0.19474199414253235,\n",
       "  0.013688655570149422,\n",
       "  0.5158392786979675,\n",
       "  -0.20714668929576874,\n",
       "  -0.4269808232784271,\n",
       "  -0.1989830732345581,\n",
       "  0.019452707841992378,\n",
       "  0.003826805157586932,\n",
       "  -0.89957195520401,\n",
       "  -0.4286869168281555,\n",
       "  -0.0382392518222332,\n",
       "  0.38160526752471924,\n",
       "  0.5184934735298157,\n",
       "  0.03202255070209503,\n",
       "  -0.6420595049858093,\n",
       "  -0.1360992044210434,\n",
       "  0.050308577716350555,\n",
       "  0.3413587510585785,\n",
       "  -0.40859586000442505,\n",
       "  0.12311729788780212,\n",
       "  0.19384804368019104,\n",
       "  0.28185132145881653,\n",
       "  0.13951259851455688,\n",
       "  0.5814095139503479,\n",
       "  -0.3154950737953186,\n",
       "  -0.1854190230369568,\n",
       "  0.06399369239807129,\n",
       "  0.25282222032546997,\n",
       "  -0.05173686891794205,\n",
       "  -0.21610401570796967,\n",
       "  -0.03656230866909027,\n",
       "  -0.22397226095199585,\n",
       "  -0.007589278277009726,\n",
       "  0.1626456081867218,\n",
       "  -1.9365695714950562,\n",
       "  -0.10576067119836807,\n",
       "  0.590091347694397,\n",
       "  -0.07427757233381271,\n",
       "  0.17707780003547668,\n",
       "  -0.2830815315246582,\n",
       "  0.16561488807201385,\n",
       "  0.3820725083351135,\n",
       "  -0.10643642395734787,\n",
       "  -0.09023184329271317,\n",
       "  -0.15113085508346558,\n",
       "  0.6557567119598389,\n",
       "  0.11127658188343048,\n",
       "  0.1654430776834488,\n",
       "  -0.09123630821704865,\n",
       "  -0.6255208253860474,\n",
       "  -0.4871487617492676,\n",
       "  -0.34839850664138794,\n",
       "  0.10916300117969513,\n",
       "  -0.9921050071716309,\n",
       "  -0.2253103256225586,\n",
       "  0.6314945220947266,\n",
       "  0.7647891044616699,\n",
       "  0.1289629340171814,\n",
       "  0.03854874148964882,\n",
       "  -0.32970431447029114,\n",
       "  -0.002516691107302904,\n",
       "  0.3706390857696533,\n",
       "  0.05061403289437294,\n",
       "  0.24953855574131012,\n",
       "  0.35177135467529297,\n",
       "  0.12793877720832825,\n",
       "  -0.8429774641990662,\n",
       "  0.06458117067813873,\n",
       "  0.39192691445350647,\n",
       "  0.40299156308174133,\n",
       "  0.41197773814201355,\n",
       "  -0.23538699746131897,\n",
       "  0.43065574765205383,\n",
       "  0.43894556164741516,\n",
       "  -0.6606647968292236,\n",
       "  0.35109591484069824,\n",
       "  0.5190305113792419,\n",
       "  0.6520794034004211,\n",
       "  0.8571969866752625,\n",
       "  -0.05022159591317177,\n",
       "  -0.10029426962137222,\n",
       "  0.2952761650085449,\n",
       "  -0.32723426818847656,\n",
       "  -0.017702119424939156,\n",
       "  -0.7253603339195251,\n",
       "  -0.7763994336128235,\n",
       "  -0.0747443363070488,\n",
       "  -0.35449352860450745,\n",
       "  -0.198677659034729,\n",
       "  -0.49206504225730896,\n",
       "  0.38733184337615967,\n",
       "  0.1457296758890152,\n",
       "  -0.9076860547065735,\n",
       "  -0.33420440554618835,\n",
       "  0.5267676115036011,\n",
       "  -0.07851012051105499,\n",
       "  -0.43514230847358704,\n",
       "  -0.43984705209732056,\n",
       "  -0.08559336513280869,\n",
       "  -1.0786504745483398,\n",
       "  -0.28133469820022583,\n",
       "  -0.07433544844388962,\n",
       "  0.015066095627844334,\n",
       "  0.20733742415905,\n",
       "  0.11163754761219025,\n",
       "  -0.02526504173874855,\n",
       "  -0.7287487983703613,\n",
       "  0.19242285192012787,\n",
       "  -0.4180862605571747,\n",
       "  -0.29124394059181213,\n",
       "  0.132492333650589,\n",
       "  -0.1641431599855423,\n",
       "  0.5331347584724426,\n",
       "  -0.6004188060760498,\n",
       "  0.3266528248786926,\n",
       "  0.19985897839069366,\n",
       "  0.2508074641227722,\n",
       "  0.5183570981025696,\n",
       "  -0.6566883325576782,\n",
       "  0.011749832890927792,\n",
       "  -0.4450083076953888,\n",
       "  0.22919724881649017,\n",
       "  0.30244335532188416,\n",
       "  0.12190672755241394,\n",
       "  -0.48163577914237976,\n",
       "  -0.6678341031074524,\n",
       "  -0.05269142985343933,\n",
       "  0.14905701577663422,\n",
       "  -0.26032546162605286,\n",
       "  -0.28518247604370117,\n",
       "  0.04718537628650665,\n",
       "  0.5703840851783752,\n",
       "  -0.32296475768089294,\n",
       "  -0.767652690410614,\n",
       "  -0.028027929365634918,\n",
       "  0.4003502130508423,\n",
       "  0.7045083045959473,\n",
       "  -0.0024386586155742407,\n",
       "  0.33113357424736023,\n",
       "  0.47623196244239807,\n",
       "  0.6452591419219971,\n",
       "  -0.6414557099342346,\n",
       "  -0.4135698676109314,\n",
       "  -0.2912571430206299,\n",
       "  0.2803230583667755,\n",
       "  -0.25887420773506165,\n",
       "  -0.2568710446357727,\n",
       "  0.25726157426834106,\n",
       "  -0.11538080871105194,\n",
       "  -0.8551483750343323,\n",
       "  -0.24193046987056732,\n",
       "  -0.31402918696403503,\n",
       "  1.4807443618774414,\n",
       "  0.3956575393676758,\n",
       "  -0.33006277680397034,\n",
       "  -0.28906020522117615,\n",
       "  0.39670252799987793,\n",
       "  0.5810874700546265,\n",
       "  -0.08746033906936646,\n",
       "  0.7076026797294617,\n",
       "  -0.49196168780326843,\n",
       "  0.9828351140022278,\n",
       "  -0.11483540385961533,\n",
       "  0.5720252394676208,\n",
       "  -0.5338782668113708,\n",
       "  -0.3397670388221741,\n",
       "  1.0628236532211304,\n",
       "  0.22742335498332977,\n",
       "  0.245201975107193,\n",
       "  -0.055027008056640625,\n",
       "  -0.4301733672618866,\n",
       "  -0.11962784081697464,\n",
       "  -0.5559842586517334,\n",
       "  0.9395849108695984,\n",
       "  0.8768144845962524,\n",
       "  0.3721594214439392,\n",
       "  -0.2621835172176361,\n",
       "  0.6894754767417908,\n",
       "  0.031490884721279144,\n",
       "  -0.45206230878829956,\n",
       "  0.017423762008547783,\n",
       "  1.2395076751708984,\n",
       "  -0.6819962859153748,\n",
       "  -0.21774542331695557,\n",
       "  0.2407231628894806,\n",
       "  0.48617616295814514,\n",
       "  -0.7289584279060364,\n",
       "  -0.18832236528396606,\n",
       "  -0.868733823299408,\n",
       "  -0.07730326801538467,\n",
       "  -0.17490480840206146,\n",
       "  -0.49257999658584595,\n",
       "  0.1646927446126938,\n",
       "  -0.012394888326525688,\n",
       "  0.97123783826828,\n",
       "  -0.06959221512079239,\n",
       "  -1.0203454494476318,\n",
       "  0.5534039735794067,\n",
       "  -0.6465563774108887,\n",
       "  -0.32650575041770935,\n",
       "  0.1482006311416626,\n",
       "  0.10388380289077759,\n",
       "  0.2709469199180603,\n",
       "  -0.18422652781009674,\n",
       "  -0.26728710532188416,\n",
       "  0.1764126867055893,\n",
       "  0.383524626493454,\n",
       "  0.12405954301357269,\n",
       "  0.6090409755706787,\n",
       "  0.06067296117544174,\n",
       "  -0.26954978704452515,\n",
       "  0.08975710719823837,\n",
       "  -0.42179277539253235,\n",
       "  0.24224570393562317,\n",
       "  0.41087329387664795,\n",
       "  0.23719225823879242,\n",
       "  0.6771267056465149,\n",
       "  -0.16299887001514435,\n",
       "  0.19770996272563934,\n",
       "  0.04112868010997772,\n",
       "  0.28650322556495667,\n",
       "  -0.4513266384601593,\n",
       "  -0.20538204908370972,\n",
       "  0.7205323576927185,\n",
       "  -0.019271565601229668,\n",
       "  0.8237189054489136,\n",
       "  0.3385160267353058,\n",
       "  0.7132264375686646,\n",
       "  0.7630184888839722,\n",
       "  -0.13469535112380981,\n",
       "  -0.6349261403083801,\n",
       "  -1.4645342826843262,\n",
       "  0.3074992299079895,\n",
       "  0.23793555796146393,\n",
       "  0.6368815898895264,\n",
       "  -0.3870506286621094,\n",
       "  0.2774500548839569,\n",
       "  0.9369627237319946,\n",
       "  -0.15526948869228363,\n",
       "  -0.14886446297168732,\n",
       "  -0.368557333946228,\n",
       "  0.4437929093837738,\n",
       "  0.1247909739613533,\n",
       "  0.7323305606842041,\n",
       "  -1.0264643430709839,\n",
       "  0.049332935363054276,\n",
       "  -0.07287430763244629,\n",
       "  1.1246798038482666,\n",
       "  -0.25645190477371216,\n",
       "  0.79436856508255,\n",
       "  -0.26167434453964233,\n",
       "  0.21237047016620636,\n",
       "  -0.1532057672739029,\n",
       "  -0.02862439677119255,\n",
       "  -0.4626915156841278,\n",
       "  -0.8138589859008789,\n",
       "  -0.31271106004714966,\n",
       "  0.08624204248189926,\n",
       "  -0.10287543386220932,\n",
       "  -0.29928845167160034,\n",
       "  0.15514004230499268,\n",
       "  -0.2512807548046112,\n",
       "  0.45485618710517883,\n",
       "  -0.7099696397781372,\n",
       "  0.2852531969547272,\n",
       "  -0.3635960519313812,\n",
       "  0.4106740951538086,\n",
       "  -0.03722316026687622,\n",
       "  0.4611254632472992,\n",
       "  0.26617658138275146,\n",
       "  -0.12129662930965424,\n",
       "  0.018484685570001602,\n",
       "  0.7792474627494812,\n",
       "  -0.7508952021598816,\n",
       "  0.3767417371273041,\n",
       "  0.3458622992038727,\n",
       "  -0.017128678038716316,\n",
       "  1.0647449493408203,\n",
       "  -0.12255655974149704,\n",
       "  0.701700747013092,\n",
       "  -0.17210090160369873,\n",
       "  -0.21266409754753113,\n",
       "  0.3220290541648865,\n",
       "  1.042075514793396,\n",
       "  0.44450265169143677,\n",
       "  0.2265007495880127,\n",
       "  -0.18980370461940765,\n",
       "  0.18499352037906647,\n",
       "  -0.15596164762973785,\n",
       "  -0.0973033607006073,\n",
       "  -0.4193395674228668,\n",
       "  -0.5341764688491821,\n",
       "  0.3734762370586395,\n",
       "  -0.46815618872642517,\n",
       "  -0.15334327518939972,\n",
       "  1.063309907913208,\n",
       "  -0.30913424491882324,\n",
       "  0.266042560338974,\n",
       "  0.44362929463386536,\n",
       "  -0.10186593979597092,\n",
       "  -0.6078144311904907,\n",
       "  -0.5296705365180969,\n",
       "  -0.1086951345205307,\n",
       "  0.029407847672700882,\n",
       "  0.13378363847732544,\n",
       "  0.576744556427002,\n",
       "  -0.3269336521625519,\n",
       "  0.34273573756217957,\n",
       "  0.6779901385307312,\n",
       "  0.2496640533208847,\n",
       "  -0.1499091535806656,\n",
       "  -0.08570697158575058,\n",
       "  0.3204309940338135,\n",
       "  0.08414646238088608,\n",
       "  -0.646040678024292,\n",
       "  0.3570067882537842,\n",
       "  -5.690296649932861,\n",
       "  0.41276815533638,\n",
       "  -0.23042500019073486,\n",
       "  0.13111449778079987,\n",
       "  -0.4327654540538788,\n",
       "  -0.989452600479126,\n",
       "  -0.2599603831768036,\n",
       "  -0.15610752999782562,\n",
       "  -0.38662955164909363,\n",
       "  -0.4319131672382355,\n",
       "  -0.10625971853733063,\n",
       "  0.46662232279777527,\n",
       "  0.17167523503303528,\n",
       "  -0.26219871640205383,\n",
       "  -0.01638292521238327,\n",
       "  0.8044725060462952,\n",
       "  -0.7595658898353577,\n",
       "  -0.5881166458129883,\n",
       "  -0.025703895837068558,\n",
       "  -0.2029799222946167,\n",
       "  0.3818010985851288,\n",
       "  -0.1393527388572693,\n",
       "  -0.11042293906211853,\n",
       "  1.4981578588485718,\n",
       "  -0.0036011619959026575,\n",
       "  -0.08999548852443695,\n",
       "  0.0007514312164857984,\n",
       "  -0.3181125223636627,\n",
       "  0.2870157063007355,\n",
       "  -0.11600325256586075,\n",
       "  0.09765161573886871,\n",
       "  0.4179441034793854,\n",
       "  0.28066346049308777,\n",
       "  0.39467859268188477,\n",
       "  0.13252809643745422,\n",
       "  0.18732275068759918,\n",
       "  0.5330065488815308,\n",
       "  -0.005108908750116825,\n",
       "  0.14801445603370667,\n",
       "  0.8875568509101868,\n",
       "  0.8857049942016602,\n",
       "  0.0008163273450918496,\n",
       "  0.22233706712722778,\n",
       "  0.14635850489139557,\n",
       "  -0.3280401825904846,\n",
       "  -1.1395660638809204,\n",
       "  -0.019569920375943184,\n",
       "  0.05176907405257225,\n",
       "  0.20769082009792328,\n",
       "  -0.738433837890625,\n",
       "  0.0810212641954422,\n",
       "  -0.57448810338974,\n",
       "  0.01890065334737301,\n",
       "  -0.6642919778823853,\n",
       "  -0.23686735332012177,\n",
       "  0.4988414943218231,\n",
       "  -0.4114721119403839,\n",
       "  0.1259208470582962,\n",
       "  0.20167165994644165,\n",
       "  -0.038704901933670044,\n",
       "  0.9287362694740295,\n",
       "  -0.6229997873306274,\n",
       "  -0.25441837310791016,\n",
       "  -0.8440266251564026,\n",
       "  0.5294130444526672,\n",
       "  0.16173341870307922,\n",
       "  -0.7345454096794128,\n",
       "  0.36443933844566345,\n",
       "  0.5440770983695984,\n",
       "  -0.24436499178409576,\n",
       "  -0.22731997072696686,\n",
       "  0.36946284770965576,\n",
       "  -0.3556789457798004,\n",
       "  -0.10366591066122055,\n",
       "  -0.7346314787864685,\n",
       "  0.19080977141857147,\n",
       "  0.3967592418193817,\n",
       "  -0.04712070897221565,\n",
       "  -0.21215929090976715,\n",
       "  -0.08550339192152023,\n",
       "  0.19921128451824188,\n",
       "  -0.03884485736489296,\n",
       "  0.05804602429270744,\n",
       "  1.0955346822738647,\n",
       "  -1.2348569631576538,\n",
       "  -0.49811726808547974,\n",
       "  -0.2274211347103119,\n",
       "  -0.7072733640670776,\n",
       "  0.46943145990371704,\n",
       "  -0.28947630524635315,\n",
       "  0.5181368589401245,\n",
       "  0.2877310514450073,\n",
       "  -0.14419975876808167,\n",
       "  -0.09450389444828033,\n",
       "  -0.17006058990955353,\n",
       "  -0.4197314977645874,\n",
       "  -0.24286271631717682,\n",
       "  1.2148160934448242,\n",
       "  -0.03178662061691284,\n",
       "  0.042943235486745834,\n",
       "  -0.36007633805274963,\n",
       "  0.5239415168762207,\n",
       "  -0.8245298266410828,\n",
       "  0.015807142481207848,\n",
       "  0.26179471611976624,\n",
       "  0.556049108505249,\n",
       "  -0.3179343640804291,\n",
       "  0.12528179585933685,\n",
       "  -0.5196822285652161,\n",
       "  0.03170362114906311,\n",
       "  0.41035670042037964,\n",
       "  -0.9063966870307922,\n",
       "  0.07459063827991486,\n",
       "  0.039600737392902374,\n",
       "  -0.04662210866808891,\n",
       "  0.008652030490338802,\n",
       "  -0.3990488648414612,\n",
       "  -1.518363118171692,\n",
       "  -0.2523789405822754,\n",
       "  0.16996394097805023,\n",
       "  0.5184571146965027,\n",
       "  0.07396390289068222,\n",
       "  0.26741066575050354,\n",
       "  -0.016938261687755585,\n",
       "  -0.1327054798603058,\n",
       "  -0.11027899384498596,\n",
       "  -0.1153007447719574,\n",
       "  0.1325850486755371,\n",
       "  -0.19647115468978882,\n",
       "  -0.9545804262161255,\n",
       "  -0.17417313158512115,\n",
       "  0.7408426403999329,\n",
       "  0.2696540355682373,\n",
       "  0.3485738933086395,\n",
       "  0.022285165265202522,\n",
       "  0.16813504695892334,\n",
       "  -0.10243787616491318,\n",
       "  0.01871873438358307,\n",
       "  0.4852330982685089,\n",
       "  0.4862951338291168,\n",
       "  -0.7041104435920715,\n",
       "  0.33142268657684326,\n",
       "  -0.006252328399568796,\n",
       "  0.2609426975250244,\n",
       "  0.738551139831543,\n",
       "  -0.7768146395683289,\n",
       "  0.6602467894554138,\n",
       "  0.5471489429473877,\n",
       "  0.40082600712776184,\n",
       "  -0.46358439326286316,\n",
       "  -0.3200080096721649,\n",
       "  -0.13953787088394165,\n",
       "  0.8278697729110718,\n",
       "  -0.4627791941165924,\n",
       "  -0.32709482312202454,\n",
       "  0.6943374872207642,\n",
       "  0.7043707966804504,\n",
       "  -0.06588182598352432,\n",
       "  0.9223544597625732,\n",
       "  -0.25970831513404846,\n",
       "  -0.09014131873846054,\n",
       "  -0.12743474543094635,\n",
       "  -0.5048604607582092,\n",
       "  -0.471625953912735,\n",
       "  0.19957235455513,\n",
       "  0.3579193949699402,\n",
       "  -0.08009441941976547,\n",
       "  0.010041814297437668,\n",
       "  -0.48221009969711304,\n",
       "  0.19295629858970642,\n",
       "  -0.16072118282318115,\n",
       "  0.48191940784454346,\n",
       "  0.22397290170192719,\n",
       "  0.23785580694675446,\n",
       "  0.5573644638061523,\n",
       "  0.013030987232923508,\n",
       "  0.21993489563465118,\n",
       "  0.17214475572109222,\n",
       "  0.8985391855239868,\n",
       "  1.1059409379959106,\n",
       "  -0.6165094375610352,\n",
       "  -0.15247495472431183,\n",
       "  -0.3756446838378906,\n",
       "  -0.23433122038841248,\n",
       "  0.06411436945199966,\n",
       "  -0.1295158565044403,\n",
       "  0.22380417585372925,\n",
       "  -0.6371030807495117,\n",
       "  1.1724536418914795,\n",
       "  -0.04513296112418175,\n",
       "  -0.02387055568397045,\n",
       "  -0.41024717688560486,\n",
       "  0.3714029788970947,\n",
       "  0.07922203093767166,\n",
       "  0.2749096751213074,\n",
       "  -0.02760433219373226,\n",
       "  -0.6063851714134216,\n",
       "  0.3749072551727295,\n",
       "  -0.4484843611717224,\n",
       "  -0.2681480050086975,\n",
       "  0.49209827184677124,\n",
       "  -0.7064786553382874,\n",
       "  0.3814597427845001,\n",
       "  -0.8379508256912231,\n",
       "  -0.10589183866977692,\n",
       "  0.8880450129508972,\n",
       "  -0.4523322582244873,\n",
       "  0.4013178050518036,\n",
       "  0.7524261474609375,\n",
       "  -0.3678078055381775,\n",
       "  1.2483851909637451,\n",
       "  -0.4370359778404236,\n",
       "  -0.21779949963092804,\n",
       "  0.0536472424864769,\n",
       "  0.4341031014919281,\n",
       "  0.31509914994239807,\n",
       "  0.15433916449546814,\n",
       "  0.30003172159194946,\n",
       "  0.031102627515792847,\n",
       "  -0.22313790023326874,\n",
       "  -0.7915427088737488,\n",
       "  0.2622305750846863,\n",
       "  -0.41356760263442993,\n",
       "  -0.08469942957162857,\n",
       "  0.5810692310333252,\n",
       "  -0.4819425940513611,\n",
       "  -0.37441498041152954,\n",
       "  0.7897458672523499,\n",
       "  -0.11677210032939911,\n",
       "  -0.19369973242282867,\n",
       "  0.17002998292446136,\n",
       "  0.3060799837112427,\n",
       "  0.25039854645729065,\n",
       "  0.5973700881004333,\n",
       "  0.09002286940813065,\n",
       "  0.0933876633644104,\n",
       "  0.20862933993339539,\n",
       "  -0.20386505126953125,\n",
       "  -0.00020156119717285037,\n",
       "  0.733384370803833,\n",
       "  -0.3118767738342285,\n",
       "  0.5473107695579529,\n",
       "  -0.06287690252065659,\n",
       "  0.450851708650589,\n",
       "  0.3495155870914459,\n",
       "  0.30077821016311646,\n",
       "  0.1542934775352478,\n",
       "  -0.5043416023254395,\n",
       "  ...]}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict['outputs'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2700a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids\n",
    "attention_mask \n",
    "\n",
    "# open file in write mode\n",
    "with open(r'./temp-bloom/input_ids.txt', 'w') as fp:\n",
    "    for item in input_ids:\n",
    "        # write each item on a new line\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "    print('Done input_ids')\n",
    "    \n",
    "# open file in write mode\n",
    "with open(r'./temp-bloom/attention_mask.txt', 'w') as fp:\n",
    "    for item in attention_mask:\n",
    "        # write each item on a new line\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "    print('Done attention_mask')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db9aaaa",
   "metadata": {},
   "source": [
    "### Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a412ed75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'd1348ba3-0c56-4058-b707-54259ae4065d',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'd1348ba3-0c56-4058-b707-54259ae4065d',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Fri, 16 Sep 2022 18:07:51 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_client.delete_endpoint(EndpointName=endpoint_name_p5)\n",
    "sm_client.delete_endpoint_config(EndpointConfigName=endpoint_name_p5)\n",
    "sm_client.delete_model(ModelName=endpoint_name_p5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b8022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import copy\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pprint\n",
    "import pandas as pd\n",
    "\n",
    "# sagemaker\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "# triton\n",
    "import tritonclient.http as httpclient\n",
    "\n",
    "# transformers\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# custom CloudWatch\n",
    "#from cloudwatch import get_endpoint_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4bd5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run --gpus=all --rm -it  -v `pwd`/workspace:/workspace nvcr.io/nvidia/pytorch:21.08-py3 /bin/bash generate_models.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20af1510",
   "metadata": {},
   "source": [
    "## START MME for triton "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c51d963",
   "metadata": {},
   "source": [
    "**Upload first**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f47e576",
   "metadata": {},
   "source": [
    "### Upload multiple copies for MME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1b3019",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range(1,100):\n",
    "    s3_model_path_triton_mme = sagemaker.s3.S3Uploader().upload(\n",
    "        local_path=\"./triton-serve/model.tar.gz\",\n",
    "        desired_s3_uri=f\"s3://sagemaker-us-east-1-622343165275/bloom/triton_models/bert-uc/model-{ii}\",\n",
    "        sagemaker_session=session\n",
    "    )\n",
    "s3_model_path_mme='s3://sagemaker-us-east-1-622343165275/bloom/triton_models/bert-uc'\n",
    "print(\"MULTIPLE:Uplodas:\")\n",
    "print(s3_model_path_triton_mme)\n",
    "print(s3_model_path_mme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82bc35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedc2ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_model_path_mme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb88993",
   "metadata": {},
   "source": [
    "**Create the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e81717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name_p5_mme = name_from_base(f\"p5-bert-uc-mme\")\n",
    "print(endpoint_name_p5_mme)\n",
    "\n",
    "container_p5_mme = {\n",
    "    'Image': triton_image_uri,\n",
    "    'ModelDataUrl': s3_model_path_mme,\n",
    "    'Mode':'MultiModel',\n",
    "    'Environment': {\n",
    "        #'SAGEMAKER_PROGRAM' : 'inference.py',\n",
    "        #'SAGEMAKER_SUBMIT_DIRECTORY' : 'code',\n",
    "        'SAGEMAKER_TRITON_DEFAULT_MODEL_NAME': 'model-1',\n",
    "        \"SAGEMAKER_TRITON_BATCH_SIZE\": \"16\",\n",
    "        \"SAGEMAKER_TRITON_MAX_BATCH_DELAY\": \"1000\",\n",
    "        \"SAGEMAKER_TRITON_SHM_DEFAULT_BYTE_SIZE\" : \"16777216\", #\"16777216000\",\n",
    "        \"SAGEMAKER_TRITON_SHM_GROWTH_BYTE_SIZE\": \"1048576\"\n",
    "    }\n",
    "}\n",
    "create_model_response_mme = sm_client.create_model(\n",
    "    ModelName=endpoint_name_p5_mme, ExecutionRoleArn=role, PrimaryContainer=container_p5_mme\n",
    ")\n",
    "print(create_model_response_mme)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f685bdf0",
   "metadata": {},
   "source": [
    "**Create the Endpoint config**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddedd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_endpoint_config_response_mme = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_name_p5_mme,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"InstanceType\": \"ml.g4dn.xlarge\", #\"ml.g4dn.xlarge\",ml.g5.8xlarge\n",
    "            \"InitialVariantWeight\": 1,\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"ModelName\": endpoint_name_p5_mme,\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response_mme[\"EndpointConfigArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf869733",
   "metadata": {},
   "source": [
    "**Create the endpoint**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35e5855",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_endpoint_response_mme = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name_p5_mme, EndpointConfigName=endpoint_name_p5_mme\n",
    ")\n",
    "\n",
    "print(\"Endpoint Arn: \" + create_endpoint_response_mme[\"EndpointArn\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7553ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name_p5_mme)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"MME:Model:endpoint:Triton:Status: \" + status)\n",
    "\n",
    "while status == \"Creating\":\n",
    "    time.sleep(60)\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpoint_name_p5_mme)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "    print(\"MME:model:triton:Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp[\"EndpointArn\"])\n",
    "print(\"MME:model:triton:Status: \" + status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548c80a5",
   "metadata": {},
   "source": [
    "**Test the end point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af45802",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import json\n",
    "max_seq_length=512\n",
    "text_triton = \"Triton Inference Server provides a cloud and edge inferencing solution optimized for both CPUs and GPUs.\"\n",
    "print(f\"Leverage the Tokenizer={enc}::max_seq_length={max_seq_length}:: create above when creating the model \")\n",
    "input_ids, attention_mask = tokenize_text(text_triton, enc, max_length=max_seq_length)\n",
    "\n",
    "payload = {\n",
    "    \"inputs\": [\n",
    "        {\"name\": \"INPUT__0\", \"shape\": [1, max_seq_length], \"datatype\": \"INT32\", \"data\": input_ids},\n",
    "        {\"name\": \"INPUT__1\", \"shape\": [1, max_seq_length], \"datatype\": \"INT32\", \"data\": attention_mask},\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = runtime_sm_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name_p5_mme, ContentType=\"application/octet-stream\", Body=json.dumps(payload), TargetModel  = \"/model-9/model.tar.gz\"\n",
    ")\n",
    "\n",
    "output_dict = json.loads(response[\"Body\"].read().decode(\"utf8\"))\n",
    "\n",
    "# -- output_dict['outputs'][0]['data']  -- has 0 and 1 as 2 indexes in list \n",
    "output_dict.keys()\n",
    "\n",
    "enc.decode(output_dict['outputs'][0]['data'], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa11ecd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name_p5_mme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dd9f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = runtime_sm_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name_p5_mme, ContentType=\"text/json\", Body=json.dumps(payload), TargetModel  = \"/model-9/model.tar.gz\"\n",
    ")\n",
    "output_dict = json.loads(response[\"Body\"].read().decode(\"utf8\"))\n",
    "\n",
    "# -- output_dict['outputs'][0]['data']  -- has 0 and 1 as 2 indexes in list \n",
    "output_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e948789",
   "metadata": {},
   "source": [
    "**set up in S3 payload to be used for inference load testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ce8887",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length=512\n",
    "text_triton = \"\"\"\n",
    "                Create payload JSON and upload it on S3. \n",
    "                This will be used by Inference Recommender to run the load test.\n",
    "              \"\"\"\n",
    "\n",
    "input_ids, attention_mask = tokenize_text(text_triton, enc, max_length=max_seq_length)\n",
    "\n",
    "payload = {\n",
    "    \"inputs\": [\n",
    "        {\"name\": \"INPUT__0\", \"shape\": [1, max_seq_length], \"datatype\": \"INT32\", \"data\": input_ids},\n",
    "        {\"name\": \"INPUT__1\", \"shape\": [1, max_seq_length], \"datatype\": \"INT32\", \"data\": attention_mask},\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(f\"Sample payload to be used with Inference Recommender\")\n",
    "print(payload)\n",
    "\n",
    "payload_location = \"./sample-payload/\"\n",
    "!mkdir -p $payload_location\n",
    "\n",
    "payload_archive_name = \"payload.tar.gz\"\n",
    "\n",
    "with open(payload_location + \"request.json\", \"w\") as f:\n",
    "    json.dump(payload, f)\n",
    "\n",
    "\n",
    "!cd ./sample-payload/ && tar czvf ../payload.tar.gz *\n",
    "\n",
    "print(f\"payload.tar.gz created at {payload_location}/{payload_archive_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578d4bd0",
   "metadata": {},
   "source": [
    "**Upload sample payload to S3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09803d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_sample_data_path_triton = sagemaker.s3.S3Uploader().upload(\n",
    "    local_path=f\"{payload_archive_name}\",\n",
    "    desired_s3_uri=\"s3://sagemaker-us-east-1-622343165275/bloom/triton_test_data\",\n",
    "    sagemaker_session=session\n",
    ")\n",
    "s3_sample_data_path_triton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7915a23",
   "metadata": {},
   "source": [
    "## Inference Load test set up\n",
    "### DOES NOT WORK FOR MME -- SO SKIP this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963d5bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_domain = \"NATURAL_LANGUAGE_PROCESSING\"\n",
    "ml_task = \"FILL_MASK\"\n",
    "ml_framework = \"PYTORCH\"\n",
    "framework_version = \"1.6.0\"\n",
    "model_tested = \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de326437",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "sm_model_name = \"pt-triton-benchmark-model-\" + ts\n",
    "model_package_group_name = \"pt-triton-benchmark-model-group-\" + ts\n",
    "advanced_job = \"pt-triton-benchmark-advanced-job-\" + ts\n",
    "\n",
    "print(f\"SageMaker Model Name: {sm_model_name}\")\n",
    "print(f\"SageMaker Mode Package Name: {model_package_group_name}\")\n",
    "print(f\"SageMaker Advanced Job Name: {advanced_job}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509de516",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_model_path_mme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab188e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "container_infrec_mme = {\n",
    "    'Image': triton_image_uri,\n",
    "    \"NearestModelName\": model_tested, #'model-1',\n",
    "    \"Framework\": ml_framework,\n",
    "    'ModelDataUrl': s3_model_path_mme,\n",
    "    #'Mode':'MultiModel',\n",
    "    'Environment': {\n",
    "        #'SAGEMAKER_PROGRAM' : 'inference.py',\n",
    "        #'SAGEMAKER_SUBMIT_DIRECTORY' : 'code',\n",
    "        'SAGEMAKER_TRITON_DEFAULT_MODEL_NAME': 'model-1',\n",
    "        \"SAGEMAKER_TRITON_BATCH_SIZE\": \"16\",\n",
    "        \"SAGEMAKER_TRITON_MAX_BATCH_DELAY\": \"1000\",\n",
    "        \"SAGEMAKER_TRITON_SHM_DEFAULT_BYTE_SIZE\" : \"16777216\", #\"16777216000\",\n",
    "        \"SAGEMAKER_TRITON_SHM_GROWTH_BYTE_SIZE\": \"1048576\"\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972b538c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pacakge_group_response = sm_client.create_model_package_group(\n",
    "    ModelPackageGroupName=str(model_package_group_name),\n",
    "    ModelPackageGroupDescription=\"BERT large uncased Model group for Triton Serving\",\n",
    ")\n",
    "print(f\"Model Registry package group: {model_pacakge_group_response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508c9fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_version_response = sm_client.create_model_package(\n",
    "    ModelPackageGroupName=str(model_package_group_name),\n",
    "    ModelPackageDescription=\"BERT large uncased Model group for Triton Serving\",\n",
    "    Domain=ml_domain,\n",
    "    Task=ml_task,\n",
    "    SamplePayloadUrl=s3_sample_data_path_triton,\n",
    "    InferenceSpecification={\n",
    "        \"Containers\": [container_infrec_mme],\n",
    "        \"SupportedRealtimeInferenceInstanceTypes\": [\n",
    "            \"ml.g4dn.4xlarge\",\n",
    "            \"ml.g4dn.4xlarge\",\n",
    "        ],\n",
    "        \"SupportedContentTypes\": [\"application/octet-stream\"],\n",
    "        \"SupportedResponseMIMETypes\": [\"application/json\"],\n",
    "    },\n",
    ")\n",
    "model_package_version_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a7671f",
   "metadata": {},
   "outputs": [],
   "source": [
    "advanced_response = sm_client.create_inference_recommendations_job(\n",
    "    JobName=advanced_job,\n",
    "    JobDescription=\"nlp triton Inference Advanced Recommender Job\",\n",
    "    JobType=\"Advanced\",\n",
    "    RoleArn=role,\n",
    "    InputConfig={\n",
    "        \"ModelPackageVersionArn\": model_package_version_response[\"ModelPackageArn\"],\n",
    "        \"JobDurationInSeconds\": 7200,\n",
    "        \"EndpointConfigurations\": [\n",
    "            #{\"InstanceType\": \"ml.p3.8xlarge\"},\n",
    "            #{\"InstanceType\": \"ml.p3.2xlarge\"},\n",
    "            {\"InstanceType\": \"ml.p2.16xlarge\"},\n",
    "            {\"InstanceType\": \"ml.g4dn.xlarge\"},\n",
    "            {\"InstanceType\": \"ml.g4dn.8xlarge\"},\n",
    "            {\"InstanceType\": \"ml.g4dn.4xlarge\"},\n",
    "            {\"InstanceType\": \"ml.g4dn.2xlarge\"},\n",
    "            {\"InstanceType\": \"ml.g4dn.12xlarge\"},\n",
    "        ],\n",
    "        \"TrafficPattern\": {\n",
    "            \"TrafficType\": \"PHASES\",\n",
    "            \"Phases\": [\n",
    "                {\n",
    "                    \"InitialNumberOfUsers\": 2,\n",
    "                    \"SpawnRate\": 3,\n",
    "                    \"DurationInSeconds\": 900,\n",
    "                },  # simulating 50 users, 2 initial and 3 new users every minute for 16 minutes\n",
    "            ],  # second phase, we will strt with 50 users, steady traffic for 5 minutes\n",
    "        },\n",
    "        \"ResourceLimit\": {\"MaxNumberOfTests\": 10, \"MaxParallelOfTests\": 5},\n",
    "    },\n",
    "    StoppingConditions={\n",
    "        \"MaxInvocations\": 30000,\n",
    "        \"ModelLatencyThresholds\": [{\"Percentile\": \"P95\", \"ValueInMilliseconds\": 500}],\n",
    "    },\n",
    ")\n",
    "\n",
    "print(advanced_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97377dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ended = False\n",
    "while not ended:\n",
    "    inference_recommender_job = sm_client.describe_inference_recommendations_job(\n",
    "        JobName=str(advanced_job)\n",
    "    )\n",
    "    if inference_recommender_job[\"Status\"] in [\"COMPLETED\", \"STOPPED\", \"FAILED\"]:\n",
    "        print(f\"Inference recommender job status: {inference_recommender_job['Status']} \")\n",
    "        ended = True\n",
    "    else:\n",
    "        print(\"Inference recommender job in progress\")\n",
    "        time.sleep(300)\n",
    "\n",
    "if inference_recommender_job[\"Status\"] == \"FAILED\":\n",
    "    print(\"Inference recommender job failed \")\n",
    "    print(\"Failed Reason: {}\".inference_recommender_job[\"FailedReason\"])\n",
    "else:\n",
    "    print(\"Inference recommender job completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bb227f",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee3c966",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af5726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client.delete_endpoint(EndpointName=endpoint_name_p5_mme)\n",
    "sm_client.delete_endpoint_config(EndpointConfigName=endpoint_name_p5_mme)\n",
    "sm_client.delete_model(ModelName=endpoint_name_p5_mme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72583cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
