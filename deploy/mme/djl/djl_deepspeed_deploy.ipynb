{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "137afef2",
   "metadata": {},
   "source": [
    "\n",
    "### Serve large models on SageMaker with DeepSpeed Container\n",
    "\n",
    "In this notebook, we explore how to host a large language model on SageMaker using the latest container launched using from DeepSpeed.\n",
    "\n",
    "Language models have recently exploded in both size and popularity. In 2018, BERT-large entered the scene and, with its 340M parameters and novel transformer architecture, set the standard on NLP task accuracy. Within just a few years, state-of-the-art NLP model size has grown by more than 500x with models such as OpenAIâ€™s 175 billion parameter GPT-3 and similarly sized open source Bloom 176B raising the bar on NLP accuracy. This increase in the number of parameters is driven by the simple and empirically-demonstrated positive relationship between model size and accuracy: more is better. With easy access from models zoos such as Hugging Face and improved accuracy in NLP tasks such as classification and text generation, practitioners are increasingly reaching for these large models. However, deploying them can be a challenge because of their size.\n",
    "\n",
    "Model parallelism can help deploy large models that would normally be too large for a single GPU. With model parallelism, we partition and distribute a model across multiple GPUs. Each GPU holds a different part of the model, resolving the memory capacity issue for the largest deep learning models with billions of parameters. This notebook uses tensor parallelism techniques which allow GPUs to work simultaneously on the same layer of a model and achieve low latency inference relative to a pipeline parallel solution.\n",
    "\n",
    "SageMaker has rolled out DeepSpeed container which now provides users with the ability to leverage the managed serving capabilities and help to provide the un-differentiated heavy lifting\n",
    "\n",
    "In this notebook, we deploy the open source Bloom 176B quantized model across GPU's on a ml.p4d.24xlarge instance. DeepSpeed is used for tensor parallelism inference while DJLServing handles inference requests and the distributed workers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "74586408",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "docker-compose 1.29.2 requires jsonschema<4,>=2.5.1, but you have jsonschema 4.16.0 which is incompatible.\n",
      "docker-compose 1.29.2 requires websocket-client<1,>=0.32.0, but you have websocket-client 1.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Instal boto3 library to create model and run inference workloads\n",
    "%pip install -Uqq boto3 awscli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c0f33b",
   "metadata": {},
   "source": [
    "## Setup Docker Image\n",
    "This section should be removed after DLC release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e6e9cad",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19.0-deepspeed: Pulling from deepjavalibrary/djl-serving\n",
      "d5fd17ec1767: Pulling fs layer\n",
      "602a45a9c0c5: Pulling fs layer\n",
      "e1bae4c1f40f: Pulling fs layer\n",
      "d9d586ab2510: Pulling fs layer\n",
      "2b44adc78060: Pulling fs layer\n",
      "cd4d84563a60: Pulling fs layer\n",
      "e19a4e23074d: Pulling fs layer\n",
      "a69bd65705b8: Pulling fs layer\n",
      "7145f7b4815b: Pulling fs layer\n",
      "e367c0f08642: Pulling fs layer\n",
      "f98db42fa8f9: Pulling fs layer\n",
      "889527aaa22f: Pulling fs layer\n",
      "a061992ad5a9: Pulling fs layer\n",
      "4557083dcd61: Pulling fs layer\n",
      "c5b78129d513: Pulling fs layer\n",
      "1971a3fe9e0d: Pulling fs layer\n",
      "ff79d3f300b0: Pulling fs layer\n",
      "601a5fb776e4: Pulling fs layer\n",
      "2b44adc78060: Waiting\n",
      "cd4d84563a60: Waiting\n",
      "e19a4e23074d: Waiting\n",
      "a69bd65705b8: Waiting\n",
      "7145f7b4815b: Waiting\n",
      "e367c0f08642: Waiting\n",
      "f98db42fa8f9: Waiting\n",
      "889527aaa22f: Waiting\n",
      "a061992ad5a9: Waiting\n",
      "4557083dcd61: Waiting\n",
      "c5b78129d513: Waiting\n",
      "1971a3fe9e0d: Waiting\n",
      "ff79d3f300b0: Waiting\n",
      "d9d586ab2510: Waiting\n",
      "601a5fb776e4: Waiting\n",
      "602a45a9c0c5: Verifying Checksum\n",
      "602a45a9c0c5: Download complete\n",
      "d9d586ab2510: Verifying Checksum\n",
      "d9d586ab2510: Download complete\n",
      "e1bae4c1f40f: Verifying Checksum\n",
      "e1bae4c1f40f: Download complete\n",
      "2b44adc78060: Download complete\n",
      "e19a4e23074d: Download complete\n",
      "d5fd17ec1767: Download complete\n",
      "7145f7b4815b: Verifying Checksum\n",
      "7145f7b4815b: Download complete\n",
      "d5fd17ec1767: Pull complete\n",
      "602a45a9c0c5: Pull complete\n",
      "e1bae4c1f40f: Pull complete\n",
      "d9d586ab2510: Pull complete\n",
      "2b44adc78060: Pull complete\n",
      "cd4d84563a60: Verifying Checksum\n",
      "cd4d84563a60: Download complete\n",
      "f98db42fa8f9: Verifying Checksum\n",
      "f98db42fa8f9: Download complete\n",
      "889527aaa22f: Verifying Checksum\n",
      "889527aaa22f: Download complete\n",
      "a061992ad5a9: Verifying Checksum\n",
      "a061992ad5a9: Download complete\n",
      "4557083dcd61: Verifying Checksum\n",
      "4557083dcd61: Download complete\n",
      "c5b78129d513: Verifying Checksum\n",
      "c5b78129d513: Download complete\n",
      "1971a3fe9e0d: Download complete\n",
      "a69bd65705b8: Download complete\n",
      "ff79d3f300b0: Verifying Checksum\n",
      "ff79d3f300b0: Download complete\n",
      "e367c0f08642: Verifying Checksum\n",
      "e367c0f08642: Download complete\n",
      "cd4d84563a60: Pull complete\n",
      "e19a4e23074d: Pull complete\n",
      "601a5fb776e4: Verifying Checksum\n",
      "601a5fb776e4: Download complete\n",
      "a69bd65705b8: Pull complete\n",
      "7145f7b4815b: Pull complete\n",
      "e367c0f08642: Pull complete\n",
      "f98db42fa8f9: Pull complete\n",
      "889527aaa22f: Pull complete\n",
      "a061992ad5a9: Pull complete\n",
      "4557083dcd61: Pull complete\n",
      "c5b78129d513: Pull complete\n",
      "1971a3fe9e0d: Pull complete\n",
      "ff79d3f300b0: Pull complete\n",
      "601a5fb776e4: Pull complete\n",
      "Digest: sha256:4efe305d22a2fae128dec98f0d506c225aeea34ae078f2d00f10760c6f7b3990\n",
      "Status: Image is up to date for deepjavalibrary/djl-serving:0.19.0-deepspeed\n",
      "docker.io/deepjavalibrary/djl-serving:0.19.0-deepspeed\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "docker pull deepjavalibrary/djl-serving:0.19.0-deepspeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7eb6baa9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_id=8344d1c51e98\n",
      "repo_name=djl-ds\n",
      "Full_name=622343165275.dkr.ecr.us-east-1.amazonaws.com/djl-ds:latest\n",
      "Login Succeeded\n",
      "image_id=8344d1c51e98\n",
      "The push refers to repository [622343165275.dkr.ecr.us-east-1.amazonaws.com/djl-ds]\n",
      "b67adf46a2f4: Preparing\n",
      "5dd1da667968: Preparing\n",
      "f4c0ee9d3ebe: Preparing\n",
      "ac511274f948: Preparing\n",
      "ba1a8dd44a3b: Preparing\n",
      "36aca82a9594: Preparing\n",
      "a8bb2bd009b8: Preparing\n",
      "2830fca3c261: Preparing\n",
      "1a5fac543081: Preparing\n",
      "a8d0c4c62eef: Preparing\n",
      "7ed9a71261c7: Preparing\n",
      "a1eeba43cdbe: Preparing\n",
      "6127942867a5: Preparing\n",
      "e592fe6d10a9: Preparing\n",
      "f42691182163: Preparing\n",
      "68016c5bb65c: Preparing\n",
      "8034550a3bbe: Preparing\n",
      "bf8cedc62fb3: Preparing\n",
      "36aca82a9594: Waiting\n",
      "a8bb2bd009b8: Waiting\n",
      "2830fca3c261: Waiting\n",
      "1a5fac543081: Waiting\n",
      "a8d0c4c62eef: Waiting\n",
      "7ed9a71261c7: Waiting\n",
      "a1eeba43cdbe: Waiting\n",
      "6127942867a5: Waiting\n",
      "e592fe6d10a9: Waiting\n",
      "f42691182163: Waiting\n",
      "68016c5bb65c: Waiting\n",
      "8034550a3bbe: Waiting\n",
      "bf8cedc62fb3: Waiting\n",
      "ac511274f948: Pushed\n",
      "ba1a8dd44a3b: Pushed\n",
      "f4c0ee9d3ebe: Pushed\n",
      "a8bb2bd009b8: Pushed\n",
      "36aca82a9594: Pushed\n",
      "2830fca3c261: Pushed\n",
      "a8d0c4c62eef: Pushed\n",
      "a1eeba43cdbe: Pushed\n",
      "5dd1da667968: Pushed\n",
      "e592fe6d10a9: Pushed\n",
      "f42691182163: Pushed\n",
      "68016c5bb65c: Pushed\n",
      "8034550a3bbe: Pushed\n",
      "bf8cedc62fb3: Pushed\n",
      "6127942867a5: Pushed\n",
      "7ed9a71261c7: Pushed\n",
      "1a5fac543081: Pushed\n",
      "b67adf46a2f4: Pushed\n",
      "latest: digest: sha256:4efe305d22a2fae128dec98f0d506c225aeea34ae078f2d00f10760c6f7b3990 size: 4098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "# The name of our algorithm\n",
    "image_id=$(docker images | grep 0.19.0-deepspeed | tr -s \" \" | cut -d \" \" -f 3)\n",
    "echo \"image_id=${image_id}\"\n",
    "\n",
    "\n",
    "repo_name='djl-ds' # same as algorithim name\n",
    "echo \"repo_name=$repo_name\"\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-east-1}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${repo_name}:latest\"\n",
    "echo \"Full_name=$fullname\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${repo_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${repo_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "image_id=$(docker images | grep 0.19.0-deepspeed | tr -s \" \" | cut -d \" \" -f 3)\n",
    "\n",
    "echo \"image_id=${image_id}\"\n",
    "\n",
    "#docker build -q -t ${algorithm_name} .\n",
    "\n",
    "docker tag $image_id ${fullname}\n",
    "#docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b066843c",
   "metadata": {},
   "source": [
    "## Optional Download Model from Hugging Face Hub\n",
    "\n",
    "Use this section of you are interested in downloading the model directly from Huggingface hub and storing in your own S3 bucket. This notebook currently leverages the Micosoft model stored in AWS public S3 location for ease of use. This step to download and then upload to S3 can take several minutes since the model size is extremely large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dea02502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install huggingface-hub -Uqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8034121c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa205b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - This will download the model into the ./model directory where ever the jupyter file is running\n",
    "local_model_path = Path(\"./model\")\n",
    "local_model_path.mkdir(exist_ok=True)\n",
    "model_name = \"microsoft/bloom-deepspeed-inference-int8\"\n",
    "commit_hash = \"aa00a6626f6484a2eef68e06d1e089e4e32aa571\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2c1935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Leverage the snapshot library to donload the model since the model is stored in repository using LFS\n",
    "snapshot_download(repo_id=model_name, \n",
    "                  revision=commit_hash,\n",
    "                  cache_dir=local_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4b4365",
   "metadata": {},
   "source": [
    "#### Upload to S3 using the awscli "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660c488e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_model_prefix = \"hf-large-model-djl-ds/model\" # folder where model checkpoint will go\n",
    "model_snapshot_path = list(local_model_path.glob(\"**/snapshots/*\"))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10da1e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive {model_snapshot_path} s3://{bucket}/{s3_model_prefix}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fb2fd1",
   "metadata": {},
   "source": [
    "## Create SageMaker compatible Model artifact and Upload Model to S3\n",
    "\n",
    "SageMaker needs the model to be in a Tarball format. In this notebook we are going to create the model with the Inference code to shorten the end point creation time. In the Inference code we kick of a multi threaded approach to download the model weights into the container using awscli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ed9f0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import image_uris\n",
    "import boto3\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "032aa155",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()      # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()         # sagemaker session for interacting with different AWS APIs\n",
    "bucket = sess.default_bucket()             # bucket to house artifacts\n",
    "s3_code_prefix = \"hf-large-model-djl-ds/code\"    # folder within bucket where code artifact will go\n",
    "s3_model_prefix = \"hf-large-model-djl-ds/model\" # folder where model checkpoint will go\n",
    "\n",
    "region = sess._region_name\n",
    "account_id = sess.account_id()\n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "smr_client = boto3.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c1556f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'622343165275.dkr.ecr.us-east-1.amazonaws.com/djl-ds:latest'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_image_uri = f\"{account_id}.dkr.ecr.{region}.amazonaws.com/djl-ds:latest\"\n",
    "inference_image_uri\n",
    "# 622343165275.dkr.ecr.us-east-1.amazonaws.com/djl-ds:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a21f7bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code/\n",
      "code/serving.properties\n",
      "code/model.py\n",
      "code/.ipynb_checkpoints/\n",
      "code/.ipynb_checkpoints/model-checkpoint.py\n",
      "code/.ipynb_checkpoints/requirements-checkpoint.txt\n",
      "code/.ipynb_checkpoints/serving-checkpoint.properties\n",
      "code/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "!rm model.tar.gz\n",
    "!tar czvf model.tar.gz code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab336f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-622343165275/hf-large-model-djl-ds/code/model.tar.gz'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_code_artifact = sess.upload_data(\"model.tar.gz\", bucket, s3_code_prefix)\n",
    "s3_code_artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce11038",
   "metadata": {},
   "source": [
    "#### This works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "786256ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bloom-176B/raw_model_microsoft/\n",
      "sagemaker-us-east-1-622343165275\n"
     ]
    }
   ],
   "source": [
    "s3_model_prefix = 'bloom-176B/raw_model_microsoft/'\n",
    "print(s3_model_prefix)\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c082aa8",
   "metadata": {},
   "source": [
    "#### Test the new downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c7d62879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hf-large-model-djl-ds/model/\n",
      "sagemaker-us-east-1-622343165275\n"
     ]
    }
   ],
   "source": [
    "s3_model_prefix = 'hf-large-model-djl-ds/model/'\n",
    "print(s3_model_prefix)\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9bd19003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['subnet-0508539ff391bc62a', 'subnet-0f88fe2e674a870c4', 'subnet-02e4d3f4bd7ac9e66', 'subnet-0814f48bf38ffc0ae', 'subnet-076597677e5d1293b', 'subnet-09e3b111fe0bc7fa7']\n",
      "vpc-05edeb4f9b293161c\n",
      "sg-042c834d701c600a1\n"
     ]
    }
   ],
   "source": [
    "!aws sagemaker describe-domain --domain-id d-vj9jud4p6ywy | python3 -c \"import sys, json; print(json.load(sys.stdin)['SubnetIds'])\"\n",
    "!aws sagemaker describe-domain --domain-id d-vj9jud4p6ywy | python3 -c \"import sys, json; print(json.load(sys.stdin)['VpcId'])\"\n",
    "!aws ec2 describe-security-groups --filter Name=vpc-id,Values=vpc-05edeb4f9b293161c | python3 -c \"import sys, json; print(json.load(sys.stdin)['SecurityGroups'][0]['GroupId'])\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1555a729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SecurityGroupIds': [], 'Subnets': []}\n"
     ]
    }
   ],
   "source": [
    "# - provide networking configs if needed. \n",
    "security_group_ids = [] # add the security group id's\n",
    "subnets = [] # add the subnet id for this vpc\n",
    "privateVpcConfig={\n",
    "    'SecurityGroupIds': security_group_ids, \n",
    "    'Subnets': subnets\n",
    "}\n",
    "print(privateVpcConfig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c7351056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622343165275.dkr.ecr.us-east-1.amazonaws.com/djl-ds:latest\n"
     ]
    }
   ],
   "source": [
    "# - print the Inference image\n",
    "print(inference_image_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5940abbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bloom-djl-ds-2022-10-27-19-41-28-480\n",
      "Created Model: arn:aws:sagemaker:us-east-1:622343165275:model/bloom-djl-ds-2022-10-27-19-41-28-480\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.utils import name_from_base\n",
    "model_name = name_from_base(f\"bloom-djl-ds\")\n",
    "print(model_name)\n",
    "\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName=model_name,\n",
    "    ExecutionRoleArn=role,\n",
    "    PrimaryContainer={\n",
    "        \"Image\": inference_image_uri,\n",
    "        \"ModelDataUrl\": s3_code_artifact,\n",
    "        \"Environment\": {\n",
    "            \"MODEL_S3_BUCKET\": bucket,\n",
    "            \"MODEL_S3_PREFIX\": s3_model_prefix,\n",
    "            \"TENSOR_PARALLEL_DEGREE\": \"8\"\n",
    "        },\n",
    "    },\n",
    "    # Uncomment if providing networking configs\n",
    "    #VpcConfig=privateVpcConfig\n",
    ")\n",
    "model_arn = create_model_response[\"ModelArn\"]\n",
    "\n",
    "print(f\"Created Model: {model_arn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "04282919",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_config_name = f\"{model_name}-config\"\n",
    "endpoint_name = f\"{model_name}-endpoint\"\n",
    "\n",
    "endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"variant1\",\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": \"ml.p4d.24xlarge\",\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            # \"VolumeSizeInGB\" : 200\n",
    "            'ModelDataDownloadTimeoutInSeconds': 2400,\n",
    "            'ContainerStartupHealthCheckTimeoutInSeconds': 2400\n",
    "        },\n",
    "    ],\n",
    "     \n",
    ")\n",
    "endpoint_config_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d2de891c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Endpoint: arn:aws:sagemaker:us-east-1:622343165275:endpoint/bloom-djl-ds-2022-10-27-19-41-28-480-endpoint\n"
     ]
    }
   ],
   "source": [
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=f\"{endpoint_name}\", EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "print(f\"Created Endpoint: {create_endpoint_response['EndpointArn']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "024b0335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: InService\n",
      "Arn: arn:aws:sagemaker:us-east-1:622343165275:endpoint/bloom-djl-ds-2022-10-27-19-41-28-480-endpoint\n",
      "Status: InService\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp['EndpointStatus']\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status=='Creating':\n",
    "    time.sleep(60)\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp['EndpointStatus']\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp['EndpointArn'])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "56fdd46e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\n  \"Amazon.com is the best  online shopping site in the world. It has a wide range of products. You can buy anything you want from the site. The site is very easy to use and you can search for the product you are looking for. There are a lot of options to choose from and the prices are very reasonable. I have been using this site for a long time now and I am very happy with the service. They have a very good customer service and they are always ready to help you with any problem you have\"\\n]'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smr_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=json.dumps({\"input\": \"Amazon.com is the best \", \"gen_kwargs\": {\"min_length\":5, \"max_new_tokens\": 100, \"temperature\": 0.8, \"num_beams\": 5, \"no_repeat_ngram_size\": 2} }),\n",
    "    ContentType='application/json'\n",
    ")[\"Body\"].read().decode(\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457b0b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9970ccff",
   "metadata": {},
   "source": [
    "## Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51c0e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Delete the end point \n",
    "sm_client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5b6eeecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '0151fe17-2ae0-431d-98df-764c3f8f9151',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '0151fe17-2ae0-431d-98df-764c3f8f9151',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Thu, 27 Oct 2022 17:39:48 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# - In case the end point failed we still want to delete the model \n",
    "sm_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "sm_client.delete_model(ModelName=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01284814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally delete the model checkpoint from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6c3f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 rm --recursive s3://{bucket}/{s3_model_prefix}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcad6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client(\"s3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e50e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(s3_client.list_objects(Bucket=bucket, Prefix=f\"{s3_model_prefix}/\")[\"Contents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8443ced3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
