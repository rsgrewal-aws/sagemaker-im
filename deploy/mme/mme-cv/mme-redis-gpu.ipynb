{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "---\n",
    "## <span style=\"color:orange\"> Host Multiple TensorFlow Computer Vision Models using SageMaker Multi-Model Endpoint </span>\n",
    "---\n",
    "## <span style=\"color:black\">Contents</span>\n",
    "1. [Background](#Background)\n",
    "1. [Setup](#Setup)\n",
    "1. [Train Model 2 - Sign Language Image Classification](#Train-Model-2---Sign-Language-Image-Classification)\n",
    "1. [Create a Multi-Model Endpoint](#Create-a-Multi-Model-Endpoint)\n",
    "1. [Test Multi-Model Endpoint for Real Time Inference](#Test-Multi-Model-Endpoint-for-Real-Time-Inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Background\n",
    "In this notebook, we show how to host multiple computer vision models trained using the TensorFlow framework under one SageMaker multi-model endpoint.  For the model we use a pretrained VGG16 CNN model pretrained on the ImageNet dataset and fine-tune on Sign Language Digits Dataset.\n",
    "\n",
    "in this notebook we are using the final version as training is not the focus. To simulate multiple models we will create copies of the same model and load them in S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    " #### Prerequisites \n",
    " Choose Kernel for this notebook.<br>\n",
    " Under `Kernel` tab at the top of this notebook &#8594; `Choose kernel`, select `conda_python3` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install tensorflow==2.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 16:35:45.920107: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.0/lib64:/usr/local/cuda-11.0/extras/CUPTI/lib64:/usr/local/cuda-11.0/lib:/usr/local/cuda-11.0/efa/lib:/opt/amazon/efa/lib:/opt/amazon/efa/lib64:/opt/amazon/efa/lib64:/opt/amazon/openmpi/lib64:/usr/local/lib:/usr/lib:/lib:\n",
      "2022-11-10 16:35:45.920131: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall tensorflow -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall redis -y\n",
    "!pip uninstall redis-py-cluster -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install redis-py-cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.0.1 requires botocore<1.22.9,>=1.22.8, but you have botocore 1.29.6 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U awscli --quiet\n",
    "!pip install torch==1.8.0 --quiet \n",
    "!pip install torchvision==0.9.0 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting mxnet\n",
      "  Downloading mxnet-1.9.1-py3-none-manylinux2014_x86_64.whl (49.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from mxnet) (1.18.5)\n",
      "Collecting graphviz<0.9.0,>=0.8.1\n",
      "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from mxnet) (2.26.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from requests<3,>=2.20.0->mxnet) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from requests<3,>=2.20.0->mxnet) (2.0.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from requests<3,>=2.20.0->mxnet) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from requests<3,>=2.20.0->mxnet) (3.1)\n",
      "Installing collected packages: graphviz, mxnet\n",
      "Successfully installed graphviz-0.8.4 mxnet-1.9.1\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install mxnet --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sagemaker.tensorflow.serving import TensorFlowModel\n",
    "from sagemaker.multidatamodel import MultiDataModel\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker import get_execution_role\n",
    "from tensorflow.keras import utils\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "import logging\n",
    "import boto3\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "from rediscluster import RedisCluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using sageMaker VPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rediscluster import RedisCluster\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "redis = RedisCluster(\n",
    "    startup_nodes=[{\"host\": 'testblogredismemcache.m7ovi1.ng.0001.use1.cache.amazonaws.com', \"port\": '6379'}],\n",
    "    decode_responses=True, #ssl=True, skip_full_coverage_check=True,\n",
    "    username='default', \n",
    "    #password='testRedisUserpassword'\n",
    ")\n",
    "\n",
    "if redis.ping():\n",
    "    print(\"Connected to Redis in CLUSTER mode\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Redis in single mode \n"
     ]
    }
   ],
   "source": [
    "from redis import Redis\n",
    "redis_client = Redis(\n",
    "    host='testredis.m7ovi1.ng.0001.use1.cache.amazonaws.com', \n",
    "    port=6379, #decode_responses=True, ssl=True, \n",
    "    username='default', #'testredisuser', 'default'\n",
    "    #password='testRedisUserPassword'\n",
    ")\n",
    "# redis_client = Redis(\n",
    "#     host='testredis.m7ovi1.ng.0001.use1.cache.amazonaws.com',\n",
    "#     username='testredisuser',\n",
    "#     password='testRedisUserPassword', ssl_cert_reqs=None,  decode_responses=True)\n",
    "\n",
    "if redis_client.ping():\n",
    "    print(\"Connected to Redis in single mode \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Setup Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Using TensorFlow version: 2.3.0]\n",
      "INFO:__main__:[Using TensorFlow version: 2.3.0]\n",
      "[Using SageMaker version: 2.116.0]\n",
      "INFO:__main__:[Using SageMaker version: 2.116.0]\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'[Using TensorFlow version: {tf.__version__}]')\n",
    "logger.info(f'[Using SageMaker version: {sagemaker.__version__}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Seed for Reproducability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "SEED = 123\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Create Roles, Sessions and Data Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-1\n",
      "622343165275\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "session = boto3.Session()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region=sagemaker_session.boto_region_name\n",
    "print(region)\n",
    "account_id = sagemaker_session.account_id()\n",
    "print(account_id)\n",
    "\n",
    "s3 = session.resource('s3')\n",
    "TF_FRAMEWORK_VERSION = '2.3.0'\n",
    "BUCKET = sagemaker.Session().default_bucket()\n",
    "PREFIX = 'cv-models'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### b) Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# - ./data/sign_language/train/0/IMG_1118.JPG\n",
    "train_path  = './data/sign_language/train'\n",
    "img = mpimg.imread(f'{train_path}/0/IMG_1118.JPG')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create custom container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "sha256:6cffa50ea4c74b597245be87d75fb6af20bda366078ca81860938d7a9f414f98\n",
      "The push refers to repository [622343165275.dkr.ecr.us-east-1.amazonaws.com/demo-redis-cv-gpu]\n",
      "4d5116e47ba8: Preparing\n",
      "36d84765fb87: Preparing\n",
      "2ce39db8f45d: Preparing\n",
      "d2c565221bb9: Preparing\n",
      "e22b9da2be44: Preparing\n",
      "0f13e18a9cc4: Preparing\n",
      "b7abf7d0bb2c: Preparing\n",
      "eba15308a6ba: Preparing\n",
      "a92e3c51a0b6: Preparing\n",
      "419e1b612781: Preparing\n",
      "599518d61809: Preparing\n",
      "dda6665a48d3: Preparing\n",
      "69f57fbceb1b: Preparing\n",
      "0f13e18a9cc4: Waiting\n",
      "b7abf7d0bb2c: Waiting\n",
      "dda6665a48d3: Waiting\n",
      "eba15308a6ba: Waiting\n",
      "69f57fbceb1b: Waiting\n",
      "a92e3c51a0b6: Waiting\n",
      "599518d61809: Waiting\n",
      "2ce39db8f45d: Layer already exists\n",
      "e22b9da2be44: Layer already exists\n",
      "36d84765fb87: Layer already exists\n",
      "d2c565221bb9: Layer already exists\n",
      "0f13e18a9cc4: Layer already exists\n",
      "eba15308a6ba: Layer already exists\n",
      "a92e3c51a0b6: Layer already exists\n",
      "b7abf7d0bb2c: Layer already exists\n",
      "599518d61809: Layer already exists\n",
      "419e1b612781: Layer already exists\n",
      "dda6665a48d3: Layer already exists\n",
      "69f57fbceb1b: Layer already exists\n",
      "4d5116e47ba8: Pushed\n",
      "latest: digest: sha256:b119b93fb29b7cd1a1cbec440ef7d4d230759ae2157a0f9b63c48c84b5fd69e0 size: 3039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=demo-redis-cv-gpu\n",
    "\n",
    "cd container_gpu\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build -q -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download resnet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import os\n",
    "import tarfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import os\n",
    "import tarfile\n",
    "\n",
    "model_path = \"http://data.mxnet.io/models/imagenet/\"\n",
    "!mkdir -p models/resnet_18\n",
    "\n",
    "mx.test_utils.download(\n",
    "    model_path + \"resnet/18-layers/resnet-18-0000.params\", None, \"models/resnet_18\"\n",
    ")\n",
    "mx.test_utils.download(\n",
    "    model_path + \"resnet/18-layers/resnet-18-symbol.json\", None, \"models/resnet_18\"\n",
    ")\n",
    "mx.test_utils.download(model_path + \"synset.txt\", None, \"data/resnet_18\")\n",
    "\n",
    "with open(\"models/resnet_18/resnet-18-shapes.json\", \"w\") as file:\n",
    "    file.write('[{\"shape\": [1, 3, 224, 224], \"name\": \"data\"}]')\n",
    "\n",
    "with tarfile.open(\"models/resnet_18.tar.gz\", \"w:gz\") as tar:\n",
    "    tar.add(\"models/resnet_18\", arcname=\".\")\n",
    "    \n",
    " \n",
    "!mkdir -p models/resnet_152\n",
    "mx.test_utils.download(\n",
    "    model_path + \"resnet/152-layers/resnet-152-0000.params\", None, \"models/resnet_152\"\n",
    ")\n",
    "mx.test_utils.download(\n",
    "    model_path + \"resnet/152-layers/resnet-152-symbol.json\", None, \"models/resnet_152\"\n",
    ")\n",
    "mx.test_utils.download(model_path + \"synset.txt\", None, \"data/resnet_152\")\n",
    "\n",
    "with open(\"models/resnet_152/resnet-152-shapes.json\", \"w\") as file:\n",
    "    file.write('[{\"shape\": [1, 3, 224, 224], \"name\": \"data\"}]')\n",
    "\n",
    "with tarfile.open(\"models/resnet_152.tar.gz\", \"w:gz\") as tar:\n",
    "    tar.add(\"data/resnet_152\", arcname=\".\") \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-622343165275\n",
      "cv-models\n",
      "arn:aws:iam::622343165275:role/service-role/AmazonSageMaker-ExecutionRole-20220208T115633\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "s3_bucket = sess.default_bucket()  # Replace with your own bucket name if needed\n",
    "prefix = \"cv-models\"\n",
    "print(s3_bucket)\n",
    "print(prefix)\n",
    "\n",
    "sm_client = boto3.client(service_name=\"sagemaker\")\n",
    "runtime_sm_client = boto3.client(service_name=\"sagemaker-runtime\")\n",
    "\n",
    "account_id = boto3.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.client import ClientError\n",
    "import os\n",
    "\n",
    "s3 = boto3.resource(\"s3\")\n",
    "s3.meta.client.head_bucket(Bucket=s3_bucket)\n",
    "\n",
    "models = {\"resnet_18.tar.gz\", \"resnet_152.tar.gz\"}\n",
    "\n",
    "for model in models:\n",
    "    key = os.path.join(prefix, model)\n",
    "    with open(\"models/\" + model, \"rb\") as file_obj:\n",
    "        s3.Bucket(s3_bucket).Object(key).upload_fileobj(file_obj)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create end point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: GPU-REDIS-CV-MME2022-11-10-21-43-59\n",
      "Model data Url: s3://sagemaker-us-east-1-622343165275/cv-models/resnet_18.tar.gz\n",
      "Container image: 622343165275.dkr.ecr.us-east-1.amazonaws.com/demo-redis-cv-gpu:latest\n",
      "Model Arn: arn:aws:sagemaker:us-east-1:622343165275:model/gpu-redis-cv-mme2022-11-10-21-43-59\n"
     ]
    }
   ],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "model_name = \"GPU-REDIS-CV-MME\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "#model_url = \"https://s3-{}.amazonaws.com/{}/{}/\".format(region, s3_bucket, prefix)\n",
    "\n",
    "# -- 622343165275.dkr.ecr.us-east-1.amazonaws.com/demo-redis-cv-gpu    \n",
    "container = \"{}.dkr.ecr.{}.amazonaws.com/{}:latest\".format(\n",
    "    account_id, region, \"demo-redis-cv-gpu\"\n",
    ")\n",
    "\n",
    "# print(\"Model name: \" + model_name)\n",
    "# print(\"Model data Url: \" + model_url)\n",
    "# print(\"Container image: \" + container)\n",
    "\n",
    "#primary_container = {\"Image\": container, \"ModelDataUrl\": model_url, \"Mode\": \"MultiModel\"}\n",
    "\n",
    "# create_model_response = sm_client.create_model(\n",
    "#     ModelName=model_name, ExecutionRoleArn=role, Containers=[primary_container]\n",
    "# )\n",
    "\n",
    "\n",
    "vpc = 'vpc-05edeb4f9b293161c'\n",
    "subnet_a = 'subnet-0508539ff391bc62a'\n",
    "subnet_b = 'subnet-0f88fe2e674a870c4'\n",
    "\n",
    "subnet_c = 'subnet-02e4d3f4bd7ac9e66'\n",
    "subnet_d = 'subnet-0814f48bf38ffc0ae'\n",
    "subnet_e = 'subnet-076597677e5d1293b'\n",
    "subnet_f = 'subnet-09e3b111fe0bc7fa7'\n",
    "\n",
    "\n",
    "security_group = 'sg-0394e815564b9f05a'\n",
    "\n",
    "model_url = 's3://sagemaker-us-east-1-622343165275/cv-models/resnet_18.tar.gz'\n",
    "print(\"Model name: \" + model_name)\n",
    "print(\"Model data Url: \" + model_url)\n",
    "print(\"Container image: \" + container)\n",
    "\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    PrimaryContainer = {\n",
    "        'Image': container,\n",
    "        'ModelDataUrl': model_url\n",
    "    },\n",
    "    VpcConfig = {\n",
    "        'SecurityGroupIds': [security_group],\n",
    "        'Subnets': [subnet_a, subnet_b,subnet_c,subnet_d,subnet_e,subnet_f,],\n",
    "    },\n",
    "    EnableNetworkIsolation=False\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Model Arn: \" + create_model_response[\"ModelArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End point config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint config name: GPU-REDIS-CV-MME2022-11-10-21-43-59\n",
      "Endpoint config Arn: arn:aws:sagemaker:us-east-1:622343165275:endpoint-config/gpu-redis-cv-mme2022-11-10-21-43-59\n"
     ]
    }
   ],
   "source": [
    "endpoint_config_name = model_name\n",
    "print(\"Endpoint config name: \" + endpoint_config_name)\n",
    "\n",
    "create_endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"InstanceType\": \"ml.m5.xlarge\",\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"InitialVariantWeight\": 1,\n",
    "            \"ModelName\": model_name,\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Endpoint config Arn: \" + create_endpoint_config_response[\"EndpointConfigArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create End point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint name: GPU-REDIS-CV-MME2022-11-10-21-43-59\n",
      "Endpoint Arn: arn:aws:sagemaker:us-east-1:622343165275:endpoint/gpu-redis-cv-mme2022-11-10-21-43-59\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "endpoint_name = model_name\n",
    "print(\"Endpoint name: \" + endpoint_name)\n",
    "\n",
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "print(\"Endpoint Arn: \" + create_endpoint_response[\"EndpointArn\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Status: Creating\n",
      "Waiting for GPU-REDIS-CV-MME2022-11-10-21-43-59 endpoint to be in service...\n",
      "endpointGPU-REDIS-CV-MME2022-11-10-21-43-59:: still creating...\n",
      "endpointGPU-REDIS-CV-MME2022-11-10-21-43-59:: still creating...\n",
      "endpointGPU-REDIS-CV-MME2022-11-10-21-43-59:: still creating...\n",
      "endpointGPU-REDIS-CV-MME2022-11-10-21-43-59:: still creating...\n",
      "Endpoint Created:::\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"Endpoint Status: \" + status)\n",
    "\n",
    "print(\"Waiting for {} endpoint to be in service...\".format(endpoint_name))\n",
    "while 'Creating' == status:\n",
    "    print(f\"endpoint{endpoint_name}:: still creating...\")\n",
    "    time.sleep(30) # 30 sec\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "    \n",
    "#waiter = sm_client.get_waiter(\"endpoint_in_service\")\n",
    "#waiter.wait(EndpointName=endpoint_name)\n",
    "\n",
    "print(\"Endpoint Created:::\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GPU-REDIS-CV-MME2022-11-10-21-43-59'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Invoke end point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = mx.test_utils.download(\n",
    "    \"https://github.com/dmlc/web-data/blob/master/mxnet/doc/tutorials/python/predict_image/cat.jpg?raw=true\",\n",
    "    \"cat.jpg\",\n",
    ")\n",
    "\n",
    "with open(fname, \"rb\") as f:\n",
    "    payload = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bytes'>\n",
      "227791\n"
     ]
    }
   ],
   "source": [
    "print(type(payload))\n",
    "print(len(payload))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GPU-REDIS-CV-MME2022-11-10-21-43-59'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\"key_id\": \"12345\"}'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bytes(json.dumps({'key_id':\"12345\"}) , 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability=0.244390, class=label::277\n",
      "probability=0.170342, class=label::278\n",
      "probability=0.145019, class=label::263\n",
      "probability=0.059833, class=label::335\n",
      "probability=0.051555, class=label::282\n",
      "CPU times: user 2.83 ms, sys: 1.87 ms, total: 4.7 ms\n",
      "Wall time: 69.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import json\n",
    "\n",
    "custom_attr = {'key1': 'image1', 'key2':'image2', 'cpu_endpointname' : 'endpointGPU-REDIS-CV-MME2022-11-10-17-41-29'}\n",
    "response = runtime_sm_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=\"application/x-image\",\n",
    "    Body=bytes(json.dumps({'key_id':\"12345\"}) , 'utf-8'), #payload,\n",
    "    CustomAttributes=json.dumps(custom_attr)\n",
    ")\n",
    "\n",
    "response_body = response[\"Body\"].read()\n",
    "\n",
    "print(*json.loads(response_body), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'[\\n  \"probability=0.244390, class=label::277\",\\n  \"probability=0.170342, class=label::278\",\\n  \"probability=0.145019, class=label::263\",\\n  \"probability=0.059833, class=label::335\",\\n  \"probability=0.051555, class=label::282\"\\n]'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Model invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import json\n",
    "\n",
    "response = runtime_sm_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=\"application/x-image\",\n",
    "    TargetModel=\"resnet_18.tar.gz\",  # this is the rest of the S3 path where the model artifacts are located\n",
    "    Body=payload,\n",
    ")\n",
    "\n",
    "print(*json.loads(response[\"Body\"].read()), sep=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '0d9dc777-42f8-42b6-af8e-5442330ed27b',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '0d9dc777-42f8-42b6-af8e-5442330ed27b',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Thu, 10 Nov 2022 21:43:02 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_client.delete_endpoint(EndpointName=endpoint_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'df341498-8e5d-4133-ad57-35eddbce468e',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'df341498-8e5d-4133-ad57-35eddbce468e',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Thu, 10 Nov 2022 21:43:02 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_client.delete_endpoint_config(EndpointConfigName=endpoint_name)\n",
    "sm_client.delete_model(ModelName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<p>ImageDataGenerator generates batches of tensor image data with real-time data augmentation. \n",
    "The data will be looped over (in batches)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Create a Multi-Model Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### a) Copy Trained Models to a common S3 Prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "output_2 = f's3://{BUCKET}/{PREFIX}/mme/sign-language.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "print(output_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 100 copies of this model to simulate multiple models\n",
    "\n",
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "s3_bucket = sess.default_bucket()  # Replace with your own bucket name if needed\n",
    "print(s3_bucket)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 100 copies of this model to simulate multiple models\n",
    "\n",
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "s3_bucket = sess.default_bucket()  # Replace with your own bucket name if needed\n",
    "print(s3_bucket)\n",
    "\n",
    "# Cell 06\n",
    "import boto3\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "with open(\"models/model2/model.tar.gz\", \"rb\") as f:\n",
    "    # - s3://{BUCKET}/{PREFIX}/mme/sign-language.tar.gz\n",
    "    s3.upload_fileobj(f, s3_bucket, f\"{PREFIX}/mme/sign-language.tar.gz\")\n",
    "\n",
    "for i in range(0, 5):\n",
    "    with open(\"models/model2/model.tar.gz\", \"rb\") as f:\n",
    "        # - s3://{BUCKET}/{PREFIX}/mme/sign-language-0.tar.gz\n",
    "        s3.upload_fileobj(f, s3_bucket, f\"{PREFIX}/mme/sign-language-{i}.tar.gz\")\n",
    "\n",
    "print(\"Models:uploaded and ready for use\")\n",
    "!aws s3 ls s3://{s3_bucket}/{PREFIX}/mme/\n",
    "!aws s3 ls {output_2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### b) Essentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "IMAGE_URI = '763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.3.1-cpu-py37-ubuntu18.04'\n",
    "model_data_prefix = f's3://{BUCKET}/{PREFIX}/mme/'\n",
    "model_data_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls {model_data_prefix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploy multi model end point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sm_client = boto3.client(service_name=\"sagemaker\")\n",
    "runtime_sm_client = boto3.client(service_name=\"sagemaker-runtime\")\n",
    "\n",
    "account_id = boto3.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Model\n",
    "\n",
    "model_url must point to the S3 prefix under which the models are stored so like with the \"/\" at end\n",
    "\n",
    "s3://s3_bucket/cv-models/mme/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13\n",
    "from time import gmtime, strftime\n",
    "\n",
    "model_name = \"mme-tensorflow-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "container = '763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.3.1-cpu-py37-ubuntu18.04'\n",
    "\n",
    "instance_type = \"ml.m5.xlarge\"\n",
    "\n",
    "print(\"Model name: \" + model_name)\n",
    "print(\"Model data Url: \" + model_data_prefix)\n",
    "print(\"Container image: \" + container)\n",
    "\n",
    "container = {\"Image\": container, \"ModelDataUrl\": model_data_prefix, \"Mode\": \"MultiModel\"}\n",
    "\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName=model_name, ExecutionRoleArn=role, Containers=[container]\n",
    ")\n",
    "\n",
    "print(\"Model ARN: \" + create_model_response[\"ModelArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create end point config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14\n",
    "endpoint_config_name = model_name # - keep the name the same across for ease of tracking\n",
    "print(\"Endpoint config name: \" + endpoint_config_name)\n",
    "\n",
    "create_endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"InstanceType\": instance_type,\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"InitialVariantWeight\": 1,\n",
    "            \"ModelName\": model_name,\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Endpoint config ARN: \" + create_endpoint_config_response[\"EndpointConfigArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create end point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Cell 15\n",
    "\n",
    "import time\n",
    "\n",
    "endpoint_name = model_name # - keep the name the same across for ease of tracking\n",
    "print(\"Endpoint name: \" + endpoint_name)\n",
    "\n",
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "print(\"Endpoint Arn: \" + create_endpoint_response[\"EndpointArn\"])\n",
    "\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"Endpoint Status: \" + status)\n",
    "\n",
    "print(\"Waiting for {} endpoint to be in service...\".format(endpoint_name))\n",
    "waiter = sm_client.get_waiter(\"endpoint_in_service\")\n",
    "waiter.wait(EndpointName=endpoint_name)\n",
    "\n",
    "print(\"Created {} endpoint is in Service and read to invoke ...\".format(endpoint_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Invoke the end point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from IPython.display import Image\n",
    "import matplotlib.image as mpimg \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path  = './data/sign_language/test'\n",
    "img = mpimg.imread(f'{test_path}/0/IMG_4159.JPG')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def get_sample_image(img_path):\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    #img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img = img.resize((224, 224))\n",
    "    img = (np.array(img).astype(np.float32) / 255) - np.array(\n",
    "        [0.485, 0.456, 0.406], dtype=np.float32\n",
    "    ).reshape(1, 1, 3)\n",
    "    img = img / np.array([0.229, 0.224, 0.225], dtype=np.float32).reshape(1, 1, 3)\n",
    "    img = np.transpose(img, (2, 0, 1))\n",
    "    return img.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_sample_image(f'{test_path}/0/IMG_4159.JPG')\n",
    "print(len(data[0]))\n",
    "print(type(data))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import CSVDeserializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sess,\n",
    "    serializer=CSVSerializer(), \n",
    "    deserializer=JSONDeserializer(),#C SVDeserializer(),\n",
    "    #target_model=\"sign-language-0.tar.gz\"\n",
    ")\n",
    "predictor.predict(data=data, target_model=\"sign-language-0.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(f'{test_path}/0/IMG_4159.JPG', \"rb\") as f:\n",
    "with open(f'{test_path}/0/Prakash.jpeg', \"rb\") as f:    \n",
    "    payload = f.read()\n",
    "    \n",
    "import json\n",
    "\n",
    "response = sm_runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, \n",
    "    ContentType=\"application/x-image\", \n",
    "    Body=payload,\n",
    "    TargetModel=\"sign-language-0.tar.gz\"\n",
    ")\n",
    "result = response[\"Body\"].read()\n",
    "# result will be in json format and convert it to ndarray\n",
    "result = json.loads(result)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = path_to_tensor(f'{test_path}/0/IMG_4159.JPG')\n",
    "payload = {'instances': data}\n",
    "payload\n",
    "print(type(payload))\n",
    "print(type(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(data))\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import CSVDeserializer\n",
    "\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sess,\n",
    "    serializer=CSVSerializer(), \n",
    "    deserializer=CSVDeserializer(),\n",
    "    #target_model=\"sign-language-0.tar.gz\"\n",
    ")\n",
    "predictor.predict(data, target_model=\"sign-language-0.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_runtime = boto3.Session().client('sagemaker-runtime')\n",
    "\n",
    "with open(f'{test_path}/0/IMG_4159.JPG', 'rb') as f:\n",
    "    payload = f.read()\n",
    "    payload = bytearray(payload)\n",
    "    print(type(payload))\n",
    "    print(payload)\n",
    "    response = sm_runtime.invoke_endpoint(\n",
    "        EndpointName=endpoint_name, \n",
    "        ContentType=\"application/x-image\", \n",
    "        Body=payload,\n",
    "        TargetModel=\"sign-language-0.tar.gz\"\n",
    "    )\n",
    "    result = response[\"Body\"].read()\n",
    "    # result will be in json format and convert it to ndarray\n",
    "    result = json.loads(result)\n",
    "    # the result will output the probabilities for all classes\n",
    "    # find the class with maximum probability and print the class index\n",
    "    index = np.argmax(result)\n",
    "    print(\"Result: label - \" + object_categories[index] + \", probability - \" + str(result[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import CSVDeserializer\n",
    "\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sess,\n",
    "    serializer=CSVSerializer(), \n",
    "    deserializer=CSVDeserializer()\n",
    ")\n",
    "predictor.predict(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16\n",
    "from datetime import datetime\n",
    "import time\n",
    "import json\n",
    "\n",
    "data = np.array(data)\n",
    "payload = json.dumps(data.tolist())\n",
    "\n",
    "print(type(payload))\n",
    "\n",
    "for i in range(0, 2):\n",
    "    start_time = datetime.now()\n",
    "    response = runtime_sm_client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        ContentType='application/json',\n",
    "        TargetModel=f\"sign-language-{i}.tar.gz\",\n",
    "        Body=payload\n",
    "    )\n",
    "    result = json.loads(response['Body'].read().decode())\n",
    "    #res = result['predictions']\n",
    "    time_delta = (datetime.now()-start_time).total_seconds() * 1000 \n",
    "    time_delta = \"{:.2f}\".format(time_delta)\n",
    "    \n",
    "    print(f'Time={time_delta} --- > ::{len(result)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.keys())\n",
    "response['Body'].read().decode()\n",
    "response['ResponseMetadata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
