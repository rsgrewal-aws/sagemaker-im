{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "---\n",
    "## <span style=\"color:orange\"> Host Multiple TensorFlow Computer Vision Models using SageMaker Multi-Model Endpoint </span>\n",
    "---\n",
    "## <span style=\"color:black\">Contents</span>\n",
    "1. [Background](#Background)\n",
    "1. [Setup](#Setup)\n",
    "1. [Train Model 2 - Sign Language Image Classification](#Train-Model-2---Sign-Language-Image-Classification)\n",
    "1. [Create a Multi-Model Endpoint](#Create-a-Multi-Model-Endpoint)\n",
    "1. [Test Multi-Model Endpoint for Real Time Inference](#Test-Multi-Model-Endpoint-for-Real-Time-Inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Background\n",
    "In this notebook, we show how to host multiple computer vision models trained using the TensorFlow framework under one SageMaker multi-model endpoint.  For the model we use a pretrained VGG16 CNN model pretrained on the ImageNet dataset and fine-tune on Sign Language Digits Dataset.\n",
    "\n",
    "in this notebook we are using the final version as training is not the focus. To simulate multiple models we will create copies of the same model and load them in S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    " #### Prerequisites \n",
    " Choose Kernel for this notebook.<br>\n",
    " Under `Kernel` tab at the top of this notebook &#8594; `Choose kernel`, select `conda_python3` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install tensorflow==2.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall redis -y\n",
    "!pip uninstall redis-py-cluster -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install redis-py-cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/mxnet_p37/lib/python3.7/site-packages (1.24.82)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/mxnet_p37/lib/python3.7/site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.82 in /home/ec2-user/anaconda3/envs/mxnet_p37/lib/python3.7/site-packages (from boto3) (1.27.82)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/mxnet_p37/lib/python3.7/site-packages (from boto3) (0.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/mxnet_p37/lib/python3.7/site-packages (from botocore<1.28.0,>=1.27.82->boto3) (1.26.8)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/mxnet_p37/lib/python3.7/site-packages (from botocore<1.28.0,>=1.27.82->boto3) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/mxnet_p37/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.82->boto3) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/mxnet_p37/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 22:11:33.551547: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.0/lib64:/usr/local/cuda-11.0/extras/CUPTI/lib64:/usr/local/cuda-11.0/lib:/usr/local/cuda-11.0/efa/lib:/opt/amazon/efa/lib:/opt/amazon/efa/lib64:/opt/amazon/efa/lib64:/opt/amazon/openmpi/lib64:/usr/local/lib:/usr/lib:/lib:\n",
      "2022-11-10 22:11:33.551577: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sagemaker.tensorflow.serving import TensorFlowModel\n",
    "from sagemaker.multidatamodel import MultiDataModel\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker import get_execution_role\n",
    "from tensorflow.keras import utils\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "import logging\n",
    "import boto3\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "from rediscluster import RedisCluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using sageMaker VPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Connected to Redis\n"
     ]
    }
   ],
   "source": [
    "from redis import Redis\n",
    "import logging\n",
    "redis_client = Redis(\n",
    "    host='testredis.m7ovi1.ng.0001.use1.cache.amazonaws.com', \n",
    "    port=6379, #decode_responses=True, ssl=True, \n",
    "    username='default', #'testredisuser', 'default'\n",
    "    #password='testRedisUserPassword'\n",
    ")\n",
    "# redis_client = Redis(\n",
    "#     host='testredis.m7ovi1.ng.0001.use1.cache.amazonaws.com',\n",
    "#     username='testredisuser',\n",
    "#     password='testRedisUserPassword', ssl_cert_reqs=None,  decode_responses=True)\n",
    "\n",
    "if redis_client.ping():\n",
    "    logging.info(\"Connected to Redis\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Setup Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Using TensorFlow version: 2.3.0]\n",
      "INFO:__main__:[Using TensorFlow version: 2.3.0]\n",
      "[Using SageMaker version: 2.116.0]\n",
      "INFO:__main__:[Using SageMaker version: 2.116.0]\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'[Using TensorFlow version: {tf.__version__}]')\n",
    "logger.info(f'[Using SageMaker version: {sagemaker.__version__}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Seed for Reproducability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "SEED = 123\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Create Roles, Sessions and Data Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-1\n",
      "622343165275\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "session = boto3.Session()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region=sagemaker_session.boto_region_name\n",
    "print(region)\n",
    "account_id = sagemaker_session.account_id()\n",
    "print(account_id)\n",
    "\n",
    "s3 = session.resource('s3')\n",
    "TF_FRAMEWORK_VERSION = '2.3.0'\n",
    "BUCKET = sagemaker.Session().default_bucket()\n",
    "PREFIX = 'cv-models'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### b) Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# - ./data/sign_language/train/0/IMG_1118.JPG\n",
    "train_path  = './data/sign_language/train'\n",
    "img = mpimg.imread(f'{train_path}/0/IMG_1118.JPG')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U awscli --quiet\n",
    "!pip install torch==1.8.0 --quiet \n",
    "!pip install torchvision==0.9.0 --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create custom container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "sha256:abb97409da1b0592ad722e43c12753d3e8dd4f2dbf7b63d5a670a63135082e92\n",
      "The push refers to repository [622343165275.dkr.ecr.us-east-1.amazonaws.com/cpu-cv-redis]\n",
      "6531ae424295: Preparing\n",
      "148c995515a0: Preparing\n",
      "dda72c5650f0: Preparing\n",
      "87dae351871c: Preparing\n",
      "f1a39e103d35: Preparing\n",
      "0f13e18a9cc4: Preparing\n",
      "b7abf7d0bb2c: Preparing\n",
      "eba15308a6ba: Preparing\n",
      "a92e3c51a0b6: Preparing\n",
      "419e1b612781: Preparing\n",
      "599518d61809: Preparing\n",
      "dda6665a48d3: Preparing\n",
      "69f57fbceb1b: Preparing\n",
      "0f13e18a9cc4: Waiting\n",
      "b7abf7d0bb2c: Waiting\n",
      "eba15308a6ba: Waiting\n",
      "a92e3c51a0b6: Waiting\n",
      "419e1b612781: Waiting\n",
      "599518d61809: Waiting\n",
      "dda6665a48d3: Waiting\n",
      "69f57fbceb1b: Waiting\n",
      "6531ae424295: Layer already exists\n",
      "dda72c5650f0: Layer already exists\n",
      "148c995515a0: Layer already exists\n",
      "87dae351871c: Layer already exists\n",
      "f1a39e103d35: Layer already exists\n",
      "b7abf7d0bb2c: Layer already exists\n",
      "a92e3c51a0b6: Layer already exists\n",
      "0f13e18a9cc4: Layer already exists\n",
      "419e1b612781: Layer already exists\n",
      "eba15308a6ba: Layer already exists\n",
      "599518d61809: Layer already exists\n",
      "dda6665a48d3: Layer already exists\n",
      "69f57fbceb1b: Layer already exists\n",
      "latest: digest: sha256:0c4afb978b906711eec9a690f9f2316c9f30cfab9f0fd5d599c3c5f2b9e782ae size: 3039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=cpu-cv-redis\n",
    "\n",
    "cd container\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build -q -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download resnet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import os\n",
    "import tarfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:models/resnet_18/resnet-18-0000.params exists, skipping download\n",
      "INFO:root:models/resnet_18/resnet-18-symbol.json exists, skipping download\n",
      "INFO:root:data/resnet_18/synset.txt exists, skipping download\n",
      "INFO:root:models/resnet_152/resnet-152-0000.params exists, skipping download\n",
      "INFO:root:models/resnet_152/resnet-152-symbol.json exists, skipping download\n",
      "INFO:root:data/resnet_152/synset.txt exists, skipping download\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "import os\n",
    "import tarfile\n",
    "\n",
    "model_path = \"http://data.mxnet.io/models/imagenet/\"\n",
    "!mkdir -p models/resnet_18\n",
    "\n",
    "mx.test_utils.download(\n",
    "    model_path + \"resnet/18-layers/resnet-18-0000.params\", None, \"models/resnet_18\"\n",
    ")\n",
    "mx.test_utils.download(\n",
    "    model_path + \"resnet/18-layers/resnet-18-symbol.json\", None, \"models/resnet_18\"\n",
    ")\n",
    "mx.test_utils.download(model_path + \"synset.txt\", None, \"data/resnet_18\")\n",
    "\n",
    "with open(\"models/resnet_18/resnet-18-shapes.json\", \"w\") as file:\n",
    "    file.write('[{\"shape\": [1, 3, 224, 224], \"name\": \"data\"}]')\n",
    "\n",
    "with tarfile.open(\"models/resnet_18.tar.gz\", \"w:gz\") as tar:\n",
    "    tar.add(\"models/resnet_18\", arcname=\".\")\n",
    "    \n",
    " \n",
    "!mkdir -p models/resnet_152\n",
    "mx.test_utils.download(\n",
    "    model_path + \"resnet/152-layers/resnet-152-0000.params\", None, \"models/resnet_152\"\n",
    ")\n",
    "mx.test_utils.download(\n",
    "    model_path + \"resnet/152-layers/resnet-152-symbol.json\", None, \"models/resnet_152\"\n",
    ")\n",
    "mx.test_utils.download(model_path + \"synset.txt\", None, \"data/resnet_152\")\n",
    "\n",
    "with open(\"models/resnet_152/resnet-152-shapes.json\", \"w\") as file:\n",
    "    file.write('[{\"shape\": [1, 3, 224, 224], \"name\": \"data\"}]')\n",
    "\n",
    "with tarfile.open(\"models/resnet_152.tar.gz\", \"w:gz\") as tar:\n",
    "    tar.add(\"data/resnet_152\", arcname=\".\") \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-622343165275\n",
      "cv-models\n",
      "arn:aws:iam::622343165275:role/service-role/AmazonSageMaker-ExecutionRole-20220208T115633\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "s3_bucket = sess.default_bucket()  # Replace with your own bucket name if needed\n",
    "prefix = \"cv-models\"\n",
    "print(s3_bucket)\n",
    "print(prefix)\n",
    "\n",
    "sm_client = boto3.client(service_name=\"sagemaker\")\n",
    "runtime_sm_client = boto3.client(service_name=\"sagemaker-runtime\")\n",
    "\n",
    "account_id = boto3.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.client import ClientError\n",
    "import os\n",
    "\n",
    "s3 = boto3.resource(\"s3\")\n",
    "s3.meta.client.head_bucket(Bucket=s3_bucket)\n",
    "\n",
    "models = {\"resnet_18.tar.gz\", \"resnet_152.tar.gz\"}\n",
    "\n",
    "for model in models:\n",
    "    key = os.path.join(prefix, model)\n",
    "    with open(\"models/\" + model, \"rb\") as file_obj:\n",
    "        s3.Bucket(s3_bucket).Object(key).upload_fileobj(file_obj)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create end point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container image: 622343165275.dkr.ecr.us-east-1.amazonaws.com/cpu-cv-redis:latest\n",
      "Model name: cpu-cv-redis2022-11-10-22-57-18\n",
      "Model data Url: s3://sagemaker-us-east-1-622343165275/cv-models/resnet_18.tar.gz\n",
      "Container image: 622343165275.dkr.ecr.us-east-1.amazonaws.com/cpu-cv-redis:latest\n",
      "Model Arn: arn:aws:sagemaker:us-east-1:622343165275:model/cpu-cv-redis2022-11-10-22-57-18\n"
     ]
    }
   ],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "model_name = \"cpu-cv-redis\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "#model_url = \"https://s3-{}.amazonaws.com/{}/{}/\".format(region, s3_bucket, prefix)\n",
    "\n",
    "    \n",
    "container = \"{}.dkr.ecr.{}.amazonaws.com/{}:latest\".format(\n",
    "    account_id, region, \"cpu-cv-redis\"\n",
    ")\n",
    "\n",
    "# print(\"Model name: \" + model_name)\n",
    "# print(\"Model data Url: \" + model_url)\n",
    "print(\"Container image: \" + container)\n",
    "\n",
    "#primary_container = {\"Image\": container, \"ModelDataUrl\": model_url, \"Mode\": \"MultiModel\"}\n",
    "\n",
    "# create_model_response = sm_client.create_model(\n",
    "#     ModelName=model_name, ExecutionRoleArn=role, Containers=[primary_container]\n",
    "# )\n",
    "\n",
    "\n",
    "vpc = 'vpc-05edeb4f9b293161c'\n",
    "subnet_a = 'subnet-0508539ff391bc62a'\n",
    "subnet_b = 'subnet-0f88fe2e674a870c4'\n",
    "\n",
    "subnet_c = 'subnet-02e4d3f4bd7ac9e66'\n",
    "subnet_d = 'subnet-0814f48bf38ffc0ae'\n",
    "subnet_e = 'subnet-076597677e5d1293b'\n",
    "subnet_f = 'subnet-09e3b111fe0bc7fa7'\n",
    "\n",
    "\n",
    "security_group = 'sg-0394e815564b9f05a'\n",
    "\n",
    "model_url = 's3://sagemaker-us-east-1-622343165275/cv-models/resnet_18.tar.gz'\n",
    "print(\"Model name: \" + model_name)\n",
    "print(\"Model data Url: \" + model_url)\n",
    "print(\"Container image: \" + container)\n",
    "\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    PrimaryContainer = {\n",
    "        'Image': container,\n",
    "        'ModelDataUrl': model_url\n",
    "    },\n",
    "    VpcConfig = {\n",
    "        'SecurityGroupIds': [security_group],\n",
    "        'Subnets': [subnet_a, subnet_b,subnet_c,subnet_d,subnet_e,subnet_f,],\n",
    "    },\n",
    "    EnableNetworkIsolation=False\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Model Arn: \" + create_model_response[\"ModelArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End point config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint config name: cpu-cv-redis2022-11-10-22-57-18\n",
      "Endpoint config Arn: arn:aws:sagemaker:us-east-1:622343165275:endpoint-config/cpu-cv-redis2022-11-10-22-57-18\n"
     ]
    }
   ],
   "source": [
    "endpoint_config_name = model_name\n",
    "print(\"Endpoint config name: \" + endpoint_config_name)\n",
    "\n",
    "create_endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"InstanceType\": \"ml.m5.xlarge\",\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"InitialVariantWeight\": 1,\n",
    "            \"ModelName\": model_name,\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Endpoint config Arn: \" + create_endpoint_config_response[\"EndpointConfigArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create End point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint name: cpu-cv-redis2022-11-10-22-57-18\n",
      "Endpoint Arn: arn:aws:sagemaker:us-east-1:622343165275:endpoint/cpu-cv-redis2022-11-10-22-57-18\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "endpoint_name = model_name\n",
    "print(\"Endpoint name: \" + endpoint_name)\n",
    "\n",
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "print(\"Endpoint Arn: \" + create_endpoint_response[\"EndpointArn\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Status: Creating\n",
      "Waiting for cpu-cv-redis2022-11-10-22-57-18 endpoint to be in service...\n",
      "endpointcpu-cv-redis2022-11-10-22-57-18:: still creating...\n",
      "endpointcpu-cv-redis2022-11-10-22-57-18:: still creating...\n",
      "endpointcpu-cv-redis2022-11-10-22-57-18:: still creating...\n",
      "endpointcpu-cv-redis2022-11-10-22-57-18:: still creating...\n",
      "endpointcpu-cv-redis2022-11-10-22-57-18:: still creating...\n",
      "Endpoint Created:::\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"Endpoint Status: \" + status)\n",
    "\n",
    "print(\"Waiting for {} endpoint to be in service...\".format(endpoint_name))\n",
    "while 'Creating' == status:\n",
    "    print(f\"endpoint{endpoint_name}:: still creating...\")\n",
    "    time.sleep(30) # 30 sec\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "    \n",
    "#waiter = sm_client.get_waiter(\"endpoint_in_service\")\n",
    "#waiter.wait(EndpointName=endpoint_name)\n",
    "\n",
    "print(\"Endpoint Created:::\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Invoke end point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:cat.jpg exists, skipping download\n"
     ]
    }
   ],
   "source": [
    "fname = mx.test_utils.download(\n",
    "    \"https://github.com/dmlc/web-data/blob/master/mxnet/doc/tutorials/python/predict_image/cat.jpg?raw=true\",\n",
    "    \"cat.jpg\",\n",
    ")\n",
    "\n",
    "with open(fname, \"rb\") as f:\n",
    "    payload = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bytes'>\n",
      "227791\n"
     ]
    }
   ],
   "source": [
    "print(type(payload))\n",
    "print(len(payload))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability=0.244390, class=label::277\n",
      "probability=0.170342, class=label::278\n",
      "probability=0.145019, class=label::263\n",
      "probability=0.059833, class=label::335\n",
      "probability=0.051555, class=label::282\n",
      "CPU times: user 11.6 ms, sys: 3.53 ms, total: 15.1 ms\n",
      "Wall time: 281 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import json\n",
    "\n",
    "response = runtime_sm_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=\"application/x-image\",\n",
    "    Body=payload,\n",
    ")\n",
    "\n",
    "print(*json.loads(response[\"Body\"].read()), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting invocation for CPU end point calling the GPU end point please wait ...\n",
      "\n",
      "Predictions for model latency: \n",
      "\n",
      "\n",
      "P95: 108.73383283615112 ms\n",
      "\n",
      "P90: 103.47027778625488 ms\n",
      "\n",
      "Average: 95.71578693389893 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Starting invocation for CPU end point calling the GPU end point please wait ...\")\n",
    "results = []\n",
    "for i in range(0, 1000):\n",
    "    start = time.time()\n",
    "    response = runtime_sm_client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        ContentType=\"application/x-image\",\n",
    "        Body=payload,\n",
    "    )\n",
    "    results.append((time.time() - start) * 1000)\n",
    "print(\"\\nPredictions for model latency: \\n\")\n",
    "print(\"\\nP95: \" + str(np.percentile(results, 95)) + \" ms\\n\")\n",
    "print(\"P90: \" + str(np.percentile(results, 90)) + \" ms\\n\")\n",
    "print(\"Average: \" + str(np.average(results)) + \" ms\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Model invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import json\n",
    "\n",
    "response = runtime_sm_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=\"application/x-image\",\n",
    "    TargetModel=\"resnet_18.tar.gz\",  # this is the rest of the S3 path where the model artifacts are located\n",
    "    Body=payload,\n",
    ")\n",
    "\n",
    "print(*json.loads(response[\"Body\"].read()), sep=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'f625e9bf-7e85-4c91-b3a6-5a608fce21e1',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'f625e9bf-7e85-4c91-b3a6-5a608fce21e1',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Thu, 10 Nov 2022 22:56:03 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_client.delete_endpoint(EndpointName=endpoint_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'db551d80-f234-4c46-8989-bfb71b14802a',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'db551d80-f234-4c46-8989-bfb71b14802a',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Thu, 10 Nov 2022 22:56:03 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_client.delete_endpoint_config(EndpointConfigName=endpoint_name)\n",
    "sm_client.delete_model(ModelName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<p>ImageDataGenerator generates batches of tensor image data with real-time data augmentation. \n",
    "The data will be looped over (in batches)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Create a Multi-Model Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### a) Copy Trained Models to a common S3 Prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "output_2 = f's3://{BUCKET}/{PREFIX}/mme/sign-language.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "print(output_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 100 copies of this model to simulate multiple models\n",
    "\n",
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "s3_bucket = sess.default_bucket()  # Replace with your own bucket name if needed\n",
    "print(s3_bucket)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 100 copies of this model to simulate multiple models\n",
    "\n",
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "s3_bucket = sess.default_bucket()  # Replace with your own bucket name if needed\n",
    "print(s3_bucket)\n",
    "\n",
    "# Cell 06\n",
    "import boto3\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "with open(\"models/model2/model.tar.gz\", \"rb\") as f:\n",
    "    # - s3://{BUCKET}/{PREFIX}/mme/sign-language.tar.gz\n",
    "    s3.upload_fileobj(f, s3_bucket, f\"{PREFIX}/mme/sign-language.tar.gz\")\n",
    "\n",
    "for i in range(0, 5):\n",
    "    with open(\"models/model2/model.tar.gz\", \"rb\") as f:\n",
    "        # - s3://{BUCKET}/{PREFIX}/mme/sign-language-0.tar.gz\n",
    "        s3.upload_fileobj(f, s3_bucket, f\"{PREFIX}/mme/sign-language-{i}.tar.gz\")\n",
    "\n",
    "print(\"Models:uploaded and ready for use\")\n",
    "!aws s3 ls s3://{s3_bucket}/{PREFIX}/mme/\n",
    "!aws s3 ls {output_2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### b) Essentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "IMAGE_URI = '763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.3.1-cpu-py37-ubuntu18.04'\n",
    "model_data_prefix = f's3://{BUCKET}/{PREFIX}/mme/'\n",
    "model_data_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls {model_data_prefix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploy multi model end point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sm_client = boto3.client(service_name=\"sagemaker\")\n",
    "runtime_sm_client = boto3.client(service_name=\"sagemaker-runtime\")\n",
    "\n",
    "account_id = boto3.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Model\n",
    "\n",
    "model_url must point to the S3 prefix under which the models are stored so like with the \"/\" at end\n",
    "\n",
    "s3://s3_bucket/cv-models/mme/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13\n",
    "from time import gmtime, strftime\n",
    "\n",
    "model_name = \"mme-tensorflow-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "container = '763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.3.1-cpu-py37-ubuntu18.04'\n",
    "\n",
    "instance_type = \"ml.m5.xlarge\"\n",
    "\n",
    "print(\"Model name: \" + model_name)\n",
    "print(\"Model data Url: \" + model_data_prefix)\n",
    "print(\"Container image: \" + container)\n",
    "\n",
    "container = {\"Image\": container, \"ModelDataUrl\": model_data_prefix, \"Mode\": \"MultiModel\"}\n",
    "\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName=model_name, ExecutionRoleArn=role, Containers=[container]\n",
    ")\n",
    "\n",
    "print(\"Model ARN: \" + create_model_response[\"ModelArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create end point config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14\n",
    "endpoint_config_name = model_name # - keep the name the same across for ease of tracking\n",
    "print(\"Endpoint config name: \" + endpoint_config_name)\n",
    "\n",
    "create_endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"InstanceType\": instance_type,\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"InitialVariantWeight\": 1,\n",
    "            \"ModelName\": model_name,\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Endpoint config ARN: \" + create_endpoint_config_response[\"EndpointConfigArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create end point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Cell 15\n",
    "\n",
    "import time\n",
    "\n",
    "endpoint_name = model_name # - keep the name the same across for ease of tracking\n",
    "print(\"Endpoint name: \" + endpoint_name)\n",
    "\n",
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "print(\"Endpoint Arn: \" + create_endpoint_response[\"EndpointArn\"])\n",
    "\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"Endpoint Status: \" + status)\n",
    "\n",
    "print(\"Waiting for {} endpoint to be in service...\".format(endpoint_name))\n",
    "waiter = sm_client.get_waiter(\"endpoint_in_service\")\n",
    "waiter.wait(EndpointName=endpoint_name)\n",
    "\n",
    "print(\"Created {} endpoint is in Service and read to invoke ...\".format(endpoint_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Invoke the end point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from IPython.display import Image\n",
    "import matplotlib.image as mpimg \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path  = './data/sign_language/test'\n",
    "img = mpimg.imread(f'{test_path}/0/IMG_4159.JPG')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def get_sample_image(img_path):\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    #img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img = img.resize((224, 224))\n",
    "    img = (np.array(img).astype(np.float32) / 255) - np.array(\n",
    "        [0.485, 0.456, 0.406], dtype=np.float32\n",
    "    ).reshape(1, 1, 3)\n",
    "    img = img / np.array([0.229, 0.224, 0.225], dtype=np.float32).reshape(1, 1, 3)\n",
    "    img = np.transpose(img, (2, 0, 1))\n",
    "    return img.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_sample_image(f'{test_path}/0/IMG_4159.JPG')\n",
    "print(len(data[0]))\n",
    "print(type(data))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import CSVDeserializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sess,\n",
    "    serializer=CSVSerializer(), \n",
    "    deserializer=JSONDeserializer(),#C SVDeserializer(),\n",
    "    #target_model=\"sign-language-0.tar.gz\"\n",
    ")\n",
    "predictor.predict(data=data, target_model=\"sign-language-0.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(f'{test_path}/0/IMG_4159.JPG', \"rb\") as f:\n",
    "with open(f'{test_path}/0/Prakash.jpeg', \"rb\") as f:    \n",
    "    payload = f.read()\n",
    "    \n",
    "import json\n",
    "\n",
    "response = sm_runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, \n",
    "    ContentType=\"application/x-image\", \n",
    "    Body=payload,\n",
    "    TargetModel=\"sign-language-0.tar.gz\"\n",
    ")\n",
    "result = response[\"Body\"].read()\n",
    "# result will be in json format and convert it to ndarray\n",
    "result = json.loads(result)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = path_to_tensor(f'{test_path}/0/IMG_4159.JPG')\n",
    "payload = {'instances': data}\n",
    "payload\n",
    "print(type(payload))\n",
    "print(type(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(data))\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import CSVDeserializer\n",
    "\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sess,\n",
    "    serializer=CSVSerializer(), \n",
    "    deserializer=CSVDeserializer(),\n",
    "    #target_model=\"sign-language-0.tar.gz\"\n",
    ")\n",
    "predictor.predict(data, target_model=\"sign-language-0.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_runtime = boto3.Session().client('sagemaker-runtime')\n",
    "\n",
    "with open(f'{test_path}/0/IMG_4159.JPG', 'rb') as f:\n",
    "    payload = f.read()\n",
    "    payload = bytearray(payload)\n",
    "    print(type(payload))\n",
    "    print(payload)\n",
    "    response = sm_runtime.invoke_endpoint(\n",
    "        EndpointName=endpoint_name, \n",
    "        ContentType=\"application/x-image\", \n",
    "        Body=payload,\n",
    "        TargetModel=\"sign-language-0.tar.gz\"\n",
    "    )\n",
    "    result = response[\"Body\"].read()\n",
    "    # result will be in json format and convert it to ndarray\n",
    "    result = json.loads(result)\n",
    "    # the result will output the probabilities for all classes\n",
    "    # find the class with maximum probability and print the class index\n",
    "    index = np.argmax(result)\n",
    "    print(\"Result: label - \" + object_categories[index] + \", probability - \" + str(result[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import CSVDeserializer\n",
    "\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sess,\n",
    "    serializer=CSVSerializer(), \n",
    "    deserializer=CSVDeserializer()\n",
    ")\n",
    "predictor.predict(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16\n",
    "from datetime import datetime\n",
    "import time\n",
    "import json\n",
    "\n",
    "data = np.array(data)\n",
    "payload = json.dumps(data.tolist())\n",
    "\n",
    "print(type(payload))\n",
    "\n",
    "for i in range(0, 2):\n",
    "    start_time = datetime.now()\n",
    "    response = runtime_sm_client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        ContentType='application/json',\n",
    "        TargetModel=f\"sign-language-{i}.tar.gz\",\n",
    "        Body=payload\n",
    "    )\n",
    "    result = json.loads(response['Body'].read().decode())\n",
    "    #res = result['predictions']\n",
    "    time_delta = (datetime.now()-start_time).total_seconds() * 1000 \n",
    "    time_delta = \"{:.2f}\".format(time_delta)\n",
    "    \n",
    "    print(f'Time={time_delta} --- > ::{len(result)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.keys())\n",
    "response['Body'].read().decode()\n",
    "response['ResponseMetadata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
